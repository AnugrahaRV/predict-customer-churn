{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import random\n",
    "sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_dir = '/data/churn/partitions/'\n",
    "partitions = list(range(len(os.listdir(base_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels(customer_id, trans, label_type, churn_period = 30, return_cust = False):\n",
    "    \"\"\"Make labels for one customer for one period\n",
    "    Params\n",
    "    --------\n",
    "        customer_id (str): string used to select customer\n",
    "        trans (dataframe): transactions for customers\n",
    "        label_type (str): either 'MS' for monthly labels at the start of the month or \n",
    "                          'SMS' for twice a month labels (on 1 and 15 of month)\n",
    "        churn_period (int): number of days without membership required for a churn [default 30 days]\n",
    "        return_cust (bool): whether or not to return the customer dataframe. Useful for debugging\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        labels (dataframe): labels for all months in customer history\n",
    "                            columns are ['msno', 'cutoff', 'churn', 'days_to_next_churn']\n",
    "        cust (dataframe): if return_cust == True, a dataframe of the customers transactions\n",
    "    \"\"\"\n",
    "    assert label_type in ['MS', 'SMS'], 'label_type must be either \"MS\" or \"SMS\"'\n",
    "    \n",
    "    cust = trans.loc[trans['msno'] == customer_id].copy()\n",
    "    \n",
    "    # Make sure to sort transactions and drop the index\n",
    "    cust = cust.sort_values(['transaction_date', 'membership_expire_date']).reset_index(drop = True)\n",
    "    \n",
    "    # Find gap between membership expiration and start of next membership\n",
    "    cust['gap'] = (cust['transaction_date'].shift(-1) - cust['membership_expire_date']).dt.days \n",
    "    \n",
    "    # Determine if churn occur\n",
    "    cust.loc[cust['gap'] > churn_period, 'churn']  = 1\n",
    "    cust.loc[cust['gap'] <= churn_period, 'churn'] = 0\n",
    "    \n",
    "    # Calculate date range for labels\n",
    "    first_trans = cust['transaction_date'].min()\n",
    "    last_trans = cust['membership_expire_date'].max()\n",
    "    start_date = pd.datetime(first_trans.year, first_trans.month, 1)\n",
    "    \n",
    "    # Handle case where last transaction month was december\n",
    "    if last_trans.month == 12:\n",
    "        end_date = pd.datetime(last_trans.year + 1, 1, 1)\n",
    "    else:\n",
    "        end_date = pd.datetime(last_trans.year, last_trans.month + 1, 1)\n",
    "\n",
    "    # Create a range of dates for labels \n",
    "    # 'MS' = month starts, 'SM': twice a month on 15 and end.\n",
    "    date_range = pd.date_range(start_date, end_date, freq = label_type)\n",
    "    \n",
    "    # Create a label dataframe\n",
    "    labels = pd.DataFrame({'cutoff_time': date_range})\n",
    "    labels['next_cutoff_time'] = labels['cutoff_time'].shift(-1)\n",
    "    labels['msno'] = customer_id\n",
    "    \n",
    "    # Handle case where there are no churns\n",
    "    if not np.any(cust['churn'] == 1):\n",
    "        labels['churn'] = 0\n",
    "        labels['days_to_next_churn'] = np.nan\n",
    "        return labels[['msno', 'cutoff_time', 'churn', 'days_to_next_churn']]\n",
    "    \n",
    "    # If customer did churn set the churn date\n",
    "    cust['potential_churn_date'] = cust['membership_expire_date'] + pd.Timedelta(churn_period, unit = 'd')\n",
    "    cust.loc[cust['churn'] == 1, 'churn_date'] = cust.loc[cust['churn'] == 1, 'potential_churn_date']\n",
    "    \n",
    "    previous_churn = None\n",
    "\n",
    "    # Iterate through the churn dates\n",
    "    for churn_date in cust.loc[cust['churn_date'].notnull(), 'churn_date']:\n",
    "        \n",
    "        # Assign the label 1 if the customer churned during the cutoff_time period\n",
    "        labels.loc[(labels['cutoff_time'] <= churn_date) & (labels['next_cutoff_time'] > churn_date), 'churn'] = 1\n",
    "\n",
    "        if previous_churn is not None:\n",
    "            # Subset to cutoff times after the previous churn but before the current churn\n",
    "            # Calculate the days until the churn\n",
    "            labels.loc[(labels['cutoff_time'] > previous_churn) & \n",
    "                       (labels['cutoff_time'] <= churn_date), \n",
    "                       'days_to_next_churn'] = (churn_date - labels.loc[(labels['cutoff_time'] > previous_churn) & \n",
    "                                                                       (labels['cutoff_time'] <= churn_date), \n",
    "                                                                        'cutoff_time']).dt.days\n",
    "        # No previous churn\n",
    "        else:\n",
    "            # Subset to cutoff times before the current churn and calculate days until the churn\n",
    "            labels.loc[labels['cutoff_time'] <= churn_date, \n",
    "                       'days_to_next_churn'] = (churn_date - labels.loc[labels['cutoff_time'] <= churn_date,\n",
    "                                                                         'cutoff_time']).dt.days\n",
    "        previous_churn = churn_date\n",
    "    \n",
    "    labels['churn'] = labels['churn'].fillna(0)\n",
    "    \n",
    "    # Sometimes want to return customer information for debugging\n",
    "    if return_cust:\n",
    "        return cust, labels[['msno', 'cutoff_time', 'churn', 'days_to_next_churn']]\n",
    "    \n",
    "    # Subset to relevant columns\n",
    "    return labels[['msno', 'cutoff_time', 'churn', 'days_to_next_churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_to_labels(partition, label_type, churn_period):\n",
    "    \"\"\"Make labels for all customers in one partition\n",
    "    Either for one month or twice a month\n",
    "    \n",
    "    Params\n",
    "    --------\n",
    "        partition (int): number of partition\n",
    "        label_type (str): either 'monthly' for monthly labels or\n",
    "                          'bimonthly' for twice a month labels\n",
    "        churn_period (int): number of days required without a membership for a churn\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "        None: saves the label dataframes with the appropriate name to the partition directory\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in data and filter anomalies\n",
    "    trans = pd.read_csv(f'{base_dir}p{partition}/transactions.csv',\n",
    "                        parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                        infer_datetime_format = True)\n",
    "    trans = trans.loc[trans['membership_expire_date'] >= trans['transaction_date']]\n",
    "    \n",
    "    cutoff_list = []\n",
    "\n",
    "    if label_type == 'monthly':\n",
    "        # Iterate through every customer\n",
    "        for customer_id in trans['msno'].unique():\n",
    "            cutoff_list.append(generate_labels(customer_id, trans, label_type = 'MS', churn_period = churn_period))\n",
    "        cutoff_times = pd.concat(cutoff_list)\n",
    "        cutoff_times.to_csv(f'{base_dir}p{partition}/monthly_labels_{churn_period}.csv', index = False)\n",
    "        \n",
    "    \n",
    "    elif label_type == 'bimonthly':\n",
    "        for customer_id in trans['msno'].unique():\n",
    "            cutoff_list.append(generate_labels(customer_id, trans, label_type = 'SMS', churn_period = churn_period))\n",
    "        cutoff_times = pd.concat(cutoff_list)\n",
    "        cutoff_times.to_csv(f'{base_dir}p{partition}/bimonthly_labels_{churn_period}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "partition_to_labels(1, 'monthly', 30)\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "partition_to_labels(1, 'bimonthly', 14)\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/local/spark/sbin/stop-all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/local/spark/sbin/start-all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "conf.set('spark.eventLog.enabled', True);\n",
    "conf.set('spark.eventLog.dir', '/usr/local/spark/tmp');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "sc = pyspark.SparkContext(master = 'spark://ip-172-31-23-133.ec2.internal:7077', \n",
    "                          appName = 'labeling_month', conf = conf)\n",
    "r = sc.parallelize(partitions, numSlices=1000).map(lambda x: partition_to_labels(x, \n",
    "                                                   label_type = 'monthly', \n",
    "                                                   churn_period = 30)).collect()\n",
    "sc.stop()\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "sc = pyspark.SparkContext(master = 'spark://ip-172-31-23-133.ec2.internal:7077', \n",
    "                          appName = 'labeling_bimonthly', conf = conf)\n",
    "r = sc.parallelize(partitions, numSlices=1000).map(lambda x: partition_to_labels(x, \n",
    "                                                   label_type = 'bimonthly', \n",
    "                                                   churn_period = 14)).collect()\n",
    "sc.stop()\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
