{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Automated Feature Engineering with Featuretools\n",
    "\n",
    "Automated feature engineering allows us to create hundreds or thousands of relevant features from a relational dataset in a few framework that can be re-used across problems. This approach overcomes the limitations of traditional manual feature engineering, letting us develop better predictive models in a fraction of the time. \n",
    "\n",
    "Currently, the only option for automated feature engineering using multiple related tables is [Featuretools](https://github.com/Featuretools/featuretools), an open-source Python library. \n",
    "\n",
    "In this notebook, we'll work with Featuretools to develop an automated feature engineering workflow for the customer churn dataset. After developing a function that works to build features from a single partition, we'll be able to apply this function to all of the partitions in parallel using Spark with PySpark.\n",
    "\n",
    "## Featuretools Resources\n",
    "\n",
    "We won't spend too much time on the basics of Featuretools here, so refer to the following sources for more information:\n",
    "\n",
    "* [Featuretools Documentation](https://docs.featuretools.com/)\n",
    "* [Featuretools GitHub](https://github.com/Featuretools/featuretools)\n",
    "* [Introductory tutorial on Featuretools](https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219)\n",
    "* [Why Automated Feature Engineering Will Change Machine Learning](https://towardsdatascience.com/why-automated-feature-engineering-will-change-the-way-you-do-machine-learning-5c15bf188b96)\n",
    "\n",
    "The basics are relatively easy to pick up, and if you're new, you can probably follow along with all the code here! \n",
    "With that in mind, let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data science helpers\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import featuretools as ft\n",
    "\n",
    "# Useful for showing multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "N_PARTITIONS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the data is stored on S3. To access, first configure AWS from the command line using `aws configure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTITION = '50'\n",
    "BASE_DIR = 's3://customer-churn-spark/partitions/'\n",
    "PARTITION_DIR = BASE_DIR + 'p' + PARTITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all data\n",
    "members = pd.read_csv(f'{PARTITION_DIR}/members.csv', \n",
    "                      parse_dates=['registration_init_time'], \n",
    "                      infer_datetime_format = True, \n",
    "                      dtype = {'gender': 'category'})\n",
    "\n",
    "trans = pd.read_csv(f'{PARTITION_DIR}/transactions.csv',\n",
    "                   parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                    infer_datetime_format = True)\n",
    "\n",
    "logs = pd.read_csv(f'{PARTITION_DIR}/logs.csv', parse_dates = ['date'])\n",
    "\n",
    "cutoff_times = pd.read_csv(f'{PARTITION_DIR}/cutoff_times.csv', parse_dates = ['cutoff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Entities and EntitySet\n",
    "\n",
    "The first step in using Featuretools is to make an `EntitySet` and add all the `entity`s - tables - to it. An EntitySet is a data structure that holds the tables and the relationships between them. This makes it easier to keep track of all the data in a problem with multiple relational tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "es = ft.EntitySet(id = 'customers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities\n",
    "\n",
    "When creating entities from a dataframe, we need to make sure to include:\n",
    "\n",
    "* The `index` if there is one or a name for the created index. This is a unique identifier for each observation.\n",
    "* `make_index = True` if there is no index, we need to supply a name under `index` and set this to `True`.\n",
    "* A `time_index` if present. This is the time at which the information in the row becomes known.\n",
    "* `variable_types`. In some cases our data will have discrete variables represented as integers which should be specified.\n",
    "\n",
    "For this problem these are the only arguments we'll need\n",
    "\n",
    "#### Members\n",
    "\n",
    "The `members` table holds basic information about each customer. The important point for this table is to specify that the `city` and `registered_via` columns are discrete, categorical variables and not numerical. The `msno` is the unique index identifying each customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8hW4+CV3D1oNM0CIsA39YljsF8M3m7g1LAX6AQd3C8I=</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yhcODfebyTYezE6KAPklcV1us9zdOYJ+7eHS7f/xgoU=</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>2007-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sBlgSL0AIq49XsmBQ2KceKZNUyIxT1BwSkN/xYQLGMc=</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xy3Au8sZKlEeHBQ+C7ro8Ni3X/dxgrtmx0Tt+jqM1zY=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2015-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NiCu2GVWgT5QZbI85oYRBEDqHUZbzz2azS48jvM+khg=</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd gender  \\\n",
       "0  8hW4+CV3D1oNM0CIsA39YljsF8M3m7g1LAX6AQd3C8I=     4  24   male   \n",
       "1  yhcODfebyTYezE6KAPklcV1us9zdOYJ+7eHS7f/xgoU=     8  37   male   \n",
       "2  sBlgSL0AIq49XsmBQ2KceKZNUyIxT1BwSkN/xYQLGMc=    15  21   male   \n",
       "3  Xy3Au8sZKlEeHBQ+C7ro8Ni3X/dxgrtmx0Tt+jqM1zY=     1   0    NaN   \n",
       "4  NiCu2GVWgT5QZbI85oYRBEDqHUZbzz2azS48jvM+khg=    12  21   male   \n",
       "\n",
       "   registered_via registration_init_time  \n",
       "0               3             2014-11-04  \n",
       "1               9             2007-02-11  \n",
       "2               3             2013-02-08  \n",
       "3               9             2015-02-01  \n",
       "4               3             2015-02-12  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members['msno'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6658, Columns: 6]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create entity from members\n",
    "es.entity_from_dataframe(entity_id='members', dataframe=members,\n",
    "                         index = 'msno', time_index = 'registration_init_time', \n",
    "                         variable_types = {'city': vtypes.Categorical, \n",
    "                                           'registered_via': vtypes.Categorical})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transactions\n",
    "\n",
    "The transactions concern payments made by the customers. Each row records one payment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5F7G3pHKf5ijGQpoKuko0G7Jm3Bde6ktfPKBZySWoDI=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DQMPoCSc6EB39ytgnKCRsUIZnR6ZWSrHeDmX7nbxAKs=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2016-03-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lrais3nsgqYwpfpSoyK3fHuPutf6cloTI5T5dQfs4lA=</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZPOjgxQw1/J7v5xgBJTCLXWuwq5Xmk33nO6AoUO1+mY=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-09-06</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MvR23u4bIiWM+U+VE1Mvw3qqdj/0Ixs1sf7avavjhRs=</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>2016-11-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  5F7G3pHKf5ijGQpoKuko0G7Jm3Bde6ktfPKBZySWoDI=                 41   \n",
       "1  DQMPoCSc6EB39ytgnKCRsUIZnR6ZWSrHeDmX7nbxAKs=                 41   \n",
       "2  Lrais3nsgqYwpfpSoyK3fHuPutf6cloTI5T5dQfs4lA=                 38   \n",
       "3  ZPOjgxQw1/J7v5xgBJTCLXWuwq5Xmk33nO6AoUO1+mY=                 41   \n",
       "4  MvR23u4bIiWM+U+VE1Mvw3qqdj/0Ixs1sf7avavjhRs=                 38   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 30               99                  99              1   \n",
       "1                 30              149                 149              1   \n",
       "2                 30              149                 149              0   \n",
       "3                 30              149                 119              1   \n",
       "4                 30              149                 149              0   \n",
       "\n",
       "  transaction_date membership_expire_date  is_cancel  \n",
       "0       2017-02-10             2017-03-10          0  \n",
       "1       2016-02-01             2016-03-02          0  \n",
       "2       2016-02-23             2016-04-23          0  \n",
       "3       2015-09-06             2016-08-01          0  \n",
       "4       2016-10-28             2016-11-27          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the entity, we can create a few new variables based on domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between listing price and price paid\n",
    "trans['price_difference'] = trans['plan_list_price'] - trans['actual_amount_paid']\n",
    "\n",
    "# Planned price per day\n",
    "trans['planned_daily_price'] = trans['plan_list_price'] / trans['payment_plan_days']\n",
    "\n",
    "# Actual price per day\n",
    "trans['daily_price'] = trans['actual_amount_paid'] / trans['payment_plan_days']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no `index` in this dataframe so we have to specify to make an index and pass in a name. There is a `time_index`, the time of the transaction, which will be critical when filtering data based on cutoff times to make features. Again, we also need to specify several variable types.\n",
    "\n",
    "There is one slight anomaly with the transactions where some membership expire dates are after the transactions date, so we will filter those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = trans[trans['membership_expire_date'] > trans['transaction_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6658, Columns: 6]\n",
       "    transactions [Rows: 22329, Columns: 13]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.entity_from_dataframe(entity_id='transactions', dataframe=trans,\n",
    "                         index = 'transactions_index', make_index = True,\n",
    "                         time_index = 'transaction_date', \n",
    "                         variable_types = {'payment_method_id': vtypes.Categorical, \n",
    "                                           'is_auto_renew': vtypes.Boolean, 'is_cancel': vtypes.Boolean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs\n",
    "\n",
    "The `logs` contain user listening behavior. As before we'll make a few domain knowledge columns before adding to the `EntitySet`. There is a again a `time_index` although no `index` present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6+/V1NwBbqjBOCvRSDueeJZ58F4DY7h7fG6fSZtHaAE=</td>\n",
       "      <td>2017-03-04</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>111</td>\n",
       "      <td>79</td>\n",
       "      <td>34727.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E2aBGFTKR6jzp+1knh7JOOF39gLuu+CoZMWaAL/DA0M=</td>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>173</td>\n",
       "      <td>33408.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g7exJzakJlHXwzUydnShY5w24WXSwJyS6QqgoFeyr7g=</td>\n",
       "      <td>2017-03-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>4951.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X+i9OmM3P42cETt5gPkOnz8vXGViQL5/M/NMiMQ+Olc=</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>8755.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tbl8blAVl6j4A8zW1Gnyg78Hc0LAQzzcYesmzgJ7ofs=</td>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1035.853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno       date  num_25  num_50  \\\n",
       "0  6+/V1NwBbqjBOCvRSDueeJZ58F4DY7h7fG6fSZtHaAE= 2017-03-04      29      28   \n",
       "1  E2aBGFTKR6jzp+1knh7JOOF39gLuu+CoZMWaAL/DA0M= 2017-03-27       1       0   \n",
       "2  g7exJzakJlHXwzUydnShY5w24WXSwJyS6QqgoFeyr7g= 2017-03-15       0       0   \n",
       "3  X+i9OmM3P42cETt5gPkOnz8vXGViQL5/M/NMiMQ+Olc= 2017-03-13       3       1   \n",
       "4  tbl8blAVl6j4A8zW1Gnyg78Hc0LAQzzcYesmzgJ7ofs= 2017-03-27       6       5   \n",
       "\n",
       "   num_75  num_985  num_100  num_unq  total_secs  \n",
       "0      18       11      111       79   34727.142  \n",
       "1       2        0      184      173   33408.719  \n",
       "2       0        0       21       21    4951.000  \n",
       "3       0        0       33       27    8755.599  \n",
       "4       0        0        2        6    1035.853  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a few features by hand\n",
    "logs['total'] = logs[['num_25', 'num_50', 'num_75', 'num_985', 'num_100']].sum(axis = 1)\n",
    "logs['percent_100'] = logs['num_100'] / logs['total']\n",
    "logs['percent_unique'] = logs['num_unq'] / logs['total']\n",
    "logs['seconds_per_song'] = logs['total_secs'] / logs['total'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6658, Columns: 6]\n",
       "    transactions [Rows: 22329, Columns: 13]\n",
       "    logs [Rows: 424252, Columns: 14]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                         index = 'logs_index', make_index = True,\n",
    "                         time_index = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making features by hand may seem counterintuitive if we are using automated feature engineering, but the benefits of doing this before using Featuretools is that these features can be stacked on top of to build deep features. Automated feature engineering will therefore take our existing hand-built features and extract more value from them by combining them with other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting Values\n",
    "\n",
    "In order to create conditional features, we can set interesting values for existing columns in the data. The following code will be used to build features conditional on the value of `is_cancel` and `is_auto_renew` in the transactions data. The primitives used for the conditional features are specified as `where_primitives` in the call to Deep Feature Synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "es['transactions']['is_cancel'].interesting_values = [0, 1]\n",
    "es['transactions']['is_auto_renew'].interesting_values = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationships\n",
    "\n",
    "The entityset structure for this problem is fairly simple as there are only three entities with two relationships.  `members` is the parent of `logs` and `transactions`. In both relationships, the parent and child variable is `msno`, the customer id.\n",
    "\n",
    "The two relationships are: one linking `members` to `transactions` and one linking `members` to `logs`. The order for relationships in featuretools is parent variable, child variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6658, Columns: 6]\n",
       "    transactions [Rows: 22329, Columns: 13]\n",
       "    logs [Rows: 424252, Columns: 14]\n",
       "  Relationships:\n",
       "    transactions.msno -> members.msno\n",
       "    logs.msno -> members.msno"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationships (parent, child)\n",
    "r_member_transactions = ft.Relationship(es['members']['msno'], es['transactions']['msno'])\n",
    "r_member_logs = ft.Relationship(es['members']['msno'], es['logs']['msno'])\n",
    "\n",
    "es.add_relationships([r_member_transactions, r_member_logs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Feature Synthesis\n",
    "\n",
    "With the entities and relationships fully defined, we are ready to run [Deep Feature Synthesis (DFS)](https://www.featurelabs.com/blog/deep-feature-synthesis/). This process applies feature engineering building blocks called [feature primitives](https://docs.featuretools.com/automated_feature_engineering/primitives.html) to the dataset to build hundreds of features. Feature primitives are basic operations in two categories - transforms and aggregations - that stack to build deep features. \n",
    "\n",
    "The call to `ft.dfs` needs the entityset which holds all the tables and relationships between them, the `target_entity` to make features for, the specific primitives, the maximum stacking of primitives (`max_depth`), the `cutoff_times`, and a number of optional parameters. The `cutoff_times` is a critical piece of any time based machine learning problem. This is the label dataframe that holds the member id, cutoff time, and label associated with each cutoff time. __For each cutoff time, only data from before the cutoff time can be used to build features for that label.__ This is one of the greatest advantages of Featuretools compared to manual feature engineering: __Featuretools automatically filters our data based on the cutoff times to ensure that all the features are valid for machine learning.__\n",
    "\n",
    "To start, we'll use the default aggregation and transformation primitives as well as two `where_primitives` and see how many features this generates. To only generate the definitions of the features, we pass in `features_only = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                      cutoff_time = cutoff_times,\n",
    "                      where_primitives = ['sum', 'mean'],\n",
    "                      max_depth=2, features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will generate 188 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'This will generate {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 0)>,\n",
       " <Feature: MIN(transactions.payment_plan_days)>,\n",
       " <Feature: SUM(transactions.actual_amount_paid)>,\n",
       " <Feature: MAX(logs.num_985)>,\n",
       " <Feature: STD(logs.total_secs)>,\n",
       " <Feature: STD(logs.num_50)>,\n",
       " <Feature: MEAN(transactions.plan_list_price)>,\n",
       " <Feature: SKEW(transactions.planned_daily_price)>,\n",
       " <Feature: MODE(transactions.DAY(membership_expire_date))>,\n",
       " <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 0)>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random; random.seed(42)\n",
    "\n",
    "random.sample(feature_defs, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Featuretools has built almost 200 features automatically for us using the table relationships and feature primitives. If built by hand, each of these features would require minutes of work, totaling many hours to build 188 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Primitives \n",
    "\n",
    "Now we'll do a call to `ft.dfs` specifying the primitives to use. Often, these will depend on the problem and can involve domain knowledge. We can also build our own custom primitives to use on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_time_between</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average time between consecutive events.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average value of a numeric feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Test if all values are 'True'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mode</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the most common element in a categorical feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_most_common</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the N most common elements in a categorical feature.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name         type  \\\n",
       "0  avg_time_between  aggregation   \n",
       "1              mean  aggregation   \n",
       "2               all  aggregation   \n",
       "3              mode  aggregation   \n",
       "4     n_most_common  aggregation   \n",
       "\n",
       "                                                  description  \n",
       "0       Computes the average time between consecutive events.  \n",
       "1            Computes the average value of a numeric feature.  \n",
       "2                              Test if all values are 'True'.  \n",
       "3     Finds the most common element in a categorical feature.  \n",
       "4  Finds the N most common elements in a categorical feature.  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_p = ft.list_primitives()\n",
    "trans_p = all_p.loc[all_p['type'] == 'transform'].copy()\n",
    "agg_p = all_p.loc[all_p['type'] == 'aggregation'].copy()\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "agg_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify aggregation primitives\n",
    "agg_primitives = ['sum', 'time_since_last', 'avg_time_between', 'all', 'mode', 'num_unique', 'min', 'last', \n",
    "                  'mean', 'percent_true', 'max', 'std', 'count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>or</td>\n",
       "      <td>transform</td>\n",
       "      <td>For two boolean values, determine if one value is 'True'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>subtract</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that subtracts two features.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>weekend</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform Datetime feature into the boolean of Weekend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>year</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>month</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the month.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name       type  \\\n",
       "57        or  transform   \n",
       "58  subtract  transform   \n",
       "59   weekend  transform   \n",
       "60      year  transform   \n",
       "61     month  transform   \n",
       "\n",
       "                                                  description  \n",
       "57  For two boolean values, determine if one value is 'True'.  \n",
       "58   Creates a transform feature that subtracts two features.  \n",
       "59    Transform Datetime feature into the boolean of Weekend.  \n",
       "60                Transform a Datetime feature into the year.  \n",
       "61               Transform a Datetime feature into the month.  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_p.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify transformation primitives\n",
    "trans_primitives = ['weekend', 'cum_sum', 'day', 'month', 'diff', 'time_since_previous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where Primitives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where primitives\n",
    "where_primitives = ['sum', 'count', 'mean', 'percent_true', 'all', 'any']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Primitives\n",
    "\n",
    "[Custom primitives](https://docs.featuretools.com/automated_feature_engineering/primitives.html#defining-custom-primitives) are one of the most powerful options in Featuretools. We use custom primitives to write our own functions based on domain knowledge and then pass them to `dfs` like any other primitives. Featuretools will then stack our custom primitives with the other primitives, again, in effect, amplifying our domain knowledge.\n",
    "\n",
    "For this problem, I wrote a custom primitive that calculates the sum of a value in the month prior to the cutoff time. This is actually a primitive I wrote for another problem that I can apply to this problem as well. That's oneof the benefits of feature primitives: they can work for any problem. Writing a custom primitive once will pay off far down the road. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.primitives import make_agg_primitive\n",
    "\n",
    "def total_previous_month_func(numeric, datetime, time):\n",
    "    \"\"\"Return total of `numeric` column in the month prior to `time`.\"\"\"\n",
    "    df = pd.DataFrame({'value': numeric, 'date': datetime})\n",
    "    previous_month = time.month - 1\n",
    "    year = time.year\n",
    "   \n",
    "    # Handle January\n",
    "    if previous_month == 0:\n",
    "        previous_month = 12\n",
    "        year = time.year - 1\n",
    "        \n",
    "    # Filter data and sum up total\n",
    "    df = df[(df['date'].dt.month == previous_month) & (df['date'].dt.year == year)]\n",
    "    total = df['value'].sum()\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2018-01-07 13:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>2018-01-14 02:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2018-01-20 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2018-01-27 05:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-02-02 18:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value                date\n",
       "0     10 2018-01-01 00:00:00\n",
       "1     12 2018-01-07 13:20:00\n",
       "2     14 2018-01-14 02:40:00\n",
       "3     15 2018-01-20 16:00:00\n",
       "4     19 2018-01-27 05:20:00\n",
       "5     22 2018-02-02 18:40:00"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = [10, 12, 14, 15, 19, 22, 9, 8, 8, 11]\n",
    "dates = pd.date_range('2018-01-01', '2018-03-01', periods = len(numeric))\n",
    "pd.DataFrame({'value': numeric, 'date': dates}).head(6)\n",
    "total_previous_month_func(numeric, dates, pd.datetime(2018, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2018-01-12 19:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>2018-01-24 14:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-02-05 09:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-02-17 04:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value                date\n",
       "0     10 2018-01-01 00:00:00\n",
       "1     12 2018-01-12 19:12:00\n",
       "2     14 2018-01-24 14:24:00\n",
       "3      5 2018-02-05 09:36:00\n",
       "4      7 2018-02-17 04:48:00\n",
       "5      8 2018-03-01 00:00:00"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = [10, 12, 14, 5, 7, 8]\n",
    "dates = pd.date_range('2018-01-01', '2018-03-01', periods = len(numeric))\n",
    "pd.DataFrame({'value': numeric, 'date': dates}).head(6)\n",
    "total_previous_month_func(numeric, dates, pd.datetime(2018, 3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to make a function (`total_previous_month`) that calculates the primitive. The second second is to specify the input and output types. This primitive is an aggregation primitive because it takes in multiple numbers and returns a single number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a number and outputs a number\n",
    "total_previous = make_agg_primitive(total_previous_month, input_types = [ft.variable_types.Numeric,\n",
    "                                                                         ft.variable_types.Datetime],\n",
    "                                    return_type = ft.variable_types.Numeric, \n",
    "                                    uses_calc_time = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just have to pass this in as another aggregation primitive for Featuretools to use it in calculations.\n",
    "\n",
    "The second custom primitive finds the time since a previous true value. This is originally intended for the `is_cancel` variable in the `transactions` dataframe, but it can work for any Boolean variable. It simply finds the time between True (1) examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since_true_func(boolean, datetime):\n",
    "    \"\"\"Calculate time since previous true value\"\"\"\n",
    "    \n",
    "    # Handle case with no true values\n",
    "    if np.all(np.array(boolean) == 0):\n",
    "        return [np.nan for _ in range(len(boolean))]\n",
    "    \n",
    "    # Create dataframe sorted from oldest to newest \n",
    "    df = pd.DataFrame({'value': boolean, 'date': datetime}).\\\n",
    "            sort_values('date', ascending = False)\n",
    "    \n",
    "    older_date = None\n",
    "    \n",
    "    # Iterate through each date in reverse order\n",
    "    for date in df.loc[df['value'] == 1, 'date']:\n",
    "        \n",
    "        # If there was no older true value\n",
    "        if older_date == None:\n",
    "            # Subset to times on or after true\n",
    "            times_after_idx = df.loc[df['date'] >= date].index\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Subset to times on or after true but before previous true\n",
    "            times_after_idx = df.loc[(df['date'] >= date) & (df['date'] < older_date)].index\n",
    "        older_date = date\n",
    "        # Calculate time since previous true\n",
    "        df.loc[times_after_idx, 'time_since_previous'] = (df.loc[times_after_idx, 'date'] - date).dt.total_seconds()\n",
    "        \n",
    "    return list(df['time_since_previous'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1960615.384615424,\n",
       " 1568492.3076922882,\n",
       " 1176369.2307694082,\n",
       " 784246.153846272,\n",
       " 392123.076923136,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1568492.3076922882,\n",
       " 1176369.230769152,\n",
       " 784246.153846272,\n",
       " 392123.076923136,\n",
       " 0.0]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booleans = [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1]\n",
    "dates = pd.date_range('2018-01-01', '2018-03-01', periods = len(booleans))\n",
    "\n",
    "time_since_true(booleans, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 2548800.0, 0.0]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booleans = [1, 0, 1]\n",
    "dates = pd.date_range('2018-01-01', '2018-03-01', periods = len(booleans))\n",
    "\n",
    "time_since_true_func(booleans, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booleans = [0, 0]\n",
    "dates = pd.date_range('2018-01-01', '2018-03-01', periods = len(booleans))\n",
    "\n",
    "time_since_true_func(booleans, dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a transformation primitive since it acts on multiple columns in the same table. The return is the same length as the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.primitives import make_trans_primitive\n",
    "\n",
    "time_since_true = make_trans_primitive(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feature Synthesis with Specified Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                      cutoff_time = cutoff_times, \n",
    "                      agg_primitives = agg_primitives,\n",
    "                      trans_primitives = trans_primitives,\n",
    "                      where_primitives = where_primitives,\n",
    "                      max_depth = 2, features_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'This will generate {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Deep Feature Synthesis\n",
    "\n",
    "Once we're happy with the features that will be generated, we can run deep feature synthesis to make the actual features. We need to change `feature_only` to `False` and then we're good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "feature_matrix, feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                                      cutoff_time = cutoff_times, \n",
    "                                      agg_primitives = agg_primitives,\n",
    "                                      trans_primitives = trans_primitives,\n",
    "                                      where_primitives = where_primitives,\n",
    "                                      max_depth = 2, features_only = False,\n",
    "                                      verbose = 1, chunk_size = 100)\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_times['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_matrix = feature_matrix[feature_matrix['label'].notnull()].copy()\n",
    "labels = np.array(feature_matrix.pop('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_matrix = pd.get_dummies(feature_matrix).replace({np.inf: np.nan, -np.inf:np.nan}).fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, labels, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 1000, max_depth = 10)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_test == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(feature_defs, '/data/churn/features.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition to Feature Matrix\n",
    "\n",
    "Now we'll write a function that takes in the partition number and outputs a feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_defs = ft.load_features('/data/churn/features.txt')\n",
    "print(f'There are {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_to_feature_matrix(partition, feature_defs):\n",
    "    \"\"\"Take in a partition number and return a feature matrix\"\"\"\n",
    "    directory = '/data/churn/partitions/p' + PARTITION\n",
    "    \n",
    "    # Read in the data files\n",
    "    members = pd.read_csv(f'{directory}/members.csv', \n",
    "                      parse_dates=['registration_init_time'], \n",
    "                      infer_datetime_format = True, \n",
    "                      dtype = {'gender': 'category'})\n",
    "\n",
    "    trans = pd.read_csv(f'{directory}/transactions.csv',\n",
    "                       parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                        infer_datetime_format = True)\n",
    "\n",
    "    logs = pd.read_csv(f'{directory}/logs.csv', parse_dates = ['date'])\n",
    "    cutoff_times = pd.read_csv(f'{directory}/cutoff_times.csv', parse_dates = ['cutoff'])\n",
    "    cutoff_times = cutoff_times.drop_duplicates()\n",
    "    \n",
    "    # Create empty entityset\n",
    "    es = ft.EntitySet(id = 'customers')\n",
    "\n",
    "    # Add the members parent table\n",
    "    es.entity_from_dataframe(entity_id='members', dataframe=members,\n",
    "                             index = 'msno', time_index = 'registration_init_time', \n",
    "                             variable_types = {'city': vtypes.Categorical, 'bd': vtypes.Categorical,\n",
    "                                               'registered_via': vtypes.Categorical})\n",
    "    # Create new features in transactions\n",
    "    trans['price_difference'] = trans['plan_list_price'] - trans['actual_amount_paid']\n",
    "    trans['planned_daily_price'] = trans['plan_list_price'] / trans['payment_plan_days']\n",
    "    trans['daily_price'] = trans['actual_amount_paid'] / trans['payment_plan_days']\n",
    "\n",
    "    # Add the transactions child table\n",
    "    es.entity_from_dataframe(entity_id='transactions', dataframe=trans,\n",
    "                             index = 'transactions_index', make_index = True,\n",
    "                             time_index = 'transaction_date', \n",
    "                             variable_types = {'payment_method_id': vtypes.Categorical, \n",
    "                                               'is_auto_renew': vtypes.Boolean, 'is_cancel': vtypes.Boolean})\n",
    "\n",
    "    # Add transactions interesting values\n",
    "    es['transactions']['is_cancel'].interesting_values = [0, 1]\n",
    "    es['transactions']['is_auto_renew'].interesting_values = [0, 1]\n",
    "    \n",
    "    # Create new features in logs\n",
    "    logs['total'] = logs[['num_25', 'num_50', 'num_75', 'num_985', 'num_100']].sum(axis = 1)\n",
    "    logs['percent_100'] = logs['num_100'] / logs['total']\n",
    "    logs['percent_unique'] = logs['num_unq'] / logs['total']\n",
    "    \n",
    "    # Add the logs child table\n",
    "    es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                         index = 'logs_index', make_index = True,\n",
    "                         time_index = 'date')\n",
    "\n",
    "    # Add the relationships\n",
    "    r_member_transactions = ft.Relationship(es['members']['msno'], es['transactions']['msno'])\n",
    "    r_member_logs = ft.Relationship(es['members']['msno'], es['logs']['msno'])\n",
    "    es.add_relationships([r_member_transactions, r_member_logs])\n",
    "\n",
    "    # return cutoff_times\n",
    "    \n",
    "    # Calculate and save the feature matrix\n",
    "    feature_matrix = ft.calculate_feature_matrix(entityset=es, features=feature_defs, cutoff_time=cutoff_times)\n",
    "    \n",
    "    feature_matrix.to_csv(f'{directory}/feature_matrix.csv')\n",
    "    \n",
    "    # Report progress every 10th of number of partitions\n",
    "    if (partition % (N_PARTITIONS / 10) == 0):\n",
    "        print(f'{100 * round(partition / N_PARTITIONS)}% complete.')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 1000, 50):\n",
    "    partition_to_feature_matrix(i, feature_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_to_feature_matrix(100, feature_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
