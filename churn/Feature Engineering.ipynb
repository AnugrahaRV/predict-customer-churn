{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Automated Feature Engineering with Featuretools\n",
    "\n",
    "Automated feature engineering allows us to create hundreds or thousands of relevant features from a relational dataset in a few lines of code that can be re-used across problems. Currently, the only option for automated feature engineering using many related tables is Featuretools, an open-source Python library. \n",
    "\n",
    "In this notebook, we'll work with Featuretools to develop an automated feature engineering workflow for a single partition of the customer churn data. After developing a method that works for one partition, we can take this idea and apply it to many partitions in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import featuretools as ft\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "N_PARTITIONS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logs.csv',\n",
       " 'members.csv',\n",
       " 'train.csv',\n",
       " 'cancel_cutoff_times.csv',\n",
       " 'test.csv',\n",
       " 'transactions.csv',\n",
       " 'cutoff_times.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARTITION = '500'\n",
    "directory = '/data/churn/partitions/p' + PARTITION\n",
    "\n",
    "import os\n",
    "os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv(f'{directory}/members.csv', \n",
    "                      parse_dates=['registration_init_time'], \n",
    "                      infer_datetime_format = True, \n",
    "                      dtype = {'gender': 'category'})\n",
    "\n",
    "trans = pd.read_csv(f'{directory}/transactions.csv',\n",
    "                   parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                    infer_datetime_format = True)\n",
    "\n",
    "logs = pd.read_csv(f'{directory}/logs.csv', parse_dates = ['date'])\n",
    "cutoff_times = pd.read_csv(f'{directory}/cutoff_times.csv', parse_dates = ['cutoff'])\n",
    "cutoff_times = cutoff_times.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21856, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_times.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Entities\n",
    "\n",
    "The entityset structure for this problem is fairly simple as there are only three entities.  `members` is the parent with `logs` and `transactions` both children. In both relationships, the parent and child variable is `msno`, the customer id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "es = ft.EntitySet(id = 'customers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IPcy704aIqoa4MY5NBAKhVw1qZCWvQcYICBVMufSbcg=</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N7VphdA9MRD/ojyO/jSWydNrQqfZMe2d1eDl5kwB+vg=</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wnOtVWT2Hi28usrU9Yb0JCdl/TGO48HUfJlgehG0kDw=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEIygRcw0Soz4FguDgJQnSrlHoTYHmlvTcoOLB9dF2Y=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q4k48ZA18embL69OlVhGpT/8sB5nhETBpH5B6Ud+JXI=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-08-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  IPcy704aIqoa4MY5NBAKhVw1qZCWvQcYICBVMufSbcg=     5   0    male   \n",
       "1  N7VphdA9MRD/ojyO/jSWydNrQqfZMe2d1eDl5kwB+vg=     5  17  female   \n",
       "2  wnOtVWT2Hi28usrU9Yb0JCdl/TGO48HUfJlgehG0kDw=     1   0     NaN   \n",
       "3  DEIygRcw0Soz4FguDgJQnSrlHoTYHmlvTcoOLB9dF2Y=     1   0     NaN   \n",
       "4  q4k48ZA18embL69OlVhGpT/8sB5nhETBpH5B6Ud+JXI=     1   0     NaN   \n",
       "\n",
       "   registered_via registration_init_time  \n",
       "0               3             2014-11-02  \n",
       "1               4             2016-12-26  \n",
       "2               4             2017-01-20  \n",
       "3               4             2017-01-21  \n",
       "4               4             2016-08-15  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members['msno'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6684, Columns: 6]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.entity_from_dataframe(entity_id='members', dataframe=members,\n",
    "                         index = 'msno', time_index = 'registration_init_time', \n",
    "                         variable_types = {'city': vtypes.Categorical, 'bd': vtypes.Categorical,\n",
    "                                           'registered_via': vtypes.Categorical})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/4OzeklvQKOIr804cYEbcsy4xbpWHQFF40oeMTMuTak=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1lhQM//dvJCyWLTaCw7x+aDrCFNhNk/8QzlMwiRgB4Y=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bSgrbAUbyZDpkoQgVxeH4dQ7v8yEoucUK0lB0x6F2R0=</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c3HjpBgEcGfa+mkJVtC47gE2CaW+KTBUxijgvrnBUuY=</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vWLvk74sFSINQPmCbcIMqAh1MDdzxroTKIjaxKWEQHA=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>2016-10-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  /4OzeklvQKOIr804cYEbcsy4xbpWHQFF40oeMTMuTak=                 41   \n",
       "1  1lhQM//dvJCyWLTaCw7x+aDrCFNhNk/8QzlMwiRgB4Y=                 41   \n",
       "2  bSgrbAUbyZDpkoQgVxeH4dQ7v8yEoucUK0lB0x6F2R0=                 21   \n",
       "3  c3HjpBgEcGfa+mkJVtC47gE2CaW+KTBUxijgvrnBUuY=                 28   \n",
       "4  vWLvk74sFSINQPmCbcIMqAh1MDdzxroTKIjaxKWEQHA=                 41   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 30              129                 129              1   \n",
       "1                 30              149                 149              1   \n",
       "2                 30              149                 149              1   \n",
       "3                 30              150                 150              0   \n",
       "4                 30               99                  99              1   \n",
       "\n",
       "  transaction_date membership_expire_date  is_cancel  \n",
       "0       2016-02-29             2016-03-31          0  \n",
       "1       2015-12-31             2016-01-31          0  \n",
       "2       2015-12-02             2016-01-08          0  \n",
       "3       2016-07-02             2016-08-01          0  \n",
       "4       2016-09-13             2016-10-13          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['price_difference'] = trans['plan_list_price'] - trans['actual_amount_paid']\n",
    "trans['planned_daily_price'] = trans['plan_list_price'] / trans['payment_plan_days']\n",
    "trans['daily_price'] = trans['actual_amount_paid'] / trans['payment_plan_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6684, Columns: 6]\n",
       "    transactions [Rows: 22859, Columns: 13]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6684, Columns: 6]\n",
       "    transactions [Rows: 22859, Columns: 13]\n",
       "    logs [Rows: 401596, Columns: 10]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.entity_from_dataframe(entity_id='transactions', dataframe=trans,\n",
    "                         index = 'transactions_index', make_index = True,\n",
    "                         time_index = 'transaction_date', \n",
    "                         variable_types = {'payment_method_id': vtypes.Categorical, \n",
    "                                           'is_auto_renew': vtypes.Boolean, 'is_cancel': vtypes.Boolean})\n",
    "\n",
    "es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                         index = 'logs_index', make_index = True,\n",
    "                         time_index = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1T6cC9wlTNDxYh+ikIsljHO3LJ62pdNxeo0uC6b9iUk=</td>\n",
       "      <td>2017-03-17</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>12650.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qbj5QJcK+N/z9h4fR82QYmABCS9g3EIbGijYxqOAw3M=</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>10247.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tk3KXVctKu4yERExEwFvMMOrpU88K083pDNRONhpMzY=</td>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>4565.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q9u6CM2lMNSyc0mHPnH9O/yWvMGqeTcMqBHRnS7s0MI=</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>5523.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a/vnjfU45TFglx+JFOPBWQHOaQdEY/lYUw8cxLurbwA=</td>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>3670.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno       date  num_25  num_50  \\\n",
       "0  1T6cC9wlTNDxYh+ikIsljHO3LJ62pdNxeo0uC6b9iUk= 2017-03-17      17       1   \n",
       "1  Qbj5QJcK+N/z9h4fR82QYmABCS9g3EIbGijYxqOAw3M= 2017-03-01       4       2   \n",
       "2  tk3KXVctKu4yERExEwFvMMOrpU88K083pDNRONhpMzY= 2017-03-30       0       0   \n",
       "3  q9u6CM2lMNSyc0mHPnH9O/yWvMGqeTcMqBHRnS7s0MI= 2017-03-20       0       0   \n",
       "4  a/vnjfU45TFglx+JFOPBWQHOaQdEY/lYUw8cxLurbwA= 2017-03-10       4       1   \n",
       "\n",
       "   num_75  num_985  num_100  num_unq  total_secs  \n",
       "0       1        0       55       51   12650.427  \n",
       "1       2        1       38       46   10247.052  \n",
       "2       0        0       18       18    4565.533  \n",
       "3       0        0       21       21    5523.670  \n",
       "4       1        0       12       11    3670.509  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs['total'] = logs[['num_25', 'num_50', 'num_75', 'num_985', 'num_100']].sum(axis = 1)\n",
    "logs['percent_100'] = logs['num_100'] / logs['total']\n",
    "logs['percent_unique'] = logs['num_unq'] / logs['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6684, Columns: 6]\n",
       "    transactions [Rows: 22859, Columns: 13]\n",
       "    logs [Rows: 401596, Columns: 13]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                         index = 'logs_index', make_index = True,\n",
    "                         time_index = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting Values\n",
    "\n",
    "In order to create conditional features, we can set interesting values for existing columns in the data. The following code will be used to build features conditional on the value of `is_cancel` and `is_auto_renew` in the transactions data. The primitives used for the conditional features are specified as `where_primitives` in the call to Deep Feature Synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "es['transactions']['is_cancel'].interesting_values = [0, 1]\n",
    "es['transactions']['is_auto_renew'].interesting_values = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships\n",
    "\n",
    "There are two relationships: one linking `members` to `transactions` and one linking `members` to `logs`. The order for relationships is parent variable, child variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6684, Columns: 6]\n",
       "    transactions [Rows: 22859, Columns: 13]\n",
       "    logs [Rows: 401596, Columns: 13]\n",
       "  Relationships:\n",
       "    transactions.msno -> members.msno\n",
       "    logs.msno -> members.msno"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_member_transactions = ft.Relationship(es['members']['msno'], es['transactions']['msno'])\n",
    "r_member_logs = ft.Relationship(es['members']['msno'], es['logs']['msno'])\n",
    "\n",
    "es.add_relationships([r_member_transactions, r_member_logs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Feature Synthesis\n",
    "\n",
    "With the entities and relationships fully defined, we are ready to run Deep Feature Synthesis (DFS). To start, we'll use the default aggregation and transformation primitives as well as two `where_primitives` and see how many features this generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                      cutoff_time = cutoff_times,\n",
    "                      where_primitives = ['sum', 'mean'],\n",
    "                      max_depth=2, features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will generate 182 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'This will generate {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Primitives \n",
    "\n",
    "Now we'll do a call to `ft.dfs` specifying the primitives to use. Often, these will depend on the problem and can involve domain knowledge. We can also build our own custom primitives to use on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time_since_last</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Time since last related instance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_time_between</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average time between consecutive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Counts the number of non null values.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Test if all values are 'True'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the number of 'True' values in a boolean.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n_most_common</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the N most common elements in a categori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_unique</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Returns the number of unique categorical varia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>any</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Test if any value is 'True'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>percent_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the percent of 'True' values in a boolea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the maximum non-null value of a numeric ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>last</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Returns the last value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>trend</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates the slope of the linear trend of va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mode</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the most common element in a categorical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the standard deviation of a numeric feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sum</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Sums elements of a numeric or boolean feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>min</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the minimum non-null value of a numeric ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mean</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average value of a numeric feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>skew</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the skewness of a data set.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>median</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the median value of any feature with wel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name         type  \\\n",
       "0    time_since_last  aggregation   \n",
       "1   avg_time_between  aggregation   \n",
       "2              count  aggregation   \n",
       "3                all  aggregation   \n",
       "4           num_true  aggregation   \n",
       "5      n_most_common  aggregation   \n",
       "6         num_unique  aggregation   \n",
       "7                any  aggregation   \n",
       "8       percent_true  aggregation   \n",
       "9                max  aggregation   \n",
       "10              last  aggregation   \n",
       "11             trend  aggregation   \n",
       "12              mode  aggregation   \n",
       "13               std  aggregation   \n",
       "14               sum  aggregation   \n",
       "15               min  aggregation   \n",
       "16              mean  aggregation   \n",
       "17              skew  aggregation   \n",
       "18            median  aggregation   \n",
       "\n",
       "                                          description  \n",
       "0                   Time since last related instance.  \n",
       "1   Computes the average time between consecutive ...  \n",
       "2               Counts the number of non null values.  \n",
       "3                      Test if all values are 'True'.  \n",
       "4     Finds the number of 'True' values in a boolean.  \n",
       "5   Finds the N most common elements in a categori...  \n",
       "6   Returns the number of unique categorical varia...  \n",
       "7                        Test if any value is 'True'.  \n",
       "8   Finds the percent of 'True' values in a boolea...  \n",
       "9   Finds the maximum non-null value of a numeric ...  \n",
       "10                            Returns the last value.  \n",
       "11  Calculates the slope of the linear trend of va...  \n",
       "12  Finds the most common element in a categorical...  \n",
       "13  Finds the standard deviation of a numeric feat...  \n",
       "14     Sums elements of a numeric or boolean feature.  \n",
       "15  Finds the minimum non-null value of a numeric ...  \n",
       "16   Computes the average value of a numeric feature.  \n",
       "17               Computes the skewness of a data set.  \n",
       "18  Finds the median value of any feature with wel...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_p = ft.list_primitives()\n",
    "trans_p = all_p.loc[all_p['type'] == 'transform'].copy()\n",
    "agg_p = all_p.loc[all_p['type'] == 'aggregation'].copy()\n",
    "\n",
    "pd.options.display.max_rows = 50\n",
    "agg_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_primitives = ['sum', 'time_since_last', 'avg_time_between', 'all', 'mode', 'num_unique', 'min', 'last', \n",
    "                  'mean', 'percent_true', 'max', 'std', 'count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cum_mean</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the mean of previous values of an i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>divide</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that divides two f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>not</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, negates th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>week</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>days_since</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, compute th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hours</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>minute</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the minute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>isin</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, checks whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>or</td>\n",
       "      <td>transform</td>\n",
       "      <td>For two boolean values, determine if one value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>subtract</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that subtracts two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>days</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>numwords</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the words in a given string by countin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>weekday</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform Datetime feature into the boolean of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>time_since_previous</td>\n",
       "      <td>transform</td>\n",
       "      <td>Compute the time since the previous instance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>years</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cum_min</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the min of previous values of an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>months</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>longitude</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the second value on the tuple base fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>cum_count</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the number of previous values of an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mod</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that divides two f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>percentile</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, determines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>weeks</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>is_null</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of base feature, return 'True' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>second</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the second.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cum_sum</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the sum of previous values of an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>minutes</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>diff</td>\n",
       "      <td>transform</td>\n",
       "      <td>Compute the difference between the value of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>multiply</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that multplies two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>seconds</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>and</td>\n",
       "      <td>transform</td>\n",
       "      <td>For two boolean values, determine if both valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>add</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that adds two feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>hour</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the hour.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>time_since</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates time since the cutoff time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>day</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>characters</td>\n",
       "      <td>transform</td>\n",
       "      <td>Return the characters in a given string.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>weekend</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform Datetime feature into the boolean of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>absolute</td>\n",
       "      <td>transform</td>\n",
       "      <td>Absolute value of base feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>year</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>haversine</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculate the approximate haversine distance i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>cum_max</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the max of previous values of an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>month</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the month.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>latitude</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the first value of the tuple base feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>negate</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that negates a fea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name       type  \\\n",
       "19             cum_mean  transform   \n",
       "20               divide  transform   \n",
       "21                  not  transform   \n",
       "22                 week  transform   \n",
       "23           days_since  transform   \n",
       "24                hours  transform   \n",
       "25               minute  transform   \n",
       "26                 isin  transform   \n",
       "27                   or  transform   \n",
       "28             subtract  transform   \n",
       "29                 days  transform   \n",
       "30             numwords  transform   \n",
       "31              weekday  transform   \n",
       "32  time_since_previous  transform   \n",
       "33                years  transform   \n",
       "34              cum_min  transform   \n",
       "35               months  transform   \n",
       "36            longitude  transform   \n",
       "37            cum_count  transform   \n",
       "38                  mod  transform   \n",
       "39           percentile  transform   \n",
       "40                weeks  transform   \n",
       "41              is_null  transform   \n",
       "42               second  transform   \n",
       "43              cum_sum  transform   \n",
       "44              minutes  transform   \n",
       "45                 diff  transform   \n",
       "46             multiply  transform   \n",
       "47              seconds  transform   \n",
       "48                  and  transform   \n",
       "49                  add  transform   \n",
       "50                 hour  transform   \n",
       "51           time_since  transform   \n",
       "52                  day  transform   \n",
       "53           characters  transform   \n",
       "54              weekend  transform   \n",
       "55             absolute  transform   \n",
       "56                 year  transform   \n",
       "57            haversine  transform   \n",
       "58              cum_max  transform   \n",
       "59                month  transform   \n",
       "60             latitude  transform   \n",
       "61               negate  transform   \n",
       "\n",
       "                                          description  \n",
       "19  Calculates the mean of previous values of an i...  \n",
       "20  Creates a transform feature that divides two f...  \n",
       "21  For each value of the base feature, negates th...  \n",
       "22        Transform a Datetime feature into the week.  \n",
       "23  For each value of the base feature, compute th...  \n",
       "24  Transform a Timedelta feature into the number ...  \n",
       "25      Transform a Datetime feature into the minute.  \n",
       "26  For each value of the base feature, checks whe...  \n",
       "27  For two boolean values, determine if one value...  \n",
       "28  Creates a transform feature that subtracts two...  \n",
       "29  Transform a Timedelta feature into the number ...  \n",
       "30  Returns the words in a given string by countin...  \n",
       "31  Transform Datetime feature into the boolean of...  \n",
       "32      Compute the time since the previous instance.  \n",
       "33  Transform a Timedelta feature into the number ...  \n",
       "34  Calculates the min of previous values of an in...  \n",
       "35  Transform a Timedelta feature into the number ...  \n",
       "36  Returns the second value on the tuple base fea...  \n",
       "37  Calculates the number of previous values of an...  \n",
       "38  Creates a transform feature that divides two f...  \n",
       "39  For each value of the base feature, determines...  \n",
       "40  Transform a Timedelta feature into the number ...  \n",
       "41  For each value of base feature, return 'True' ...  \n",
       "42      Transform a Datetime feature into the second.  \n",
       "43  Calculates the sum of previous values of an in...  \n",
       "44  Transform a Timedelta feature into the number ...  \n",
       "45  Compute the difference between the value of a ...  \n",
       "46  Creates a transform feature that multplies two...  \n",
       "47  Transform a Timedelta feature into the number ...  \n",
       "48  For two boolean values, determine if both valu...  \n",
       "49  Creates a transform feature that adds two feat...  \n",
       "50        Transform a Datetime feature into the hour.  \n",
       "51             Calculates time since the cutoff time.  \n",
       "52         Transform a Datetime feature into the day.  \n",
       "53           Return the characters in a given string.  \n",
       "54  Transform Datetime feature into the boolean of...  \n",
       "55                    Absolute value of base feature.  \n",
       "56        Transform a Datetime feature into the year.  \n",
       "57  Calculate the approximate haversine distance i...  \n",
       "58  Calculates the max of previous values of an in...  \n",
       "59       Transform a Datetime feature into the month.  \n",
       "60  Returns the first value of the tuple base feat...  \n",
       "61  Creates a transform feature that negates a fea...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_primitives = ['weekend', 'cum_sum', 'day', 'month', 'diff', 'time_since_previous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where Primitives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_primitives = ['sum', 'count', 'mean', 'percent_true', 'all', 'any']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feature Synthesis with Specified Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                      cutoff_time = cutoff_times, \n",
    "                      agg_primitives = agg_primitives,\n",
    "                      trans_primitives = trans_primitives,\n",
    "                      where_primitives = where_primitives,\n",
    "                      max_depth = 2, features_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will generate 230 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'This will generate {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Deep Feature Synthesis\n",
    "\n",
    "Once we're happy with the features that will be generated, we can run deep feature synthesis to make the actual features. We need to change `feature_only` to `False` and then we're good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 230 features\n",
      "Elapsed: 07:20 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 219/219 chunks\n",
      "442 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "feature_matrix, feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                                      cutoff_time = cutoff_times, \n",
    "                                      agg_primitives = agg_primitives,\n",
    "                                      trans_primitives = trans_primitives,\n",
    "                                      where_primitives = where_primitives,\n",
    "                                      max_depth = 2, features_only = False,\n",
    "                                      verbose = 1, chunk_size = 100)\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>gender</th>\n",
       "      <th>SUM(transactions.payment_plan_days)</th>\n",
       "      <th>SUM(transactions.plan_list_price)</th>\n",
       "      <th>SUM(transactions.actual_amount_paid)</th>\n",
       "      <th>SUM(transactions.price_difference)</th>\n",
       "      <th>SUM(transactions.planned_daily_price)</th>\n",
       "      <th>SUM(transactions.daily_price)</th>\n",
       "      <th>...</th>\n",
       "      <th>WEEKEND(LAST(transactions.transaction_date))</th>\n",
       "      <th>WEEKEND(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>WEEKEND(LAST(logs.date))</th>\n",
       "      <th>DAY(LAST(transactions.transaction_date))</th>\n",
       "      <th>DAY(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>DAY(LAST(logs.date))</th>\n",
       "      <th>MONTH(LAST(transactions.transaction_date))</th>\n",
       "      <th>MONTH(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>MONTH(LAST(logs.date))</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=</th>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>4.806452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              city    bd  registered_via  \\\n",
       "msno                                                                       \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=   5.0   0.0             3.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=   4.0  23.0             9.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=  22.0   0.0             3.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=   5.0   0.0             3.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=  22.0   0.0             9.0   \n",
       "\n",
       "                                             gender  \\\n",
       "msno                                                  \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=    NaN   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=   male   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=   male   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=    NaN   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=    NaN   \n",
       "\n",
       "                                              SUM(transactions.payment_plan_days)  \\\n",
       "msno                                                                                \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                   31   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                   31   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                   31   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                   31   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                   31   \n",
       "\n",
       "                                              SUM(transactions.plan_list_price)  \\\n",
       "msno                                                                              \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                149   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                149   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                149   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                149   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                149   \n",
       "\n",
       "                                              SUM(transactions.actual_amount_paid)  \\\n",
       "msno                                                                                 \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                     0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                   149   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                   149   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                   149   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                   149   \n",
       "\n",
       "                                              SUM(transactions.price_difference)  \\\n",
       "msno                                                                               \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                 149   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                   0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                   0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                   0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                   0   \n",
       "\n",
       "                                              SUM(transactions.planned_daily_price)  \\\n",
       "msno                                                                                  \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                               4.806452   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                               4.806452   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                               4.806452   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                               4.806452   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                               4.806452   \n",
       "\n",
       "                                              SUM(transactions.daily_price)  \\\n",
       "msno                                                                          \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                       0.000000   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                       4.806452   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                       4.806452   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                       4.806452   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                       4.806452   \n",
       "\n",
       "                                              ...    \\\n",
       "msno                                          ...     \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=  ...     \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=  ...     \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=  ...     \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=  ...     \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=  ...     \n",
       "\n",
       "                                              WEEKEND(LAST(transactions.transaction_date))  \\\n",
       "msno                                                                                         \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                           0.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                           0.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                           0.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                           0.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                           0.0   \n",
       "\n",
       "                                              WEEKEND(LAST(transactions.membership_expire_date))  \\\n",
       "msno                                                                                               \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                                1.0    \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                                1.0    \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                                1.0    \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                                1.0    \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                                1.0    \n",
       "\n",
       "                                              WEEKEND(LAST(logs.date))  \\\n",
       "msno                                                                     \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                       0.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                       0.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                       0.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                       0.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                       0.0   \n",
       "\n",
       "                                              DAY(LAST(transactions.transaction_date))  \\\n",
       "msno                                                                                     \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                       1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                       1.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                       1.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                       1.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                       1.0   \n",
       "\n",
       "                                              DAY(LAST(transactions.membership_expire_date))  \\\n",
       "msno                                                                                           \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                            31.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                             1.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                             1.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                             1.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                             1.0   \n",
       "\n",
       "                                              DAY(LAST(logs.date))  \\\n",
       "msno                                                                 \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                   1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                   NaN   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                   1.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                   NaN   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                   NaN   \n",
       "\n",
       "                                              MONTH(LAST(transactions.transaction_date))  \\\n",
       "msno                                                                                       \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                         1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                         1.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                         1.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                         1.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                         1.0   \n",
       "\n",
       "                                              MONTH(LAST(transactions.membership_expire_date))  \\\n",
       "msno                                                                                             \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                                               1.0   \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                                               2.0   \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                                               2.0   \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                                               2.0   \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                                               2.0   \n",
       "\n",
       "                                              MONTH(LAST(logs.date))  label  \n",
       "msno                                                                         \n",
       "+V6OulljdDvq43dsTyzLK6+x7YwZMjfkXwHAWYw0Kds=                     1.0    0.0  \n",
       "10rVobB7ZAi69b7fWLGJMSRUX0b+QZ8kDQRc7J8VEV8=                     NaN    0.0  \n",
       "1uW7L6j+0Hsgn2Khzia/hQQcFyv+ncIcRdJlTy+XmSY=                     1.0    0.0  \n",
       "5Rg2ghHz158LML0RK8cW+EzKvZAYWhzaPxsikIPlAGY=                     NaN    NaN  \n",
       "9TRUYe9vqSq9AZFrtJGF/+RJL57bySU6+Jyyt0o+LVU=                     NaN    0.0  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    18861\n",
       "1.0      603\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_times['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_matrix = feature_matrix[feature_matrix['label'].notnull()].copy()\n",
    "labels = np.array(feature_matrix.pop('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_matrix = pd.get_dummies(feature_matrix).replace({np.inf: np.nan, -np.inf:np.nan}).fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, labels, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9751335799424579"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 1000, max_depth = 10)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689683518290176"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(feature_defs, '/data/churn/features.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition to Feature Matrix\n",
    "\n",
    "Now we'll write a function that takes in the partition number and outputs a feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 230 features.\n"
     ]
    }
   ],
   "source": [
    "feature_defs = ft.load_features('/data/churn/features.txt')\n",
    "print(f'There are {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_to_feature_matrix(partition, feature_defs):\n",
    "    \"\"\"Take in a partition number and return a feature matrix\"\"\"\n",
    "    directory = '/data/churn/partitions/p' + PARTITION\n",
    "    \n",
    "    # Read in the data files\n",
    "    members = pd.read_csv(f'{directory}/members.csv', \n",
    "                      parse_dates=['registration_init_time'], \n",
    "                      infer_datetime_format = True, \n",
    "                      dtype = {'gender': 'category'})\n",
    "\n",
    "    trans = pd.read_csv(f'{directory}/transactions.csv',\n",
    "                       parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                        infer_datetime_format = True)\n",
    "\n",
    "    logs = pd.read_csv(f'{directory}/logs.csv', parse_dates = ['date'])\n",
    "    cutoff_times = pd.read_csv(f'{directory}/cutoff_times.csv', parse_dates = ['cutoff'])\n",
    "    cutoff_times = cutoff_times.drop_duplicates()\n",
    "    \n",
    "    # Create empty entityset\n",
    "    es = ft.EntitySet(id = 'customers')\n",
    "\n",
    "    # Add the members parent table\n",
    "    es.entity_from_dataframe(entity_id='members', dataframe=members,\n",
    "                             index = 'msno', time_index = 'registration_init_time', \n",
    "                             variable_types = {'city': vtypes.Categorical, 'bd': vtypes.Categorical,\n",
    "                                               'registered_via': vtypes.Categorical})\n",
    "    # Create new features in transactions\n",
    "    trans['price_difference'] = trans['plan_list_price'] - trans['actual_amount_paid']\n",
    "    trans['planned_daily_price'] = trans['plan_list_price'] / trans['payment_plan_days']\n",
    "    trans['daily_price'] = trans['actual_amount_paid'] / trans['payment_plan_days']\n",
    "\n",
    "    # Add the transactions child table\n",
    "    es.entity_from_dataframe(entity_id='transactions', dataframe=trans,\n",
    "                             index = 'transactions_index', make_index = True,\n",
    "                             time_index = 'transaction_date', \n",
    "                             variable_types = {'payment_method_id': vtypes.Categorical, \n",
    "                                               'is_auto_renew': vtypes.Boolean, 'is_cancel': vtypes.Boolean})\n",
    "\n",
    "    # Add transactions interesting values\n",
    "    es['transactions']['is_cancel'].interesting_values = [0, 1]\n",
    "    es['transactions']['is_auto_renew'].interesting_values = [0, 1]\n",
    "    \n",
    "    # Create new features in logs\n",
    "    logs['total'] = logs[['num_25', 'num_50', 'num_75', 'num_985', 'num_100']].sum(axis = 1)\n",
    "    logs['percent_100'] = logs['num_100'] / logs['total']\n",
    "    logs['percent_unique'] = logs['num_unq'] / logs['total']\n",
    "    \n",
    "    # Add the logs child table\n",
    "    es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                         index = 'logs_index', make_index = True,\n",
    "                         time_index = 'date')\n",
    "\n",
    "    # Add the relationships\n",
    "    r_member_transactions = ft.Relationship(es['members']['msno'], es['transactions']['msno'])\n",
    "    r_member_logs = ft.Relationship(es['members']['msno'], es['logs']['msno'])\n",
    "    es.add_relationships([r_member_transactions, r_member_logs])\n",
    "\n",
    "    # return cutoff_times\n",
    "    \n",
    "    # Calculate and save the feature matrix\n",
    "    feature_matrix = ft.calculate_feature_matrix(entityset=es, features=feature_defs, cutoff_time=cutoff_times)\n",
    "    \n",
    "    feature_matrix.to_csv(f'{directory}/feature_matrix.csv')\n",
    "    \n",
    "    # Report progress every 10th of number of partitions\n",
    "    if (partition % (N_PARTITIONS / 10) == 0):\n",
    "        print(f'{100 * round(partition / N_PARTITIONS)}% complete.')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% complete.\n",
      "0% complete.\n",
      "0% complete.\n",
      "0% complete.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e54912d38ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpartition_to_feature_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_defs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-0b9d023b1ca7>\u001b[0m in \u001b[0;36mpartition_to_feature_matrix\u001b[0;34m(partition, feature_defs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Calculate and save the feature matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_feature_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentityset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{directory}/feature_matrix.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_feature_matrix\u001b[0;34m(features, entityset, cutoff_time, instance_ids, entities, relationships, cutoff_time_in_index, training_window, approximate, save_progress, verbose, chunk_size, n_jobs, dask_kwargs, profile)\u001b[0m\n\u001b[1;32m    256\u001b[0m                                                  \u001b[0mcutoff_df_time_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_df_time_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                                  \u001b[0mtarget_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                                                  pass_columns=pass_columns)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mlinear_calculate_chunks\u001b[0;34m(chunks, features, approximate, training_window, profile, verbose, save_progress, entityset, no_unapproximated_aggs, cutoff_df_time_var, target_time, pass_columns)\u001b[0m\n\u001b[1;32m    518\u001b[0m                                           \u001b[0mcutoff_df_time_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                                           \u001b[0mtarget_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                                           backend=backend)\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_feature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;31m# Do a manual garbage collection in case objects from calculate_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_chunk\u001b[0;34m(chunk, features, approximate, training_window, profile, verbose, save_progress, no_unapproximated_aggs, cutoff_df_time_var, target_time, pass_columns, backend, entityset)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_feature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                        copy=copy, sort=sort)\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m    422\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 copy=self.copy)\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5420\u001b[0m             b = make_block(\n\u001b[0;32m-> 5421\u001b[0;31m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5422\u001b[0m                 placement=placement)\n\u001b[1;32m   5423\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5577\u001b[0m                 \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5579\u001b[0;31m         \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5581\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36m_concat_compat\u001b[0;34m(to_concat, axis)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_concat_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mextensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_concat_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mextensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1709\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1711\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1712\u001b[0m         \u001b[0marr_or_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr_or_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_typ'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0, 1000, 50):\n",
    "    partition_to_feature_matrix(i, feature_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% complete.\n"
     ]
    }
   ],
   "source": [
    "partition_to_feature_matrix(100, feature_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
