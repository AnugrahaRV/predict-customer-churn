{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Feature Engineering with Spark\n",
    "\n",
    "[Apache Spark](http://spark.apache.org) is a popular framework for distributed computed and large-data processing. It allows us to run computations in parallel either on a single machine, or distributed across a cluster of machines. In this notebook, we will run automated feature engineering in [Featuretools](https://github.com/Featuretools/featuretools) using Spark. \n",
    "\n",
    "We'll skip the Featuretools details in this notebook, but for an introduction see [this article](https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219). For a comparison of manual to automated feature engineering, see [this article](https://towardsdatascience.com/why-automated-feature-engineering-will-change-the-way-you-do-machine-learning-5c15bf188b96). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is initializing Spark. We can use the `findspark` library to make sure that `pyspark` can find Spark in the Jupyter Notebook. This notebook assumes the Spark cluster is already running. To get started with a Spark cluster, refer to [this guide](https://data-flair.training/blogs/install-apache-spark-multi-node-cluster/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "# Initialize with Spark file location\n",
    "findspark.init('/usr/local/spark/')\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Spark \n",
    "\n",
    "A `SparkContext` is the gateway to the running Spark cluster. We can pass in a number of parameters to the `SparkContext` using a `SparkConf` object. Namely, we'll turn on logging, tell Spark to use all cores on our 3 machines, and direct Spark to the location of the master (parent) node. \n",
    "\n",
    "Adjust the parameters depending on your cluster set up. I found [this guide](https://spoddutur.github.io/spark-notes/distribution_of_executors_cores_and_memory_for_spark_application.html) to be helpful in choosing the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('spark.eventLog.enabled', 'True'), ('spark.eventLog.dir', 'tmp/'), ('spark.num.executors', '1'), ('spark.executor.memory', '24g'), ('spark.executor.cores', '8'), ('spark.master', 'spark://ip-172-31-23-133.ec2.internal:7077')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "\n",
    "# Enable logging\n",
    "conf.set('spark.eventLog.enabled', True);\n",
    "conf.set('spark.eventLog.dir', 'tmp/');\n",
    "\n",
    "# Use all cores on all machines\n",
    "conf.set('spark.num.executors', 1)\n",
    "conf.set('spark.executor.memory', '24g')\n",
    "conf.set('spark.executor.cores', 8)\n",
    "\n",
    "# Set the parent\n",
    "conf.set('spark.master', 'spark://ip-172-31-23-133.ec2.internal:7077')\n",
    "conf.getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Spark \n",
    "\n",
    "Before we get to the feature engineering, we want to test if our cluster is running correctly. We'll instantiate a `Spark` cluster and run a simple program that calculates the value of pi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-23-133.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://ip-172-31-23-133.ec2.internal:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pi_calc</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://ip-172-31-23-133.ec2.internal:7077 appName=pi_calc>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = pyspark.SparkContext(appName=\"pi_calc\", \n",
    "                           conf = conf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14187848\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100000000\n",
    "import random\n",
    "\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "\n",
    "# Parallelize counting samples inside circle using Spark\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Dashboards\n",
    "\n",
    "After starting the Spark cluster  from the command line- before running any of the code in the notebook - you can view a dashboard of the cluster at localhost:8080. This shows basic information such as the number of workers and the currently running or completed jobs.\n",
    "\n",
    "Once a `SparkContext` has been initialized, the job can be viewed at localhost:4040. This shows particular details such as the number of tasks completed and the directed acyclic graph of the operation. \n",
    "\n",
    "Using the web dashboard can be a helpful method to help debug your cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are confident the cluster is running correctly, we can move on to feature engineering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Storage\n",
    "\n",
    "All of the reading and writing for running with Spark will happen through S3. The partitioned files are all on s3 and we can use `pandas.read_csv` to read directly from s3. To write to s3, we use the `s3fs` library (shown a little later). \n",
    "\n",
    "### Read in Data from S3\n",
    "\n",
    "Before running this code, make sure to authenticate with Amazon Web Services from the command line to access your files in S3. Run `aws configure` and then input the appropriate information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "BASE_DIR = 's3://customer-churn-spark/'\n",
    "\n",
    "partition = 50\n",
    "directory = BASE_DIR + 'p' + str(partition)\n",
    "cutoff_times_file = 'MS-30_labels.csv'\n",
    "\n",
    "\n",
    "# Read in the data files\n",
    "members = pd.read_csv(f'{directory}/members.csv', \n",
    "                  parse_dates=['registration_init_time'], \n",
    "                  infer_datetime_format = True, \n",
    "                  dtype = {'gender': 'category'})\n",
    "\n",
    "trans = pd.read_csv(f'{directory}/transactions.csv',\n",
    "                   parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                    infer_datetime_format = True)\n",
    "\n",
    "logs = pd.read_csv(f'{directory}/logs.csv', parse_dates = ['date'])\n",
    "\n",
    "cutoff_times = pd.read_csv(f'{directory}/{cutoff_times_file}', parse_dates = ['cutoff_time'])\n",
    "cutoff_times = cutoff_times.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "First we'll make the set of features using a single partiton so we don't have to recalculate them for each partition. (It also is possible to load in calculated features from disk.) Again, I'm skipping the explanation for what is going on here so check out the [Featuretools documentation](https://docs.featuretools.com/) or some of the [online tutorials](https://www.featuretools.com/demos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customers\n",
       "  Entities:\n",
       "    members [Rows: 6658, Columns: 6]\n",
       "    transactions [Rows: 22940, Columns: 13]\n",
       "    logs [Rows: 424252, Columns: 13]\n",
       "  Relationships:\n",
       "    transactions.msno -> members.msno\n",
       "    logs.msno -> members.msno"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty entityset\n",
    "es = ft.EntitySet(id = 'customers')\n",
    "\n",
    "# Add the members parent table\n",
    "es.entity_from_dataframe(entity_id='members', dataframe=members,\n",
    "                         index = 'msno', time_index = 'registration_init_time', \n",
    "                         variable_types = {'city': vtypes.Categorical, 'bd': vtypes.Categorical,\n",
    "                                           'registered_via': vtypes.Categorical})\n",
    "# Create new features in transactions\n",
    "trans['price_difference'] = trans['plan_list_price'] - trans['actual_amount_paid']\n",
    "trans['planned_daily_price'] = trans['plan_list_price'] / trans['payment_plan_days']\n",
    "trans['daily_price'] = trans['actual_amount_paid'] / trans['payment_plan_days']\n",
    "\n",
    "# Add the transactions child table\n",
    "es.entity_from_dataframe(entity_id='transactions', dataframe=trans,\n",
    "                         index = 'transactions_index', make_index = True,\n",
    "                         time_index = 'transaction_date', \n",
    "                         variable_types = {'payment_method_id': vtypes.Categorical, \n",
    "                                           'is_auto_renew': vtypes.Boolean, 'is_cancel': vtypes.Boolean})\n",
    "\n",
    "# Add transactions interesting values\n",
    "es['transactions']['is_cancel'].interesting_values = [0, 1]\n",
    "es['transactions']['is_auto_renew'].interesting_values = [0, 1]\n",
    "\n",
    "# Create new features in logs\n",
    "logs['total'] = logs[['num_25', 'num_50', 'num_75', 'num_985', 'num_100']].sum(axis = 1)\n",
    "logs['percent_100'] = logs['num_100'] / logs['total']\n",
    "logs['percent_unique'] = logs['num_unq'] / logs['total']\n",
    "\n",
    "# Add the logs child table\n",
    "es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                     index = 'logs_index', make_index = True,\n",
    "                     time_index = 'date')\n",
    "\n",
    "# Add the relationships\n",
    "r_member_transactions = ft.Relationship(es['members']['msno'], es['transactions']['msno'])\n",
    "r_member_logs = ft.Relationship(es['members']['msno'], es['logs']['msno'])\n",
    "es.add_relationships([r_member_transactions, r_member_logs])\n",
    "\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Primitives\n",
    "\n",
    "Below are two custom primitives to use with this dataset. Custom primitives allow us to build features using domain knowledge and can be applied to many problems - write them once and then use them multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_previous_month(numeric, datetime, time):\n",
    "    \"\"\"Return total of `numeric` column in the month prior to `time`.\"\"\"\n",
    "    df = pd.DataFrame({'value': numeric, 'date': datetime})\n",
    "    previous_month = time.month - 1\n",
    "    year = time.year\n",
    "   \n",
    "    # Handle January\n",
    "    if previous_month == 0:\n",
    "        previous_month = 12\n",
    "        year = time.year - 1\n",
    "        \n",
    "    # Filter data and sum up total\n",
    "    df = df[(df['date'].dt.month == previous_month) & (df['date'].dt.year == year)]\n",
    "    total = df['value'].sum()\n",
    "    \n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.primitives import make_agg_primitive\n",
    "\n",
    "# Takes in a number and outputs a number\n",
    "total_previous = make_agg_primitive(total_previous_month, input_types = [ft.variable_types.Numeric,\n",
    "                                                                         ft.variable_types.Datetime],\n",
    "                                    return_type = ft.variable_types.Numeric, \n",
    "                                    uses_calc_time = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def time_since_true(boolean, datetime):\n",
    "    \"\"\"Calculate time since previous true value\"\"\"\n",
    "    \n",
    "    if np.any(np.array(list(boolean)) == 1):\n",
    "        # Create dataframe sorted from oldest to newest \n",
    "        df = pd.DataFrame({'value': boolean, 'date': datetime}).\\\n",
    "                sort_values('date', ascending = False).reset_index()\n",
    "\n",
    "        older_date = None\n",
    "\n",
    "        # Iterate through each date in reverse order\n",
    "        for date in df.loc[df['value'] == 1, 'date']:\n",
    "\n",
    "            # If there was no older true value\n",
    "            if older_date == None:\n",
    "                # Subset to times on or after true\n",
    "                times_after_idx = df.loc[df['date'] >= date].index\n",
    "\n",
    "            else:\n",
    "                # Subset to times on or after true but before previous true\n",
    "                times_after_idx = df.loc[(df['date'] >= date) & (df['date'] < older_date)].index\n",
    "            older_date = date\n",
    "            # Calculate time since previous true\n",
    "            df.loc[times_after_idx, 'time_since_previous'] = (df.loc[times_after_idx, 'date'] - date).dt.total_seconds()\n",
    "\n",
    "        return list(df['time_since_previous'])[::-1]\n",
    "    \n",
    "    # Handle case with no true values\n",
    "    else:\n",
    "        return [np.nan for _ in range(len(boolean))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.primitives import make_trans_primitive\n",
    "\n",
    "time_since = make_trans_primitive(time_since_true, input_types = [vtypes.Boolean, vtypes.Datetime],\n",
    "                                  return_type = vtypes.Numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Deep Feature Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time we create the features, we use `ft.dfs` passing in the selected primitives and a few other parameters. We are also using `cutoff_time` which means that the features for every row are filtered based on the time when the label is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 248 features\n",
      "Elapsed: 15:13 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 29/29 chunks\n"
     ]
    }
   ],
   "source": [
    "# Specify aggregation primitives\n",
    "agg_primitives = ['sum', 'time_since_last', 'avg_time_between', 'all', 'mode', 'num_unique', 'min', 'last', \n",
    "                  'mean', 'percent_true', 'max', 'std', 'count', total_previous]\n",
    "# Specify transformation primitives\n",
    "trans_primitives = ['weekend', 'cum_sum', 'day', 'month', 'diff', 'time_since_previous']\n",
    "\n",
    "# Specify where primitives\n",
    "where_primitives = ['sum', 'mean', 'percent_true', 'all', 'any']\n",
    "\n",
    "# Run deep feature synthesis\n",
    "feature_matrix, feature_defs = ft.dfs(entityset=es, target_entity='members', \n",
    "                                      cutoff_time = cutoff_times, \n",
    "                                      agg_primitives = agg_primitives,\n",
    "                                      trans_primitives = trans_primitives,\n",
    "                                      where_primitives = where_primitives,\n",
    "                                      max_depth = 2, features_only = False,\n",
    "                                      chunk_size = 1000, n_jobs = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features can then be saved on disk. Every time we want to make the same exact features, we can just pass in these into the `ft.calculate_feature_matrix` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(feature_defs, '/data/churn/features.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 248 features.\n"
     ]
    }
   ],
   "source": [
    "feature_defs = ft.load_features('/data/churn/features.txt')\n",
    "print(f'There are {len(feature_defs)} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Feature Matrix to S3 \n",
    "\n",
    "In order to save each feature matrix from a partition, we'll write it to s3. For this we can use the `s3fs` (s3 file system) Python library. We first have to authenticate with aws by loading in the credentials and then we can upload our csv much the same as we would write any csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "# Credentials\n",
    "with open('/data/credentials.txt', 'r') as f:\n",
    "    info = f.read().strip().split(',')\n",
    "    key = info[0]\n",
    "    secret = info[1]\n",
    "\n",
    "fs = s3fs.S3FileSystem(key=key, secret=secret)\n",
    "\n",
    "# S3 directory\n",
    "directory = 's3://customer-churn-spark/p' + str(partition)\n",
    "\n",
    "# Encode in order to write to s3\n",
    "bytes_to_write = feature_matrix.to_csv(None).encode()\n",
    "\n",
    "# Write to s3\n",
    "with fs.open(f'{directory}/MS-30_feature_matrix.csv', 'wb') as f:\n",
    "    f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition to Feature Matrix Function\n",
    "\n",
    "This function:\n",
    "\n",
    "1. Takes in the name of a partition \n",
    "2. Reads the data from s3\n",
    "3. Creates an entityset from the data\n",
    "4. Computes the feature matrix for the partition\n",
    "5. Saves the feature matrix to s3\n",
    "\n",
    "Because all reading and writing happens through S3, we don't have to worry about disc space or about putting a copy of the data on each machine. Instead, we can simply read from and write to the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PARTITIONS = 1000\n",
    "BASE_DIR = 's3://customer-churn-spark/'\n",
    "    \n",
    "def partition_to_feature_matrix(partition, feature_defs, cutoff_time_name):\n",
    "    \"\"\"Take in a partition number, create a feature matrix, and save to Amazon S3\n",
    "    \n",
    "    Params\n",
    "    --------\n",
    "        partition (int): number of partition\n",
    "        feature_defs (list of ft features): features to make for the partition\n",
    "        cutoff_time_name (str): name of cutoff time file\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        None: saves the feature matrix to Amazon S3\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    partition_dir = BASE_DIR + 'p' + str(partition)\n",
    "    \n",
    "    # Read in the data files\n",
    "    members = pd.read_csv(f'{partition_dir}/members.csv', \n",
    "                      parse_dates=['registration_init_time'], \n",
    "                      infer_datetime_format = True, \n",
    "                      dtype = {'gender': 'category'}).drop_duplicates()\n",
    "\n",
    "    trans = pd.read_csv(f'{partition_dir}/transactions.csv',\n",
    "                       parse_dates=['transaction_date',\n",
    "                                    'membership_expire_date'], \n",
    "                        infer_datetime_format = True).drop_duplicates()\n",
    "    \n",
    "    logs = pd.read_csv(f'{partition_dir}/logs.csv', \n",
    "                       parse_dates = ['date']).drop_duplicates()\n",
    "    \n",
    "    # Make sure to drop duplicates\n",
    "    cutoff_times = pd.read_csv(f'{partition_dir}/{cutoff_time_name}', parse_dates = ['cutoff_time'])\n",
    "    cutoff_times = cutoff_times.drop_duplicates()\n",
    "    \n",
    "    # Needed for saving\n",
    "    cutoff_spec = cutoff_time_name.split('_')[0]\n",
    "    \n",
    "    # Create empty entityset\n",
    "    es = ft.EntitySet(id = 'customers')\n",
    "\n",
    "    # Add the members parent table\n",
    "    es.entity_from_dataframe(entity_id='members', dataframe=members,\n",
    "                             index = 'msno', time_index = 'registration_init_time', \n",
    "                             variable_types = {'city': vtypes.Categorical,\n",
    "                                               'registered_via': vtypes.Categorical})\n",
    "    # Create new features in transactions\n",
    "    trans['price_difference'] = trans['plan_list_price'] - trans['actual_amount_paid']\n",
    "    trans['planned_daily_price'] = trans['plan_list_price'] / trans['payment_plan_days']\n",
    "    trans['daily_price'] = trans['actual_amount_paid'] / trans['payment_plan_days']\n",
    "\n",
    "    # Add the transactions child table\n",
    "    es.entity_from_dataframe(entity_id='transactions', dataframe=trans,\n",
    "                             index = 'transactions_index', make_index = True,\n",
    "                             time_index = 'transaction_date', \n",
    "                             variable_types = {'payment_method_id': vtypes.Categorical, \n",
    "                                               'is_auto_renew': vtypes.Boolean, 'is_cancel': vtypes.Boolean})\n",
    "\n",
    "    # Add transactions interesting values\n",
    "    es['transactions']['is_cancel'].interesting_values = [0, 1]\n",
    "    es['transactions']['is_auto_renew'].interesting_values = [0, 1]\n",
    "    \n",
    "    # Create new features in logs\n",
    "    logs['total'] = logs[['num_25', 'num_50', 'num_75', 'num_985', 'num_100']].sum(axis = 1)\n",
    "    logs['percent_100'] = logs['num_100'] / logs['total']\n",
    "    logs['percent_unique'] = logs['num_unq'] / logs['total'] \n",
    "    \n",
    "    # Add the logs child table\n",
    "    es.entity_from_dataframe(entity_id='logs', dataframe=logs,\n",
    "                         index = 'logs_index', make_index = True,\n",
    "                         time_index = 'date')\n",
    "\n",
    "    # Add the relationships\n",
    "    r_member_transactions = ft.Relationship(es['members']['msno'], es['transactions']['msno'])\n",
    "    r_member_logs = ft.Relationship(es['members']['msno'], es['logs']['msno'])\n",
    "    es.add_relationships([r_member_transactions, r_member_logs])\n",
    "    \n",
    "    # Calculate the feature matrix using pre-calculated features\n",
    "    feature_matrix = ft.calculate_feature_matrix(entityset=es, features=feature_defs, \n",
    "                                                 cutoff_time=cutoff_times, cutoff_time_in_index = True,\n",
    "                                                 chunk_size = 1000)\n",
    "    \n",
    "    # Save to Amazon S3\n",
    "    bytes_to_write = feature_matrix.to_csv(None).encode()\n",
    "\n",
    "    with fs.open(f'{partition_dir}/{cutoff_spec}_feature_matrix.csv', 'wb') as f:\n",
    "        f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function\n",
    "\n",
    "Let's give the function a test with 2 different partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "partition_to_feature_matrix(950, feature_defs, 'MS-30_labels.csv')\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "partition_to_feature_matrix(530, feature_defs, 'MS-30_labels.csv')\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>time</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>gender</th>\n",
       "      <th>SUM(logs.num_25)</th>\n",
       "      <th>SUM(logs.num_50)</th>\n",
       "      <th>SUM(logs.num_75)</th>\n",
       "      <th>SUM(logs.num_985)</th>\n",
       "      <th>...</th>\n",
       "      <th>WEEKEND(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>DAY(LAST(logs.date))</th>\n",
       "      <th>DAY(LAST(transactions.transaction_date))</th>\n",
       "      <th>DAY(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>MONTH(LAST(logs.date))</th>\n",
       "      <th>MONTH(LAST(transactions.transaction_date))</th>\n",
       "      <th>MONTH(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>label</th>\n",
       "      <th>days_to_churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+2oyBGdHsUwF9UZQAF6JFSlOwohoHPFriNBUQDzj6xw=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+C8j6Pj/MCr/nAANcuJzta8lCkoZ6oopypdhllkqXlM=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+E+cBkZzqIXPd4L1vLHYO1xxoD6VF7J5mi1Z/GKA9r0=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+O51KSmGMnp+ItBpBgZNBJ94K/e//4fhXGYmxNHvZcg=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+WiZkfIp5sDsf0xZvBnR2j6Kxi1u2k0t0mJBJqhQIJo=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno        time  city    bd  \\\n",
       "0  +2oyBGdHsUwF9UZQAF6JFSlOwohoHPFriNBUQDzj6xw=  2015-01-01  14.0  49.0   \n",
       "1  +C8j6Pj/MCr/nAANcuJzta8lCkoZ6oopypdhllkqXlM=  2015-01-01   4.0  27.0   \n",
       "2  +E+cBkZzqIXPd4L1vLHYO1xxoD6VF7J5mi1Z/GKA9r0=  2015-01-01   1.0   0.0   \n",
       "3  +O51KSmGMnp+ItBpBgZNBJ94K/e//4fhXGYmxNHvZcg=  2015-01-01  13.0  39.0   \n",
       "4  +WiZkfIp5sDsf0xZvBnR2j6Kxi1u2k0t0mJBJqhQIJo=  2015-01-01  13.0  25.0   \n",
       "\n",
       "   registered_via  gender  SUM(logs.num_25)  SUM(logs.num_50)  \\\n",
       "0             9.0    male               0.0               0.0   \n",
       "1             9.0    male               0.0               0.0   \n",
       "2             7.0     NaN               2.0               0.0   \n",
       "3             9.0  female               0.0               0.0   \n",
       "4             9.0    male               8.0               1.0   \n",
       "\n",
       "   SUM(logs.num_75)  SUM(logs.num_985)     ...      \\\n",
       "0               0.0                0.0     ...       \n",
       "1               0.0                0.0     ...       \n",
       "2               0.0                0.0     ...       \n",
       "3               0.0                0.0     ...       \n",
       "4               1.0                0.0     ...       \n",
       "\n",
       "   WEEKEND(LAST(transactions.membership_expire_date))  DAY(LAST(logs.date))  \\\n",
       "0                                                0.0                    NaN   \n",
       "1                                                0.0                    1.0   \n",
       "2                                                0.0                    1.0   \n",
       "3                                                0.0                    NaN   \n",
       "4                                                0.0                    1.0   \n",
       "\n",
       "   DAY(LAST(transactions.transaction_date))  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "   DAY(LAST(transactions.membership_expire_date))  MONTH(LAST(logs.date))  \\\n",
       "0                                             NaN                     NaN   \n",
       "1                                             NaN                     1.0   \n",
       "2                                             NaN                     1.0   \n",
       "3                                             NaN                     NaN   \n",
       "4                                             NaN                     1.0   \n",
       "\n",
       "   MONTH(LAST(transactions.transaction_date))  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "\n",
       "   MONTH(LAST(transactions.membership_expire_date))  label  days_to_churn  \\\n",
       "0                                               NaN    0.0            NaN   \n",
       "1                                               NaN    0.0            NaN   \n",
       "2                                               NaN    0.0            NaN   \n",
       "3                                               NaN    0.0            NaN   \n",
       "4                                               NaN    0.0          441.0   \n",
       "\n",
       "   churn_date  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 253 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = pd.read_csv('s3://customer-churn-spark/p530/MS-30_feature_matrix.csv')\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with Spark\n",
    "\n",
    "The next cell parallelizes the feature engineering calculations using Spark. We want to `map` the partitions to the function and we let Spark divide the work between the executors. At the end of the computation, all of the files will be uploaded to S3 in the correct partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of partitions\n",
    "partitions = list(range(N_PARTITIONS))\n",
    "\n",
    "# Create Spark context\n",
    "sc = pyspark.SparkContext(master = 'spark://ip-172-31-23-133.ec2.internal:7077',\n",
    "                          appName = 'featuretools-1', conf = conf)\n",
    "\n",
    "# Parallelize feature engineering\n",
    "r = sc.parallelize(partitions, numSlices=N_PARTITIONS).\\\n",
    "    map(lambda x: partition_to_feature_matrix(x, feature_defs,\n",
    "                                              'MS-30_labels.csv')).\\\n",
    "    collect()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the run is going on, we can look at the status of the cluster at localhost:8080 and the state of the particular job at localhost:4040. \n",
    "\n",
    "__Here is the overall state of the cluster.__\n",
    "\n",
    "![](../images/spark_cluster2.png)\n",
    "\n",
    "__Here is information about the submitted job.__\n",
    "\n",
    "![](../images/spark_job.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 0.0 failed 4 times, most recent failure: Lost task 3.3 in stage 0.0 (TID 26, 172.31.23.133, executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 443, in info\n    Key=key, **self.req_kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 172, in _call_s3\n    return method(**additional_kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (400) when calling the HeadObject operation: Bad Request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/s3.py\", line 29, in get_filepath_or_buffer\n    filepath_or_buffer = fs.open(_strip_schema(filepath_or_buffer), mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 315, in open\n    s3_additional_kwargs=kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1102, in __init__\n    info = self.info()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1120, in info\n    refresh=refresh, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 455, in info\n    raise FileNotFoundError(path)\nFileNotFoundError: customer-churn-spark/p3/[<Feature: city>, <Feature: bd>, <Feature: registered_via>, <Feature: gender>, <Feature: SUM(logs.num_25)>, <Feature: SUM(logs.num_50)>, <Feature: SUM(logs.num_75)>, <Feature: SUM(logs.num_985)>, <Feature: SUM(logs.num_100)>, <Feature: SUM(logs.num_unq)>, <Feature: SUM(logs.total_secs)>, <Feature: SUM(logs.total)>, <Feature: SUM(logs.percent_100)>, <Feature: SUM(logs.percent_unique)>, <Feature: TIME_SINCE_LAST(logs.date)>, <Feature: AVG_TIME_BETWEEN(logs.date)>, <Feature: MIN(logs.num_25)>, <Feature: MIN(logs.num_50)>, <Feature: MIN(logs.num_75)>, <Feature: MIN(logs.num_985)>, <Feature: MIN(logs.num_100)>, <Feature: MIN(logs.num_unq)>, <Feature: MIN(logs.total_secs)>, <Feature: MIN(logs.total)>, <Feature: MIN(logs.percent_100)>, <Feature: MIN(logs.percent_unique)>, <Feature: LAST(logs.num_25)>, <Feature: LAST(logs.num_50)>, <Feature: LAST(logs.num_75)>, <Feature: LAST(logs.num_985)>, <Feature: LAST(logs.num_100)>, <Feature: LAST(logs.num_unq)>, <Feature: LAST(logs.total_secs)>, <Feature: LAST(logs.total)>, <Feature: LAST(logs.percent_100)>, <Feature: LAST(logs.percent_unique)>, <Feature: MEAN(logs.num_25)>, <Feature: MEAN(logs.num_50)>, <Feature: MEAN(logs.num_75)>, <Feature: MEAN(logs.num_985)>, <Feature: MEAN(logs.num_100)>, <Feature: MEAN(logs.num_unq)>, <Feature: MEAN(logs.total_secs)>, <Feature: MEAN(logs.total)>, <Feature: MEAN(logs.percent_100)>, <Feature: MEAN(logs.percent_unique)>, <Feature: MAX(logs.num_25)>, <Feature: MAX(logs.num_50)>, <Feature: MAX(logs.num_75)>, <Feature: MAX(logs.num_985)>, <Feature: MAX(logs.num_100)>, <Feature: MAX(logs.num_unq)>, <Feature: MAX(logs.total_secs)>, <Feature: MAX(logs.total)>, <Feature: MAX(logs.percent_100)>, <Feature: MAX(logs.percent_unique)>, <Feature: STD(logs.num_25)>, <Feature: STD(logs.num_50)>, <Feature: STD(logs.num_75)>, <Feature: STD(logs.num_985)>, <Feature: STD(logs.num_100)>, <Feature: STD(logs.num_unq)>, <Feature: STD(logs.total_secs)>, <Feature: STD(logs.total)>, <Feature: STD(logs.percent_100)>, <Feature: STD(logs.percent_unique)>, <Feature: COUNT(logs)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_985, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_25, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_50, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_75, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_unq, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_unique, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total_secs, date)>, <Feature: SUM(transactions.payment_plan_days)>, <Feature: SUM(transactions.plan_list_price)>, <Feature: SUM(transactions.actual_amount_paid)>, <Feature: SUM(transactions.price_difference)>, <Feature: SUM(transactions.planned_daily_price)>, <Feature: SUM(transactions.daily_price)>, <Feature: TIME_SINCE_LAST(transactions.transaction_date)>, <Feature: AVG_TIME_BETWEEN(transactions.transaction_date)>, <Feature: ALL(transactions.is_auto_renew)>, <Feature: ALL(transactions.is_cancel)>, <Feature: MODE(transactions.payment_method_id)>, <Feature: NUM_UNIQUE(transactions.payment_method_id)>, <Feature: MIN(transactions.payment_plan_days)>, <Feature: MIN(transactions.plan_list_price)>, <Feature: MIN(transactions.actual_amount_paid)>, <Feature: MIN(transactions.price_difference)>, <Feature: MIN(transactions.planned_daily_price)>, <Feature: MIN(transactions.daily_price)>, <Feature: LAST(transactions.payment_plan_days)>, <Feature: LAST(transactions.plan_list_price)>, <Feature: LAST(transactions.actual_amount_paid)>, <Feature: LAST(transactions.price_difference)>, <Feature: LAST(transactions.planned_daily_price)>, <Feature: LAST(transactions.daily_price)>, <Feature: LAST(transactions.payment_method_id)>, <Feature: LAST(transactions.is_auto_renew)>, <Feature: LAST(transactions.is_cancel)>, <Feature: MEAN(transactions.payment_plan_days)>, <Feature: MEAN(transactions.plan_list_price)>, <Feature: MEAN(transactions.actual_amount_paid)>, <Feature: MEAN(transactions.price_difference)>, <Feature: MEAN(transactions.planned_daily_price)>, <Feature: MEAN(transactions.daily_price)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew)>, <Feature: PERCENT_TRUE(transactions.is_cancel)>, <Feature: MAX(transactions.payment_plan_days)>, <Feature: MAX(transactions.plan_list_price)>, <Feature: MAX(transactions.actual_amount_paid)>, <Feature: MAX(transactions.price_difference)>, <Feature: MAX(transactions.planned_daily_price)>, <Feature: MAX(transactions.daily_price)>, <Feature: STD(transactions.payment_plan_days)>, <Feature: STD(transactions.plan_list_price)>, <Feature: STD(transactions.actual_amount_paid)>, <Feature: STD(transactions.price_difference)>, <Feature: STD(transactions.planned_daily_price)>, <Feature: STD(transactions.daily_price)>, <Feature: COUNT(transactions)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, membership_expire_date)>, <Feature: WEEKEND(registration_init_time)>, <Feature: DAY(registration_init_time)>, <Feature: MONTH(registration_init_time)>, <Feature: ALL(logs.WEEKEND(date))>, <Feature: MODE(logs.DAY(date))>, <Feature: MODE(logs.MONTH(date))>, <Feature: NUM_UNIQUE(logs.DAY(date))>, <Feature: NUM_UNIQUE(logs.MONTH(date))>, <Feature: LAST(logs.WEEKEND(date))>, <Feature: LAST(logs.DAY(date))>, <Feature: LAST(logs.MONTH(date))>, <Feature: PERCENT_TRUE(logs.WEEKEND(date))>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 1)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date))>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date))>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: MODE(transactions.DAY(transaction_date))>, <Feature: MODE(transactions.DAY(membership_expire_date))>, <Feature: MODE(transactions.MONTH(transaction_date))>, <Feature: MODE(transactions.MONTH(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.DAY(transaction_date))>, <Feature: NUM_UNIQUE(transactions.DAY(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(transaction_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(membership_expire_date))>, <Feature: LAST(transactions.WEEKEND(transaction_date))>, <Feature: LAST(transactions.WEEKEND(membership_expire_date))>, <Feature: LAST(transactions.DAY(transaction_date))>, <Feature: LAST(transactions.DAY(membership_expire_date))>, <Feature: LAST(transactions.MONTH(transaction_date))>, <Feature: LAST(transactions.MONTH(membership_expire_date))>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: WEEKEND(LAST(logs.date))>, <Feature: WEEKEND(LAST(transactions.transaction_date))>, <Feature: WEEKEND(LAST(transactions.membership_expire_date))>, <Feature: DAY(LAST(logs.date))>, <Feature: DAY(LAST(transactions.transaction_date))>, <Feature: DAY(LAST(transactions.membership_expire_date))>, <Feature: MONTH(LAST(logs.date))>, <Feature: MONTH(LAST(transactions.transaction_date))>, <Feature: MONTH(LAST(transactions.membership_expire_date))>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 443, in info\n    Key=key, **self.req_kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 172, in _call_s3\n    return method(**additional_kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (400) when calling the HeadObject operation: Bad Request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-20-7a778a1f9132>\", line 10, in <lambda>\n  File \"<ipython-input-15-4d0ab5d27633>\", line 36, in partition_to_feature_matrix\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\", line 678, in parser_f\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\", line 424, in _read\n    filepath_or_buffer, encoding, compression)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\", line 209, in get_filepath_or_buffer\n    mode=mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/s3.py\", line 38, in get_filepath_or_buffer\n    filepath_or_buffer = fs.open(_strip_schema(filepath_or_buffer), mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 315, in open\n    s3_additional_kwargs=kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1102, in __init__\n    info = self.info()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1120, in info\n    refresh=refresh, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 455, in info\n    raise FileNotFoundError(path)\nFileNotFoundError: customer-churn-spark/p3/[<Feature: city>, <Feature: bd>, <Feature: registered_via>, <Feature: gender>, <Feature: SUM(logs.num_25)>, <Feature: SUM(logs.num_50)>, <Feature: SUM(logs.num_75)>, <Feature: SUM(logs.num_985)>, <Feature: SUM(logs.num_100)>, <Feature: SUM(logs.num_unq)>, <Feature: SUM(logs.total_secs)>, <Feature: SUM(logs.total)>, <Feature: SUM(logs.percent_100)>, <Feature: SUM(logs.percent_unique)>, <Feature: TIME_SINCE_LAST(logs.date)>, <Feature: AVG_TIME_BETWEEN(logs.date)>, <Feature: MIN(logs.num_25)>, <Feature: MIN(logs.num_50)>, <Feature: MIN(logs.num_75)>, <Feature: MIN(logs.num_985)>, <Feature: MIN(logs.num_100)>, <Feature: MIN(logs.num_unq)>, <Feature: MIN(logs.total_secs)>, <Feature: MIN(logs.total)>, <Feature: MIN(logs.percent_100)>, <Feature: MIN(logs.percent_unique)>, <Feature: LAST(logs.num_25)>, <Feature: LAST(logs.num_50)>, <Feature: LAST(logs.num_75)>, <Feature: LAST(logs.num_985)>, <Feature: LAST(logs.num_100)>, <Feature: LAST(logs.num_unq)>, <Feature: LAST(logs.total_secs)>, <Feature: LAST(logs.total)>, <Feature: LAST(logs.percent_100)>, <Feature: LAST(logs.percent_unique)>, <Feature: MEAN(logs.num_25)>, <Feature: MEAN(logs.num_50)>, <Feature: MEAN(logs.num_75)>, <Feature: MEAN(logs.num_985)>, <Feature: MEAN(logs.num_100)>, <Feature: MEAN(logs.num_unq)>, <Feature: MEAN(logs.total_secs)>, <Feature: MEAN(logs.total)>, <Feature: MEAN(logs.percent_100)>, <Feature: MEAN(logs.percent_unique)>, <Feature: MAX(logs.num_25)>, <Feature: MAX(logs.num_50)>, <Feature: MAX(logs.num_75)>, <Feature: MAX(logs.num_985)>, <Feature: MAX(logs.num_100)>, <Feature: MAX(logs.num_unq)>, <Feature: MAX(logs.total_secs)>, <Feature: MAX(logs.total)>, <Feature: MAX(logs.percent_100)>, <Feature: MAX(logs.percent_unique)>, <Feature: STD(logs.num_25)>, <Feature: STD(logs.num_50)>, <Feature: STD(logs.num_75)>, <Feature: STD(logs.num_985)>, <Feature: STD(logs.num_100)>, <Feature: STD(logs.num_unq)>, <Feature: STD(logs.total_secs)>, <Feature: STD(logs.total)>, <Feature: STD(logs.percent_100)>, <Feature: STD(logs.percent_unique)>, <Feature: COUNT(logs)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_985, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_25, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_50, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_75, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_unq, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_unique, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total_secs, date)>, <Feature: SUM(transactions.payment_plan_days)>, <Feature: SUM(transactions.plan_list_price)>, <Feature: SUM(transactions.actual_amount_paid)>, <Feature: SUM(transactions.price_difference)>, <Feature: SUM(transactions.planned_daily_price)>, <Feature: SUM(transactions.daily_price)>, <Feature: TIME_SINCE_LAST(transactions.transaction_date)>, <Feature: AVG_TIME_BETWEEN(transactions.transaction_date)>, <Feature: ALL(transactions.is_auto_renew)>, <Feature: ALL(transactions.is_cancel)>, <Feature: MODE(transactions.payment_method_id)>, <Feature: NUM_UNIQUE(transactions.payment_method_id)>, <Feature: MIN(transactions.payment_plan_days)>, <Feature: MIN(transactions.plan_list_price)>, <Feature: MIN(transactions.actual_amount_paid)>, <Feature: MIN(transactions.price_difference)>, <Feature: MIN(transactions.planned_daily_price)>, <Feature: MIN(transactions.daily_price)>, <Feature: LAST(transactions.payment_plan_days)>, <Feature: LAST(transactions.plan_list_price)>, <Feature: LAST(transactions.actual_amount_paid)>, <Feature: LAST(transactions.price_difference)>, <Feature: LAST(transactions.planned_daily_price)>, <Feature: LAST(transactions.daily_price)>, <Feature: LAST(transactions.payment_method_id)>, <Feature: LAST(transactions.is_auto_renew)>, <Feature: LAST(transactions.is_cancel)>, <Feature: MEAN(transactions.payment_plan_days)>, <Feature: MEAN(transactions.plan_list_price)>, <Feature: MEAN(transactions.actual_amount_paid)>, <Feature: MEAN(transactions.price_difference)>, <Feature: MEAN(transactions.planned_daily_price)>, <Feature: MEAN(transactions.daily_price)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew)>, <Feature: PERCENT_TRUE(transactions.is_cancel)>, <Feature: MAX(transactions.payment_plan_days)>, <Feature: MAX(transactions.plan_list_price)>, <Feature: MAX(transactions.actual_amount_paid)>, <Feature: MAX(transactions.price_difference)>, <Feature: MAX(transactions.planned_daily_price)>, <Feature: MAX(transactions.daily_price)>, <Feature: STD(transactions.payment_plan_days)>, <Feature: STD(transactions.plan_list_price)>, <Feature: STD(transactions.actual_amount_paid)>, <Feature: STD(transactions.price_difference)>, <Feature: STD(transactions.planned_daily_price)>, <Feature: STD(transactions.daily_price)>, <Feature: COUNT(transactions)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, membership_expire_date)>, <Feature: WEEKEND(registration_init_time)>, <Feature: DAY(registration_init_time)>, <Feature: MONTH(registration_init_time)>, <Feature: ALL(logs.WEEKEND(date))>, <Feature: MODE(logs.DAY(date))>, <Feature: MODE(logs.MONTH(date))>, <Feature: NUM_UNIQUE(logs.DAY(date))>, <Feature: NUM_UNIQUE(logs.MONTH(date))>, <Feature: LAST(logs.WEEKEND(date))>, <Feature: LAST(logs.DAY(date))>, <Feature: LAST(logs.MONTH(date))>, <Feature: PERCENT_TRUE(logs.WEEKEND(date))>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 1)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date))>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date))>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: MODE(transactions.DAY(transaction_date))>, <Feature: MODE(transactions.DAY(membership_expire_date))>, <Feature: MODE(transactions.MONTH(transaction_date))>, <Feature: MODE(transactions.MONTH(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.DAY(transaction_date))>, <Feature: NUM_UNIQUE(transactions.DAY(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(transaction_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(membership_expire_date))>, <Feature: LAST(transactions.WEEKEND(transaction_date))>, <Feature: LAST(transactions.WEEKEND(membership_expire_date))>, <Feature: LAST(transactions.DAY(transaction_date))>, <Feature: LAST(transactions.DAY(membership_expire_date))>, <Feature: LAST(transactions.MONTH(transaction_date))>, <Feature: LAST(transactions.MONTH(membership_expire_date))>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: WEEKEND(LAST(logs.date))>, <Feature: WEEKEND(LAST(transactions.transaction_date))>, <Feature: WEEKEND(LAST(transactions.membership_expire_date))>, <Feature: DAY(LAST(logs.date))>, <Feature: DAY(LAST(transactions.transaction_date))>, <Feature: DAY(LAST(transactions.membership_expire_date))>, <Feature: MONTH(LAST(logs.date))>, <Feature: MONTH(LAST(transactions.transaction_date))>, <Feature: MONTH(LAST(transactions.membership_expire_date))>]\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:162)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 443, in info\n    Key=key, **self.req_kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 172, in _call_s3\n    return method(**additional_kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (400) when calling the HeadObject operation: Bad Request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/s3.py\", line 29, in get_filepath_or_buffer\n    filepath_or_buffer = fs.open(_strip_schema(filepath_or_buffer), mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 315, in open\n    s3_additional_kwargs=kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1102, in __init__\n    info = self.info()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1120, in info\n    refresh=refresh, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 455, in info\n    raise FileNotFoundError(path)\nFileNotFoundError: customer-churn-spark/p3/[<Feature: city>, <Feature: bd>, <Feature: registered_via>, <Feature: gender>, <Feature: SUM(logs.num_25)>, <Feature: SUM(logs.num_50)>, <Feature: SUM(logs.num_75)>, <Feature: SUM(logs.num_985)>, <Feature: SUM(logs.num_100)>, <Feature: SUM(logs.num_unq)>, <Feature: SUM(logs.total_secs)>, <Feature: SUM(logs.total)>, <Feature: SUM(logs.percent_100)>, <Feature: SUM(logs.percent_unique)>, <Feature: TIME_SINCE_LAST(logs.date)>, <Feature: AVG_TIME_BETWEEN(logs.date)>, <Feature: MIN(logs.num_25)>, <Feature: MIN(logs.num_50)>, <Feature: MIN(logs.num_75)>, <Feature: MIN(logs.num_985)>, <Feature: MIN(logs.num_100)>, <Feature: MIN(logs.num_unq)>, <Feature: MIN(logs.total_secs)>, <Feature: MIN(logs.total)>, <Feature: MIN(logs.percent_100)>, <Feature: MIN(logs.percent_unique)>, <Feature: LAST(logs.num_25)>, <Feature: LAST(logs.num_50)>, <Feature: LAST(logs.num_75)>, <Feature: LAST(logs.num_985)>, <Feature: LAST(logs.num_100)>, <Feature: LAST(logs.num_unq)>, <Feature: LAST(logs.total_secs)>, <Feature: LAST(logs.total)>, <Feature: LAST(logs.percent_100)>, <Feature: LAST(logs.percent_unique)>, <Feature: MEAN(logs.num_25)>, <Feature: MEAN(logs.num_50)>, <Feature: MEAN(logs.num_75)>, <Feature: MEAN(logs.num_985)>, <Feature: MEAN(logs.num_100)>, <Feature: MEAN(logs.num_unq)>, <Feature: MEAN(logs.total_secs)>, <Feature: MEAN(logs.total)>, <Feature: MEAN(logs.percent_100)>, <Feature: MEAN(logs.percent_unique)>, <Feature: MAX(logs.num_25)>, <Feature: MAX(logs.num_50)>, <Feature: MAX(logs.num_75)>, <Feature: MAX(logs.num_985)>, <Feature: MAX(logs.num_100)>, <Feature: MAX(logs.num_unq)>, <Feature: MAX(logs.total_secs)>, <Feature: MAX(logs.total)>, <Feature: MAX(logs.percent_100)>, <Feature: MAX(logs.percent_unique)>, <Feature: STD(logs.num_25)>, <Feature: STD(logs.num_50)>, <Feature: STD(logs.num_75)>, <Feature: STD(logs.num_985)>, <Feature: STD(logs.num_100)>, <Feature: STD(logs.num_unq)>, <Feature: STD(logs.total_secs)>, <Feature: STD(logs.total)>, <Feature: STD(logs.percent_100)>, <Feature: STD(logs.percent_unique)>, <Feature: COUNT(logs)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_985, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_25, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_50, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_75, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_unq, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_unique, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total_secs, date)>, <Feature: SUM(transactions.payment_plan_days)>, <Feature: SUM(transactions.plan_list_price)>, <Feature: SUM(transactions.actual_amount_paid)>, <Feature: SUM(transactions.price_difference)>, <Feature: SUM(transactions.planned_daily_price)>, <Feature: SUM(transactions.daily_price)>, <Feature: TIME_SINCE_LAST(transactions.transaction_date)>, <Feature: AVG_TIME_BETWEEN(transactions.transaction_date)>, <Feature: ALL(transactions.is_auto_renew)>, <Feature: ALL(transactions.is_cancel)>, <Feature: MODE(transactions.payment_method_id)>, <Feature: NUM_UNIQUE(transactions.payment_method_id)>, <Feature: MIN(transactions.payment_plan_days)>, <Feature: MIN(transactions.plan_list_price)>, <Feature: MIN(transactions.actual_amount_paid)>, <Feature: MIN(transactions.price_difference)>, <Feature: MIN(transactions.planned_daily_price)>, <Feature: MIN(transactions.daily_price)>, <Feature: LAST(transactions.payment_plan_days)>, <Feature: LAST(transactions.plan_list_price)>, <Feature: LAST(transactions.actual_amount_paid)>, <Feature: LAST(transactions.price_difference)>, <Feature: LAST(transactions.planned_daily_price)>, <Feature: LAST(transactions.daily_price)>, <Feature: LAST(transactions.payment_method_id)>, <Feature: LAST(transactions.is_auto_renew)>, <Feature: LAST(transactions.is_cancel)>, <Feature: MEAN(transactions.payment_plan_days)>, <Feature: MEAN(transactions.plan_list_price)>, <Feature: MEAN(transactions.actual_amount_paid)>, <Feature: MEAN(transactions.price_difference)>, <Feature: MEAN(transactions.planned_daily_price)>, <Feature: MEAN(transactions.daily_price)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew)>, <Feature: PERCENT_TRUE(transactions.is_cancel)>, <Feature: MAX(transactions.payment_plan_days)>, <Feature: MAX(transactions.plan_list_price)>, <Feature: MAX(transactions.actual_amount_paid)>, <Feature: MAX(transactions.price_difference)>, <Feature: MAX(transactions.planned_daily_price)>, <Feature: MAX(transactions.daily_price)>, <Feature: STD(transactions.payment_plan_days)>, <Feature: STD(transactions.plan_list_price)>, <Feature: STD(transactions.actual_amount_paid)>, <Feature: STD(transactions.price_difference)>, <Feature: STD(transactions.planned_daily_price)>, <Feature: STD(transactions.daily_price)>, <Feature: COUNT(transactions)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, membership_expire_date)>, <Feature: WEEKEND(registration_init_time)>, <Feature: DAY(registration_init_time)>, <Feature: MONTH(registration_init_time)>, <Feature: ALL(logs.WEEKEND(date))>, <Feature: MODE(logs.DAY(date))>, <Feature: MODE(logs.MONTH(date))>, <Feature: NUM_UNIQUE(logs.DAY(date))>, <Feature: NUM_UNIQUE(logs.MONTH(date))>, <Feature: LAST(logs.WEEKEND(date))>, <Feature: LAST(logs.DAY(date))>, <Feature: LAST(logs.MONTH(date))>, <Feature: PERCENT_TRUE(logs.WEEKEND(date))>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 1)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date))>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date))>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: MODE(transactions.DAY(transaction_date))>, <Feature: MODE(transactions.DAY(membership_expire_date))>, <Feature: MODE(transactions.MONTH(transaction_date))>, <Feature: MODE(transactions.MONTH(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.DAY(transaction_date))>, <Feature: NUM_UNIQUE(transactions.DAY(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(transaction_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(membership_expire_date))>, <Feature: LAST(transactions.WEEKEND(transaction_date))>, <Feature: LAST(transactions.WEEKEND(membership_expire_date))>, <Feature: LAST(transactions.DAY(transaction_date))>, <Feature: LAST(transactions.DAY(membership_expire_date))>, <Feature: LAST(transactions.MONTH(transaction_date))>, <Feature: LAST(transactions.MONTH(membership_expire_date))>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: WEEKEND(LAST(logs.date))>, <Feature: WEEKEND(LAST(transactions.transaction_date))>, <Feature: WEEKEND(LAST(transactions.membership_expire_date))>, <Feature: DAY(LAST(logs.date))>, <Feature: DAY(LAST(transactions.transaction_date))>, <Feature: DAY(LAST(transactions.membership_expire_date))>, <Feature: MONTH(LAST(logs.date))>, <Feature: MONTH(LAST(transactions.transaction_date))>, <Feature: MONTH(LAST(transactions.membership_expire_date))>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 443, in info\n    Key=key, **self.req_kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 172, in _call_s3\n    return method(**additional_kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (400) when calling the HeadObject operation: Bad Request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-20-7a778a1f9132>\", line 10, in <lambda>\n  File \"<ipython-input-15-4d0ab5d27633>\", line 36, in partition_to_feature_matrix\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\", line 678, in parser_f\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\", line 424, in _read\n    filepath_or_buffer, encoding, compression)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\", line 209, in get_filepath_or_buffer\n    mode=mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/s3.py\", line 38, in get_filepath_or_buffer\n    filepath_or_buffer = fs.open(_strip_schema(filepath_or_buffer), mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 315, in open\n    s3_additional_kwargs=kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1102, in __init__\n    info = self.info()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1120, in info\n    refresh=refresh, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 455, in info\n    raise FileNotFoundError(path)\nFileNotFoundError: customer-churn-spark/p3/[<Feature: city>, <Feature: bd>, <Feature: registered_via>, <Feature: gender>, <Feature: SUM(logs.num_25)>, <Feature: SUM(logs.num_50)>, <Feature: SUM(logs.num_75)>, <Feature: SUM(logs.num_985)>, <Feature: SUM(logs.num_100)>, <Feature: SUM(logs.num_unq)>, <Feature: SUM(logs.total_secs)>, <Feature: SUM(logs.total)>, <Feature: SUM(logs.percent_100)>, <Feature: SUM(logs.percent_unique)>, <Feature: TIME_SINCE_LAST(logs.date)>, <Feature: AVG_TIME_BETWEEN(logs.date)>, <Feature: MIN(logs.num_25)>, <Feature: MIN(logs.num_50)>, <Feature: MIN(logs.num_75)>, <Feature: MIN(logs.num_985)>, <Feature: MIN(logs.num_100)>, <Feature: MIN(logs.num_unq)>, <Feature: MIN(logs.total_secs)>, <Feature: MIN(logs.total)>, <Feature: MIN(logs.percent_100)>, <Feature: MIN(logs.percent_unique)>, <Feature: LAST(logs.num_25)>, <Feature: LAST(logs.num_50)>, <Feature: LAST(logs.num_75)>, <Feature: LAST(logs.num_985)>, <Feature: LAST(logs.num_100)>, <Feature: LAST(logs.num_unq)>, <Feature: LAST(logs.total_secs)>, <Feature: LAST(logs.total)>, <Feature: LAST(logs.percent_100)>, <Feature: LAST(logs.percent_unique)>, <Feature: MEAN(logs.num_25)>, <Feature: MEAN(logs.num_50)>, <Feature: MEAN(logs.num_75)>, <Feature: MEAN(logs.num_985)>, <Feature: MEAN(logs.num_100)>, <Feature: MEAN(logs.num_unq)>, <Feature: MEAN(logs.total_secs)>, <Feature: MEAN(logs.total)>, <Feature: MEAN(logs.percent_100)>, <Feature: MEAN(logs.percent_unique)>, <Feature: MAX(logs.num_25)>, <Feature: MAX(logs.num_50)>, <Feature: MAX(logs.num_75)>, <Feature: MAX(logs.num_985)>, <Feature: MAX(logs.num_100)>, <Feature: MAX(logs.num_unq)>, <Feature: MAX(logs.total_secs)>, <Feature: MAX(logs.total)>, <Feature: MAX(logs.percent_100)>, <Feature: MAX(logs.percent_unique)>, <Feature: STD(logs.num_25)>, <Feature: STD(logs.num_50)>, <Feature: STD(logs.num_75)>, <Feature: STD(logs.num_985)>, <Feature: STD(logs.num_100)>, <Feature: STD(logs.num_unq)>, <Feature: STD(logs.total_secs)>, <Feature: STD(logs.total)>, <Feature: STD(logs.percent_100)>, <Feature: STD(logs.percent_unique)>, <Feature: COUNT(logs)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_985, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_25, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_50, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_75, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_unq, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_unique, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total_secs, date)>, <Feature: SUM(transactions.payment_plan_days)>, <Feature: SUM(transactions.plan_list_price)>, <Feature: SUM(transactions.actual_amount_paid)>, <Feature: SUM(transactions.price_difference)>, <Feature: SUM(transactions.planned_daily_price)>, <Feature: SUM(transactions.daily_price)>, <Feature: TIME_SINCE_LAST(transactions.transaction_date)>, <Feature: AVG_TIME_BETWEEN(transactions.transaction_date)>, <Feature: ALL(transactions.is_auto_renew)>, <Feature: ALL(transactions.is_cancel)>, <Feature: MODE(transactions.payment_method_id)>, <Feature: NUM_UNIQUE(transactions.payment_method_id)>, <Feature: MIN(transactions.payment_plan_days)>, <Feature: MIN(transactions.plan_list_price)>, <Feature: MIN(transactions.actual_amount_paid)>, <Feature: MIN(transactions.price_difference)>, <Feature: MIN(transactions.planned_daily_price)>, <Feature: MIN(transactions.daily_price)>, <Feature: LAST(transactions.payment_plan_days)>, <Feature: LAST(transactions.plan_list_price)>, <Feature: LAST(transactions.actual_amount_paid)>, <Feature: LAST(transactions.price_difference)>, <Feature: LAST(transactions.planned_daily_price)>, <Feature: LAST(transactions.daily_price)>, <Feature: LAST(transactions.payment_method_id)>, <Feature: LAST(transactions.is_auto_renew)>, <Feature: LAST(transactions.is_cancel)>, <Feature: MEAN(transactions.payment_plan_days)>, <Feature: MEAN(transactions.plan_list_price)>, <Feature: MEAN(transactions.actual_amount_paid)>, <Feature: MEAN(transactions.price_difference)>, <Feature: MEAN(transactions.planned_daily_price)>, <Feature: MEAN(transactions.daily_price)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew)>, <Feature: PERCENT_TRUE(transactions.is_cancel)>, <Feature: MAX(transactions.payment_plan_days)>, <Feature: MAX(transactions.plan_list_price)>, <Feature: MAX(transactions.actual_amount_paid)>, <Feature: MAX(transactions.price_difference)>, <Feature: MAX(transactions.planned_daily_price)>, <Feature: MAX(transactions.daily_price)>, <Feature: STD(transactions.payment_plan_days)>, <Feature: STD(transactions.plan_list_price)>, <Feature: STD(transactions.actual_amount_paid)>, <Feature: STD(transactions.price_difference)>, <Feature: STD(transactions.planned_daily_price)>, <Feature: STD(transactions.daily_price)>, <Feature: COUNT(transactions)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, membership_expire_date)>, <Feature: WEEKEND(registration_init_time)>, <Feature: DAY(registration_init_time)>, <Feature: MONTH(registration_init_time)>, <Feature: ALL(logs.WEEKEND(date))>, <Feature: MODE(logs.DAY(date))>, <Feature: MODE(logs.MONTH(date))>, <Feature: NUM_UNIQUE(logs.DAY(date))>, <Feature: NUM_UNIQUE(logs.MONTH(date))>, <Feature: LAST(logs.WEEKEND(date))>, <Feature: LAST(logs.DAY(date))>, <Feature: LAST(logs.MONTH(date))>, <Feature: PERCENT_TRUE(logs.WEEKEND(date))>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 1)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date))>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date))>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: MODE(transactions.DAY(transaction_date))>, <Feature: MODE(transactions.DAY(membership_expire_date))>, <Feature: MODE(transactions.MONTH(transaction_date))>, <Feature: MODE(transactions.MONTH(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.DAY(transaction_date))>, <Feature: NUM_UNIQUE(transactions.DAY(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(transaction_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(membership_expire_date))>, <Feature: LAST(transactions.WEEKEND(transaction_date))>, <Feature: LAST(transactions.WEEKEND(membership_expire_date))>, <Feature: LAST(transactions.DAY(transaction_date))>, <Feature: LAST(transactions.DAY(membership_expire_date))>, <Feature: LAST(transactions.MONTH(transaction_date))>, <Feature: LAST(transactions.MONTH(membership_expire_date))>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: WEEKEND(LAST(logs.date))>, <Feature: WEEKEND(LAST(transactions.transaction_date))>, <Feature: WEEKEND(LAST(transactions.membership_expire_date))>, <Feature: DAY(LAST(logs.date))>, <Feature: DAY(LAST(transactions.transaction_date))>, <Feature: DAY(LAST(transactions.membership_expire_date))>, <Feature: MONTH(LAST(logs.date))>, <Feature: MONTH(LAST(transactions.transaction_date))>, <Feature: MONTH(LAST(transactions.membership_expire_date))>]\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7a778a1f9132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Parallelize feature engineering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m r = sc.parallelize(partitions, numSlices=N_PARTITIONS).    map(lambda x: partition_to_feature_matrix(x, 'SMS-14_labels.csv',\n\u001b[0m\u001b[1;32m     10\u001b[0m                                                feature_defs)).collect()\n\u001b[1;32m     11\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m         \"\"\"\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 0.0 failed 4 times, most recent failure: Lost task 3.3 in stage 0.0 (TID 26, 172.31.23.133, executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 443, in info\n    Key=key, **self.req_kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 172, in _call_s3\n    return method(**additional_kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (400) when calling the HeadObject operation: Bad Request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/s3.py\", line 29, in get_filepath_or_buffer\n    filepath_or_buffer = fs.open(_strip_schema(filepath_or_buffer), mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 315, in open\n    s3_additional_kwargs=kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1102, in __init__\n    info = self.info()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1120, in info\n    refresh=refresh, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 455, in info\n    raise FileNotFoundError(path)\nFileNotFoundError: customer-churn-spark/p3/[<Feature: city>, <Feature: bd>, <Feature: registered_via>, <Feature: gender>, <Feature: SUM(logs.num_25)>, <Feature: SUM(logs.num_50)>, <Feature: SUM(logs.num_75)>, <Feature: SUM(logs.num_985)>, <Feature: SUM(logs.num_100)>, <Feature: SUM(logs.num_unq)>, <Feature: SUM(logs.total_secs)>, <Feature: SUM(logs.total)>, <Feature: SUM(logs.percent_100)>, <Feature: SUM(logs.percent_unique)>, <Feature: TIME_SINCE_LAST(logs.date)>, <Feature: AVG_TIME_BETWEEN(logs.date)>, <Feature: MIN(logs.num_25)>, <Feature: MIN(logs.num_50)>, <Feature: MIN(logs.num_75)>, <Feature: MIN(logs.num_985)>, <Feature: MIN(logs.num_100)>, <Feature: MIN(logs.num_unq)>, <Feature: MIN(logs.total_secs)>, <Feature: MIN(logs.total)>, <Feature: MIN(logs.percent_100)>, <Feature: MIN(logs.percent_unique)>, <Feature: LAST(logs.num_25)>, <Feature: LAST(logs.num_50)>, <Feature: LAST(logs.num_75)>, <Feature: LAST(logs.num_985)>, <Feature: LAST(logs.num_100)>, <Feature: LAST(logs.num_unq)>, <Feature: LAST(logs.total_secs)>, <Feature: LAST(logs.total)>, <Feature: LAST(logs.percent_100)>, <Feature: LAST(logs.percent_unique)>, <Feature: MEAN(logs.num_25)>, <Feature: MEAN(logs.num_50)>, <Feature: MEAN(logs.num_75)>, <Feature: MEAN(logs.num_985)>, <Feature: MEAN(logs.num_100)>, <Feature: MEAN(logs.num_unq)>, <Feature: MEAN(logs.total_secs)>, <Feature: MEAN(logs.total)>, <Feature: MEAN(logs.percent_100)>, <Feature: MEAN(logs.percent_unique)>, <Feature: MAX(logs.num_25)>, <Feature: MAX(logs.num_50)>, <Feature: MAX(logs.num_75)>, <Feature: MAX(logs.num_985)>, <Feature: MAX(logs.num_100)>, <Feature: MAX(logs.num_unq)>, <Feature: MAX(logs.total_secs)>, <Feature: MAX(logs.total)>, <Feature: MAX(logs.percent_100)>, <Feature: MAX(logs.percent_unique)>, <Feature: STD(logs.num_25)>, <Feature: STD(logs.num_50)>, <Feature: STD(logs.num_75)>, <Feature: STD(logs.num_985)>, <Feature: STD(logs.num_100)>, <Feature: STD(logs.num_unq)>, <Feature: STD(logs.total_secs)>, <Feature: STD(logs.total)>, <Feature: STD(logs.percent_100)>, <Feature: STD(logs.percent_unique)>, <Feature: COUNT(logs)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_985, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_25, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_50, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_75, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_unq, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_unique, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total_secs, date)>, <Feature: SUM(transactions.payment_plan_days)>, <Feature: SUM(transactions.plan_list_price)>, <Feature: SUM(transactions.actual_amount_paid)>, <Feature: SUM(transactions.price_difference)>, <Feature: SUM(transactions.planned_daily_price)>, <Feature: SUM(transactions.daily_price)>, <Feature: TIME_SINCE_LAST(transactions.transaction_date)>, <Feature: AVG_TIME_BETWEEN(transactions.transaction_date)>, <Feature: ALL(transactions.is_auto_renew)>, <Feature: ALL(transactions.is_cancel)>, <Feature: MODE(transactions.payment_method_id)>, <Feature: NUM_UNIQUE(transactions.payment_method_id)>, <Feature: MIN(transactions.payment_plan_days)>, <Feature: MIN(transactions.plan_list_price)>, <Feature: MIN(transactions.actual_amount_paid)>, <Feature: MIN(transactions.price_difference)>, <Feature: MIN(transactions.planned_daily_price)>, <Feature: MIN(transactions.daily_price)>, <Feature: LAST(transactions.payment_plan_days)>, <Feature: LAST(transactions.plan_list_price)>, <Feature: LAST(transactions.actual_amount_paid)>, <Feature: LAST(transactions.price_difference)>, <Feature: LAST(transactions.planned_daily_price)>, <Feature: LAST(transactions.daily_price)>, <Feature: LAST(transactions.payment_method_id)>, <Feature: LAST(transactions.is_auto_renew)>, <Feature: LAST(transactions.is_cancel)>, <Feature: MEAN(transactions.payment_plan_days)>, <Feature: MEAN(transactions.plan_list_price)>, <Feature: MEAN(transactions.actual_amount_paid)>, <Feature: MEAN(transactions.price_difference)>, <Feature: MEAN(transactions.planned_daily_price)>, <Feature: MEAN(transactions.daily_price)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew)>, <Feature: PERCENT_TRUE(transactions.is_cancel)>, <Feature: MAX(transactions.payment_plan_days)>, <Feature: MAX(transactions.plan_list_price)>, <Feature: MAX(transactions.actual_amount_paid)>, <Feature: MAX(transactions.price_difference)>, <Feature: MAX(transactions.planned_daily_price)>, <Feature: MAX(transactions.daily_price)>, <Feature: STD(transactions.payment_plan_days)>, <Feature: STD(transactions.plan_list_price)>, <Feature: STD(transactions.actual_amount_paid)>, <Feature: STD(transactions.price_difference)>, <Feature: STD(transactions.planned_daily_price)>, <Feature: STD(transactions.daily_price)>, <Feature: COUNT(transactions)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, membership_expire_date)>, <Feature: WEEKEND(registration_init_time)>, <Feature: DAY(registration_init_time)>, <Feature: MONTH(registration_init_time)>, <Feature: ALL(logs.WEEKEND(date))>, <Feature: MODE(logs.DAY(date))>, <Feature: MODE(logs.MONTH(date))>, <Feature: NUM_UNIQUE(logs.DAY(date))>, <Feature: NUM_UNIQUE(logs.MONTH(date))>, <Feature: LAST(logs.WEEKEND(date))>, <Feature: LAST(logs.DAY(date))>, <Feature: LAST(logs.MONTH(date))>, <Feature: PERCENT_TRUE(logs.WEEKEND(date))>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 1)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date))>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date))>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: MODE(transactions.DAY(transaction_date))>, <Feature: MODE(transactions.DAY(membership_expire_date))>, <Feature: MODE(transactions.MONTH(transaction_date))>, <Feature: MODE(transactions.MONTH(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.DAY(transaction_date))>, <Feature: NUM_UNIQUE(transactions.DAY(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(transaction_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(membership_expire_date))>, <Feature: LAST(transactions.WEEKEND(transaction_date))>, <Feature: LAST(transactions.WEEKEND(membership_expire_date))>, <Feature: LAST(transactions.DAY(transaction_date))>, <Feature: LAST(transactions.DAY(membership_expire_date))>, <Feature: LAST(transactions.MONTH(transaction_date))>, <Feature: LAST(transactions.MONTH(membership_expire_date))>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: WEEKEND(LAST(logs.date))>, <Feature: WEEKEND(LAST(transactions.transaction_date))>, <Feature: WEEKEND(LAST(transactions.membership_expire_date))>, <Feature: DAY(LAST(logs.date))>, <Feature: DAY(LAST(transactions.transaction_date))>, <Feature: DAY(LAST(transactions.membership_expire_date))>, <Feature: MONTH(LAST(logs.date))>, <Feature: MONTH(LAST(transactions.transaction_date))>, <Feature: MONTH(LAST(transactions.membership_expire_date))>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 443, in info\n    Key=key, **self.req_kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 172, in _call_s3\n    return method(**additional_kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (400) when calling the HeadObject operation: Bad Request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-20-7a778a1f9132>\", line 10, in <lambda>\n  File \"<ipython-input-15-4d0ab5d27633>\", line 36, in partition_to_feature_matrix\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\", line 678, in parser_f\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\", line 424, in _read\n    filepath_or_buffer, encoding, compression)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\", line 209, in get_filepath_or_buffer\n    mode=mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/s3.py\", line 38, in get_filepath_or_buffer\n    filepath_or_buffer = fs.open(_strip_schema(filepath_or_buffer), mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 315, in open\n    s3_additional_kwargs=kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1102, in __init__\n    info = self.info()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1120, in info\n    refresh=refresh, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 455, in info\n    raise FileNotFoundError(path)\nFileNotFoundError: customer-churn-spark/p3/[<Feature: city>, <Feature: bd>, <Feature: registered_via>, <Feature: gender>, <Feature: SUM(logs.num_25)>, <Feature: SUM(logs.num_50)>, <Feature: SUM(logs.num_75)>, <Feature: SUM(logs.num_985)>, <Feature: SUM(logs.num_100)>, <Feature: SUM(logs.num_unq)>, <Feature: SUM(logs.total_secs)>, <Feature: SUM(logs.total)>, <Feature: SUM(logs.percent_100)>, <Feature: SUM(logs.percent_unique)>, <Feature: TIME_SINCE_LAST(logs.date)>, <Feature: AVG_TIME_BETWEEN(logs.date)>, <Feature: MIN(logs.num_25)>, <Feature: MIN(logs.num_50)>, <Feature: MIN(logs.num_75)>, <Feature: MIN(logs.num_985)>, <Feature: MIN(logs.num_100)>, <Feature: MIN(logs.num_unq)>, <Feature: MIN(logs.total_secs)>, <Feature: MIN(logs.total)>, <Feature: MIN(logs.percent_100)>, <Feature: MIN(logs.percent_unique)>, <Feature: LAST(logs.num_25)>, <Feature: LAST(logs.num_50)>, <Feature: LAST(logs.num_75)>, <Feature: LAST(logs.num_985)>, <Feature: LAST(logs.num_100)>, <Feature: LAST(logs.num_unq)>, <Feature: LAST(logs.total_secs)>, <Feature: LAST(logs.total)>, <Feature: LAST(logs.percent_100)>, <Feature: LAST(logs.percent_unique)>, <Feature: MEAN(logs.num_25)>, <Feature: MEAN(logs.num_50)>, <Feature: MEAN(logs.num_75)>, <Feature: MEAN(logs.num_985)>, <Feature: MEAN(logs.num_100)>, <Feature: MEAN(logs.num_unq)>, <Feature: MEAN(logs.total_secs)>, <Feature: MEAN(logs.total)>, <Feature: MEAN(logs.percent_100)>, <Feature: MEAN(logs.percent_unique)>, <Feature: MAX(logs.num_25)>, <Feature: MAX(logs.num_50)>, <Feature: MAX(logs.num_75)>, <Feature: MAX(logs.num_985)>, <Feature: MAX(logs.num_100)>, <Feature: MAX(logs.num_unq)>, <Feature: MAX(logs.total_secs)>, <Feature: MAX(logs.total)>, <Feature: MAX(logs.percent_100)>, <Feature: MAX(logs.percent_unique)>, <Feature: STD(logs.num_25)>, <Feature: STD(logs.num_50)>, <Feature: STD(logs.num_75)>, <Feature: STD(logs.num_985)>, <Feature: STD(logs.num_100)>, <Feature: STD(logs.num_unq)>, <Feature: STD(logs.total_secs)>, <Feature: STD(logs.total)>, <Feature: STD(logs.percent_100)>, <Feature: STD(logs.percent_unique)>, <Feature: COUNT(logs)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_985, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_25, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_50, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_75, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_unq, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_unique, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total_secs, date)>, <Feature: SUM(transactions.payment_plan_days)>, <Feature: SUM(transactions.plan_list_price)>, <Feature: SUM(transactions.actual_amount_paid)>, <Feature: SUM(transactions.price_difference)>, <Feature: SUM(transactions.planned_daily_price)>, <Feature: SUM(transactions.daily_price)>, <Feature: TIME_SINCE_LAST(transactions.transaction_date)>, <Feature: AVG_TIME_BETWEEN(transactions.transaction_date)>, <Feature: ALL(transactions.is_auto_renew)>, <Feature: ALL(transactions.is_cancel)>, <Feature: MODE(transactions.payment_method_id)>, <Feature: NUM_UNIQUE(transactions.payment_method_id)>, <Feature: MIN(transactions.payment_plan_days)>, <Feature: MIN(transactions.plan_list_price)>, <Feature: MIN(transactions.actual_amount_paid)>, <Feature: MIN(transactions.price_difference)>, <Feature: MIN(transactions.planned_daily_price)>, <Feature: MIN(transactions.daily_price)>, <Feature: LAST(transactions.payment_plan_days)>, <Feature: LAST(transactions.plan_list_price)>, <Feature: LAST(transactions.actual_amount_paid)>, <Feature: LAST(transactions.price_difference)>, <Feature: LAST(transactions.planned_daily_price)>, <Feature: LAST(transactions.daily_price)>, <Feature: LAST(transactions.payment_method_id)>, <Feature: LAST(transactions.is_auto_renew)>, <Feature: LAST(transactions.is_cancel)>, <Feature: MEAN(transactions.payment_plan_days)>, <Feature: MEAN(transactions.plan_list_price)>, <Feature: MEAN(transactions.actual_amount_paid)>, <Feature: MEAN(transactions.price_difference)>, <Feature: MEAN(transactions.planned_daily_price)>, <Feature: MEAN(transactions.daily_price)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew)>, <Feature: PERCENT_TRUE(transactions.is_cancel)>, <Feature: MAX(transactions.payment_plan_days)>, <Feature: MAX(transactions.plan_list_price)>, <Feature: MAX(transactions.actual_amount_paid)>, <Feature: MAX(transactions.price_difference)>, <Feature: MAX(transactions.planned_daily_price)>, <Feature: MAX(transactions.daily_price)>, <Feature: STD(transactions.payment_plan_days)>, <Feature: STD(transactions.plan_list_price)>, <Feature: STD(transactions.actual_amount_paid)>, <Feature: STD(transactions.price_difference)>, <Feature: STD(transactions.planned_daily_price)>, <Feature: STD(transactions.daily_price)>, <Feature: COUNT(transactions)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, membership_expire_date)>, <Feature: WEEKEND(registration_init_time)>, <Feature: DAY(registration_init_time)>, <Feature: MONTH(registration_init_time)>, <Feature: ALL(logs.WEEKEND(date))>, <Feature: MODE(logs.DAY(date))>, <Feature: MODE(logs.MONTH(date))>, <Feature: NUM_UNIQUE(logs.DAY(date))>, <Feature: NUM_UNIQUE(logs.MONTH(date))>, <Feature: LAST(logs.WEEKEND(date))>, <Feature: LAST(logs.DAY(date))>, <Feature: LAST(logs.MONTH(date))>, <Feature: PERCENT_TRUE(logs.WEEKEND(date))>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 1)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date))>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date))>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: MODE(transactions.DAY(transaction_date))>, <Feature: MODE(transactions.DAY(membership_expire_date))>, <Feature: MODE(transactions.MONTH(transaction_date))>, <Feature: MODE(transactions.MONTH(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.DAY(transaction_date))>, <Feature: NUM_UNIQUE(transactions.DAY(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(transaction_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(membership_expire_date))>, <Feature: LAST(transactions.WEEKEND(transaction_date))>, <Feature: LAST(transactions.WEEKEND(membership_expire_date))>, <Feature: LAST(transactions.DAY(transaction_date))>, <Feature: LAST(transactions.DAY(membership_expire_date))>, <Feature: LAST(transactions.MONTH(transaction_date))>, <Feature: LAST(transactions.MONTH(membership_expire_date))>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: WEEKEND(LAST(logs.date))>, <Feature: WEEKEND(LAST(transactions.transaction_date))>, <Feature: WEEKEND(LAST(transactions.membership_expire_date))>, <Feature: DAY(LAST(logs.date))>, <Feature: DAY(LAST(transactions.transaction_date))>, <Feature: DAY(LAST(transactions.membership_expire_date))>, <Feature: MONTH(LAST(logs.date))>, <Feature: MONTH(LAST(transactions.transaction_date))>, <Feature: MONTH(LAST(transactions.membership_expire_date))>]\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:162)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 443, in info\n    Key=key, **self.req_kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 172, in _call_s3\n    return method(**additional_kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (400) when calling the HeadObject operation: Bad Request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/s3.py\", line 29, in get_filepath_or_buffer\n    filepath_or_buffer = fs.open(_strip_schema(filepath_or_buffer), mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 315, in open\n    s3_additional_kwargs=kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1102, in __init__\n    info = self.info()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1120, in info\n    refresh=refresh, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 455, in info\n    raise FileNotFoundError(path)\nFileNotFoundError: customer-churn-spark/p3/[<Feature: city>, <Feature: bd>, <Feature: registered_via>, <Feature: gender>, <Feature: SUM(logs.num_25)>, <Feature: SUM(logs.num_50)>, <Feature: SUM(logs.num_75)>, <Feature: SUM(logs.num_985)>, <Feature: SUM(logs.num_100)>, <Feature: SUM(logs.num_unq)>, <Feature: SUM(logs.total_secs)>, <Feature: SUM(logs.total)>, <Feature: SUM(logs.percent_100)>, <Feature: SUM(logs.percent_unique)>, <Feature: TIME_SINCE_LAST(logs.date)>, <Feature: AVG_TIME_BETWEEN(logs.date)>, <Feature: MIN(logs.num_25)>, <Feature: MIN(logs.num_50)>, <Feature: MIN(logs.num_75)>, <Feature: MIN(logs.num_985)>, <Feature: MIN(logs.num_100)>, <Feature: MIN(logs.num_unq)>, <Feature: MIN(logs.total_secs)>, <Feature: MIN(logs.total)>, <Feature: MIN(logs.percent_100)>, <Feature: MIN(logs.percent_unique)>, <Feature: LAST(logs.num_25)>, <Feature: LAST(logs.num_50)>, <Feature: LAST(logs.num_75)>, <Feature: LAST(logs.num_985)>, <Feature: LAST(logs.num_100)>, <Feature: LAST(logs.num_unq)>, <Feature: LAST(logs.total_secs)>, <Feature: LAST(logs.total)>, <Feature: LAST(logs.percent_100)>, <Feature: LAST(logs.percent_unique)>, <Feature: MEAN(logs.num_25)>, <Feature: MEAN(logs.num_50)>, <Feature: MEAN(logs.num_75)>, <Feature: MEAN(logs.num_985)>, <Feature: MEAN(logs.num_100)>, <Feature: MEAN(logs.num_unq)>, <Feature: MEAN(logs.total_secs)>, <Feature: MEAN(logs.total)>, <Feature: MEAN(logs.percent_100)>, <Feature: MEAN(logs.percent_unique)>, <Feature: MAX(logs.num_25)>, <Feature: MAX(logs.num_50)>, <Feature: MAX(logs.num_75)>, <Feature: MAX(logs.num_985)>, <Feature: MAX(logs.num_100)>, <Feature: MAX(logs.num_unq)>, <Feature: MAX(logs.total_secs)>, <Feature: MAX(logs.total)>, <Feature: MAX(logs.percent_100)>, <Feature: MAX(logs.percent_unique)>, <Feature: STD(logs.num_25)>, <Feature: STD(logs.num_50)>, <Feature: STD(logs.num_75)>, <Feature: STD(logs.num_985)>, <Feature: STD(logs.num_100)>, <Feature: STD(logs.num_unq)>, <Feature: STD(logs.total_secs)>, <Feature: STD(logs.total)>, <Feature: STD(logs.percent_100)>, <Feature: STD(logs.percent_unique)>, <Feature: COUNT(logs)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_985, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_25, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_50, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_75, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_unq, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_unique, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total_secs, date)>, <Feature: SUM(transactions.payment_plan_days)>, <Feature: SUM(transactions.plan_list_price)>, <Feature: SUM(transactions.actual_amount_paid)>, <Feature: SUM(transactions.price_difference)>, <Feature: SUM(transactions.planned_daily_price)>, <Feature: SUM(transactions.daily_price)>, <Feature: TIME_SINCE_LAST(transactions.transaction_date)>, <Feature: AVG_TIME_BETWEEN(transactions.transaction_date)>, <Feature: ALL(transactions.is_auto_renew)>, <Feature: ALL(transactions.is_cancel)>, <Feature: MODE(transactions.payment_method_id)>, <Feature: NUM_UNIQUE(transactions.payment_method_id)>, <Feature: MIN(transactions.payment_plan_days)>, <Feature: MIN(transactions.plan_list_price)>, <Feature: MIN(transactions.actual_amount_paid)>, <Feature: MIN(transactions.price_difference)>, <Feature: MIN(transactions.planned_daily_price)>, <Feature: MIN(transactions.daily_price)>, <Feature: LAST(transactions.payment_plan_days)>, <Feature: LAST(transactions.plan_list_price)>, <Feature: LAST(transactions.actual_amount_paid)>, <Feature: LAST(transactions.price_difference)>, <Feature: LAST(transactions.planned_daily_price)>, <Feature: LAST(transactions.daily_price)>, <Feature: LAST(transactions.payment_method_id)>, <Feature: LAST(transactions.is_auto_renew)>, <Feature: LAST(transactions.is_cancel)>, <Feature: MEAN(transactions.payment_plan_days)>, <Feature: MEAN(transactions.plan_list_price)>, <Feature: MEAN(transactions.actual_amount_paid)>, <Feature: MEAN(transactions.price_difference)>, <Feature: MEAN(transactions.planned_daily_price)>, <Feature: MEAN(transactions.daily_price)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew)>, <Feature: PERCENT_TRUE(transactions.is_cancel)>, <Feature: MAX(transactions.payment_plan_days)>, <Feature: MAX(transactions.plan_list_price)>, <Feature: MAX(transactions.actual_amount_paid)>, <Feature: MAX(transactions.price_difference)>, <Feature: MAX(transactions.planned_daily_price)>, <Feature: MAX(transactions.daily_price)>, <Feature: STD(transactions.payment_plan_days)>, <Feature: STD(transactions.plan_list_price)>, <Feature: STD(transactions.actual_amount_paid)>, <Feature: STD(transactions.price_difference)>, <Feature: STD(transactions.planned_daily_price)>, <Feature: STD(transactions.daily_price)>, <Feature: COUNT(transactions)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, membership_expire_date)>, <Feature: WEEKEND(registration_init_time)>, <Feature: DAY(registration_init_time)>, <Feature: MONTH(registration_init_time)>, <Feature: ALL(logs.WEEKEND(date))>, <Feature: MODE(logs.DAY(date))>, <Feature: MODE(logs.MONTH(date))>, <Feature: NUM_UNIQUE(logs.DAY(date))>, <Feature: NUM_UNIQUE(logs.MONTH(date))>, <Feature: LAST(logs.WEEKEND(date))>, <Feature: LAST(logs.DAY(date))>, <Feature: LAST(logs.MONTH(date))>, <Feature: PERCENT_TRUE(logs.WEEKEND(date))>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 1)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date))>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date))>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: MODE(transactions.DAY(transaction_date))>, <Feature: MODE(transactions.DAY(membership_expire_date))>, <Feature: MODE(transactions.MONTH(transaction_date))>, <Feature: MODE(transactions.MONTH(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.DAY(transaction_date))>, <Feature: NUM_UNIQUE(transactions.DAY(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(transaction_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(membership_expire_date))>, <Feature: LAST(transactions.WEEKEND(transaction_date))>, <Feature: LAST(transactions.WEEKEND(membership_expire_date))>, <Feature: LAST(transactions.DAY(transaction_date))>, <Feature: LAST(transactions.DAY(membership_expire_date))>, <Feature: LAST(transactions.MONTH(transaction_date))>, <Feature: LAST(transactions.MONTH(membership_expire_date))>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: WEEKEND(LAST(logs.date))>, <Feature: WEEKEND(LAST(transactions.transaction_date))>, <Feature: WEEKEND(LAST(transactions.membership_expire_date))>, <Feature: DAY(LAST(logs.date))>, <Feature: DAY(LAST(transactions.transaction_date))>, <Feature: DAY(LAST(transactions.membership_expire_date))>, <Feature: MONTH(LAST(logs.date))>, <Feature: MONTH(LAST(transactions.transaction_date))>, <Feature: MONTH(LAST(transactions.membership_expire_date))>]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 443, in info\n    Key=key, **self.req_kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 172, in _call_s3\n    return method(**additional_kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (400) when calling the HeadObject operation: Bad Request\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-20-7a778a1f9132>\", line 10, in <lambda>\n  File \"<ipython-input-15-4d0ab5d27633>\", line 36, in partition_to_feature_matrix\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\", line 678, in parser_f\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\", line 424, in _read\n    filepath_or_buffer, encoding, compression)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\", line 209, in get_filepath_or_buffer\n    mode=mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/io/s3.py\", line 38, in get_filepath_or_buffer\n    filepath_or_buffer = fs.open(_strip_schema(filepath_or_buffer), mode)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 315, in open\n    s3_additional_kwargs=kw)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1102, in __init__\n    info = self.info()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 1120, in info\n    refresh=refresh, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/s3fs/core.py\", line 455, in info\n    raise FileNotFoundError(path)\nFileNotFoundError: customer-churn-spark/p3/[<Feature: city>, <Feature: bd>, <Feature: registered_via>, <Feature: gender>, <Feature: SUM(logs.num_25)>, <Feature: SUM(logs.num_50)>, <Feature: SUM(logs.num_75)>, <Feature: SUM(logs.num_985)>, <Feature: SUM(logs.num_100)>, <Feature: SUM(logs.num_unq)>, <Feature: SUM(logs.total_secs)>, <Feature: SUM(logs.total)>, <Feature: SUM(logs.percent_100)>, <Feature: SUM(logs.percent_unique)>, <Feature: TIME_SINCE_LAST(logs.date)>, <Feature: AVG_TIME_BETWEEN(logs.date)>, <Feature: MIN(logs.num_25)>, <Feature: MIN(logs.num_50)>, <Feature: MIN(logs.num_75)>, <Feature: MIN(logs.num_985)>, <Feature: MIN(logs.num_100)>, <Feature: MIN(logs.num_unq)>, <Feature: MIN(logs.total_secs)>, <Feature: MIN(logs.total)>, <Feature: MIN(logs.percent_100)>, <Feature: MIN(logs.percent_unique)>, <Feature: LAST(logs.num_25)>, <Feature: LAST(logs.num_50)>, <Feature: LAST(logs.num_75)>, <Feature: LAST(logs.num_985)>, <Feature: LAST(logs.num_100)>, <Feature: LAST(logs.num_unq)>, <Feature: LAST(logs.total_secs)>, <Feature: LAST(logs.total)>, <Feature: LAST(logs.percent_100)>, <Feature: LAST(logs.percent_unique)>, <Feature: MEAN(logs.num_25)>, <Feature: MEAN(logs.num_50)>, <Feature: MEAN(logs.num_75)>, <Feature: MEAN(logs.num_985)>, <Feature: MEAN(logs.num_100)>, <Feature: MEAN(logs.num_unq)>, <Feature: MEAN(logs.total_secs)>, <Feature: MEAN(logs.total)>, <Feature: MEAN(logs.percent_100)>, <Feature: MEAN(logs.percent_unique)>, <Feature: MAX(logs.num_25)>, <Feature: MAX(logs.num_50)>, <Feature: MAX(logs.num_75)>, <Feature: MAX(logs.num_985)>, <Feature: MAX(logs.num_100)>, <Feature: MAX(logs.num_unq)>, <Feature: MAX(logs.total_secs)>, <Feature: MAX(logs.total)>, <Feature: MAX(logs.percent_100)>, <Feature: MAX(logs.percent_unique)>, <Feature: STD(logs.num_25)>, <Feature: STD(logs.num_50)>, <Feature: STD(logs.num_75)>, <Feature: STD(logs.num_985)>, <Feature: STD(logs.num_100)>, <Feature: STD(logs.num_unq)>, <Feature: STD(logs.total_secs)>, <Feature: STD(logs.total)>, <Feature: STD(logs.percent_100)>, <Feature: STD(logs.percent_unique)>, <Feature: COUNT(logs)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_985, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_25, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_50, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_100, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_75, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.num_unq, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.percent_unique, date)>, <Feature: TOTAL_PREVIOUS_MONTH(logs.total_secs, date)>, <Feature: SUM(transactions.payment_plan_days)>, <Feature: SUM(transactions.plan_list_price)>, <Feature: SUM(transactions.actual_amount_paid)>, <Feature: SUM(transactions.price_difference)>, <Feature: SUM(transactions.planned_daily_price)>, <Feature: SUM(transactions.daily_price)>, <Feature: TIME_SINCE_LAST(transactions.transaction_date)>, <Feature: AVG_TIME_BETWEEN(transactions.transaction_date)>, <Feature: ALL(transactions.is_auto_renew)>, <Feature: ALL(transactions.is_cancel)>, <Feature: MODE(transactions.payment_method_id)>, <Feature: NUM_UNIQUE(transactions.payment_method_id)>, <Feature: MIN(transactions.payment_plan_days)>, <Feature: MIN(transactions.plan_list_price)>, <Feature: MIN(transactions.actual_amount_paid)>, <Feature: MIN(transactions.price_difference)>, <Feature: MIN(transactions.planned_daily_price)>, <Feature: MIN(transactions.daily_price)>, <Feature: LAST(transactions.payment_plan_days)>, <Feature: LAST(transactions.plan_list_price)>, <Feature: LAST(transactions.actual_amount_paid)>, <Feature: LAST(transactions.price_difference)>, <Feature: LAST(transactions.planned_daily_price)>, <Feature: LAST(transactions.daily_price)>, <Feature: LAST(transactions.payment_method_id)>, <Feature: LAST(transactions.is_auto_renew)>, <Feature: LAST(transactions.is_cancel)>, <Feature: MEAN(transactions.payment_plan_days)>, <Feature: MEAN(transactions.plan_list_price)>, <Feature: MEAN(transactions.actual_amount_paid)>, <Feature: MEAN(transactions.price_difference)>, <Feature: MEAN(transactions.planned_daily_price)>, <Feature: MEAN(transactions.daily_price)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew)>, <Feature: PERCENT_TRUE(transactions.is_cancel)>, <Feature: MAX(transactions.payment_plan_days)>, <Feature: MAX(transactions.plan_list_price)>, <Feature: MAX(transactions.actual_amount_paid)>, <Feature: MAX(transactions.price_difference)>, <Feature: MAX(transactions.planned_daily_price)>, <Feature: MAX(transactions.daily_price)>, <Feature: STD(transactions.payment_plan_days)>, <Feature: STD(transactions.plan_list_price)>, <Feature: STD(transactions.actual_amount_paid)>, <Feature: STD(transactions.price_difference)>, <Feature: STD(transactions.planned_daily_price)>, <Feature: STD(transactions.daily_price)>, <Feature: COUNT(transactions)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.daily_price, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.payment_plan_days, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.plan_list_price, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, membership_expire_date)>, <Feature: TOTAL_PREVIOUS_MONTH(transactions.price_difference, membership_expire_date)>, <Feature: WEEKEND(registration_init_time)>, <Feature: DAY(registration_init_time)>, <Feature: MONTH(registration_init_time)>, <Feature: ALL(logs.WEEKEND(date))>, <Feature: MODE(logs.DAY(date))>, <Feature: MODE(logs.MONTH(date))>, <Feature: NUM_UNIQUE(logs.DAY(date))>, <Feature: NUM_UNIQUE(logs.MONTH(date))>, <Feature: LAST(logs.WEEKEND(date))>, <Feature: LAST(logs.DAY(date))>, <Feature: LAST(logs.MONTH(date))>, <Feature: PERCENT_TRUE(logs.WEEKEND(date))>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: SUM(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 1)>, <Feature: SUM(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.price_difference WHERE is_cancel = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 1)>, <Feature: SUM(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: SUM(transactions.daily_price WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: ALL(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date))>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date))>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: ALL(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: MODE(transactions.DAY(transaction_date))>, <Feature: MODE(transactions.DAY(membership_expire_date))>, <Feature: MODE(transactions.MONTH(transaction_date))>, <Feature: MODE(transactions.MONTH(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.DAY(transaction_date))>, <Feature: NUM_UNIQUE(transactions.DAY(membership_expire_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(transaction_date))>, <Feature: NUM_UNIQUE(transactions.MONTH(membership_expire_date))>, <Feature: LAST(transactions.WEEKEND(transaction_date))>, <Feature: LAST(transactions.WEEKEND(membership_expire_date))>, <Feature: LAST(transactions.DAY(transaction_date))>, <Feature: LAST(transactions.DAY(membership_expire_date))>, <Feature: LAST(transactions.MONTH(transaction_date))>, <Feature: LAST(transactions.MONTH(membership_expire_date))>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 1)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.payment_plan_days WHERE is_cancel = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.plan_list_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.plan_list_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 1)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.actual_amount_paid WHERE is_cancel = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 1)>, <Feature: MEAN(transactions.price_difference WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.price_difference WHERE is_cancel = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.planned_daily_price WHERE is_cancel = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 1)>, <Feature: MEAN(transactions.daily_price WHERE is_auto_renew = 0)>, <Feature: MEAN(transactions.daily_price WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.is_auto_renew WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.is_cancel WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(transaction_date) WHERE is_cancel = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date))>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 1)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)>, <Feature: PERCENT_TRUE(transactions.WEEKEND(membership_expire_date) WHERE is_cancel = 0)>, <Feature: WEEKEND(LAST(logs.date))>, <Feature: WEEKEND(LAST(transactions.transaction_date))>, <Feature: WEEKEND(LAST(transactions.membership_expire_date))>, <Feature: DAY(LAST(logs.date))>, <Feature: DAY(LAST(transactions.transaction_date))>, <Feature: DAY(LAST(transactions.membership_expire_date))>, <Feature: MONTH(LAST(logs.date))>, <Feature: MONTH(LAST(transactions.transaction_date))>, <Feature: MONTH(LAST(transactions.membership_expire_date))>]\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "# Create list of partitions\n",
    "partitions = list(range(N_PARTITIONS))\n",
    "\n",
    "# Create Spark context\n",
    "sc = pyspark.SparkContext(master = 'spark://ip-172-31-23-133.ec2.internal:7077',\n",
    "                          appName = 'featuretools-2', conf = conf)\n",
    "\n",
    "# Parallelize feature engineering\n",
    "r = sc.parallelize(partitions, numSlices=N_PARTITIONS).\\\n",
    "    map(lambda x: partition_to_feature_matrix(x, 'SMS-14_labels.csv',\n",
    "                                               feature_defs)).collect()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "From here, we could read in all the partitioned feature matrices and build a single feature matrix or if we have a model that supports incremental (also known as on-line) learning, we can train it with one partition at a time. One of the benefits of storing our data on S3 is we can now access it from any machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = pd.read_csv('s3://customer-churn-spark/p50/feature_matrix.csv')\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this notebook, we saw how to distribute feature engineering in Featuretools using the Spark framework. This big-data processing technology lets us use multiple computers to parallelize calculations, resulting in efficient data science workflows even on large datasets. Moreover, we saw how the same partition and distribute approach that worked with Dask can also work with Spark. The nice part about these frameworks is we don't have to change the underlying Featuretools code. We simply write our code in native Python, change the backend running the calculations, and distribute the calculations across a cluster of machines. Using this approach, we'll be able to scale to any size datasets and take on even more exciting data science and machine learning problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
