{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Prediction Engineering - Labeling\n",
    "\n",
    "In this notebook, we will develop a method for labeling customer data for a prediction problem. The objective of labeling is to create a set of historical examples of what we want to predict based on the business need: in this problem, our goal is to predict customer churn, so we want to label examples of churned customers using past data.\n",
    "\n",
    "The end outcome of this notebook is a set of labels along with cutoff times (in a table called a label times table) that can be used in Featuretools for automated feature engineering. These features in turn will be used to train a predictive model to forecast customer churn, a common need for subscription-based business models, and one for which machine learning is well-suited.\n",
    "\n",
    "## Definition of Churn\n",
    "\n",
    "The [data (publicly available)](https://www.kaggle.com/c/kkbox-churn-prediction-challenge/data) consists of customer transaction records showing membership to KKBOX, a music streaming service. The definition of churn is __a customer going without an active membership for a certain number of days.__ The number of days and when to make predictions are left as parameters that can be adjusted based on the particular business need. For example, we can say that churn is no active membership for 30 days and make predictions on the first of each month or 14 days and make predictions on the first and the fifteenth of the month. \n",
    "\n",
    "### Dataset\n",
    "\n",
    "For each customer, we have background information (in `members`), logs of listening behavior (in `logs`), and transactions information (in `trans`). The only data we need for labeling is the transactions information.\n",
    "\n",
    "The transactions data consists of a number of variables, the most important of which are customer id (`msno`), the date of transaction (`transaction_date`), and the expiration date of the membership (`membership_expire_date`). Using these columns, we can find each churn for each customer and the corresponding date on which it occurred. Let's look at a few typical examples of customer transaction data to illustrate how to find a churn example. For these examples, we will set the definition of churn as 30 days without an active membership.\n",
    "\n",
    "__Example 1:__\n",
    "\n",
    "```\n",
    "(transaction_date, membership_expire_date, is_cancel)\n",
    "\n",
    "(2017-01-01, 2017-02-28, false)\n",
    "\n",
    "(2017-02-25, 0217-03-15, false)\n",
    "\n",
    "(2017-04-30, 3017-05-20, false)\n",
    "```\n",
    "This customer is a churn because they go without a membership for over 30 days, from 03-15 to 04-30. \n",
    "\n",
    "__Example 2:__\n",
    "```\n",
    "(transaction_date, membership_expire_date, is_cancel)\n",
    "\n",
    "(2017-01-01, 2017-02-28, false)\n",
    "\n",
    "(2017-02-25, 2017-04-03, false)\n",
    "\n",
    "(2017-03-15, 2017-03-16, true)\n",
    "\n",
    "(2017-04-01, 3017-06-30, false)\n",
    "```\n",
    "\n",
    "This customer is not a churn. Even though they have a cancelled membership (cancelled on 03-15 and takes effect on 03-16), the membership plan is renewed within 30 days. \n",
    "\n",
    "__Example 3:__\n",
    "```\n",
    "(transaction_date, membership_expire_date, is_cancel)\n",
    "\n",
    "(2017-05-30, 2017-06-30, false)\n",
    "\n",
    "(2017-07-01, 2017-08-01, false)\n",
    "\n",
    "(2017-08-01, 2017-09-01, false)\n",
    "\n",
    "(2017-10-15, 2017-11-15, false)\n",
    "```\n",
    "This customer is a churn because they go without a membership for over 30 days, from 09-01 to 10-15. \n",
    "\n",
    "These three examples illustrate different situations that occur frequently in the data.\n",
    "\n",
    "### Approach\n",
    "\n",
    "Given the data above, to find each example of churn, we need to find the difference between one `membership_expire_date` and the next `transaction_date`. If this period is greater than the days selected for a churn, then this is a positive example of churn. For each churn, we can find the exact date on which it occurred by adding the number of days for a churn to the `membership_expire_date` associated with the churn. \n",
    "\n",
    "We can very rapidly label customer transactions by shifting each `transaction_date` back by one and matching it to the previous `membership_expire_date`. We then find the difference in days between these two (`transaction` - `expire`) and if the difference is greater than the number established for churn, this is a positive label. If this is not clear, we'll shortly see how to do it in code which should clear things up! \n",
    "\n",
    "The general framework is implemented in two functions:\n",
    "\n",
    "1. `customer_to_label_times(customer_id, transactions, **params)`\n",
    "2. `make_label_times(transactions, **params)` \n",
    "\n",
    "The first takes a single customer and returns a table of cutoff times along with the associated labels. The second goes through all of the customers and applies the `customer_to_label_times` function to each one. The end outcome is a single table consisting of the label times for each customer. Since we already partitioned the data, we can run this function over multiple partitions in parallel to rapidly label all the data.\n",
    "\n",
    "## Cutoff Times\n",
    "\n",
    "A critical part of the label times table is the cutoff time associated with each label. This time at which we make a prediction are referred to as _cutoff_ times and they represent when all our data for making features for that particular label must be before. For instance, if our cutoff time is July 1, and we want to make predictions of churn during the month of July, all of our features for this label must be made with data from before July 1. Cutoff times are a critical consideration when feature engineering in order to prevent data leakage. Later when we go to perform automated feature engineering, Featuretools will automatically filter data based on the cutoff times so we don't have to worry about invalid training data.\n",
    "\n",
    "\n",
    "## Prediction Problem\n",
    "\n",
    "Given the definition of churn and the available transactions data, there are a number of prediction problems that can be asked. A prediction problem is simply a way of framing a business need as a machine learning supervised task. For example, we can choose to make predictions of customer churn at different time points and for different time frames. In this notebook we will look at making predictions at two different points in time. \n",
    "\n",
    "* On the first day of every month\n",
    "* On the first and fifteenth day of every month\n",
    "\n",
    "We can also vary the number of days required for a customer to be considered a churn. We'll look at two different definitions of churn:\n",
    "\n",
    "* No active membership for _more than_ 30 days\n",
    "* No active membership for _more than_ 14 days\n",
    "\n",
    "Another parameter in terms of a prediction problem is the format of the task. We can predict the churn itself - a __binary yes or no__ - or the __number of days__ until the customer churns - a regression problem. We could even segment the number of days until a churn into multiple groups - say 1-7 days, 8-14 days, 15-21 days and longer - and then make this a multiclass problem. \n",
    "\n",
    "To leave the format of the prediction problem (regression or classification) open, in this notebook, we'll find the labels - churn or not - as well as the number of days until the next churn. \n",
    "\n",
    "We'll look at two different business scenarios:\n",
    "\n",
    "1. Making a prediction on the first of the month with the churn period set at 30 days.\n",
    "2. Making a prediction on the first and fifteenth of the month with the churn period set at 14 days. \n",
    "\n",
    "Once we calculate and save these labels for the two different time frames, we can change the exact prediction problem from classification to regression. Moreover, the same features can be used for both classification and regression because they will be calculated based on the same cutoff time. This shows a few important points: for any dataset we can make multiple prediction problems based on the business requirements. We can also use the same features to make predictions for different labels if the cutoff times are the same. \n",
    "\n",
    "### Outcome\n",
    "\n",
    "Our overall goal is to build two functions that will generate labels for customers. We can then run this function over our partitions in parallel (our data has been partitioned in 1000 segments, each containing a random subset of customers). Once the label dataframes with cutoff times have been created, we can use them for automated feature engineering using Featuretools.\n",
    "\n",
    "__With all that in mind (don't worry if it hasn't sunk in yet), let's get started!__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G7TmHc9Gg2t8ovG/KFaB53We/0CQPELhZ5UUN2Ol3AQ=</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LPbp8N7VRuqEISEVim8ppTaeYJG/rWS/t4g/dEFuWjw=</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xvYqULBWzJvN8heyFtY3hbY3egyQNbXuDx0igtsoi00=</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UR4iin4mAkajoa7o+AyTTmz5k3N2GR3/rZY8a4KwADI=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ax8CRhY8BMRA/ZvT1wI+2N/EdPXiSPGxa9y7bntA1Uc=</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>2016-06-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  G7TmHc9Gg2t8ovG/KFaB53We/0CQPELhZ5UUN2Ol3AQ=                 39   \n",
       "1  LPbp8N7VRuqEISEVim8ppTaeYJG/rWS/t4g/dEFuWjw=                 34   \n",
       "2  xvYqULBWzJvN8heyFtY3hbY3egyQNbXuDx0igtsoi00=                 29   \n",
       "3  UR4iin4mAkajoa7o+AyTTmz5k3N2GR3/rZY8a4KwADI=                 41   \n",
       "4  ax8CRhY8BMRA/ZvT1wI+2N/EdPXiSPGxa9y7bntA1Uc=                 40   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 30              149                 149              1   \n",
       "1                 30              149                 149              1   \n",
       "2                 30              180                 180              1   \n",
       "3                 30               99                  99              1   \n",
       "4                 30              149                 149              1   \n",
       "\n",
       "  transaction_date membership_expire_date  is_cancel  \n",
       "0       2015-09-30             2015-11-13          0  \n",
       "1       2016-02-29             2016-03-31          0  \n",
       "2       2017-01-31             2017-03-01          0  \n",
       "3       2017-01-31             2017-02-28          0  \n",
       "4       2016-05-04             2016-06-08          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARTITION = '100'\n",
    "BASE_DIR = 's3://customer-churn-spark/'\n",
    "PARTITION_DIR = BASE_DIR + 'p' + PARTITION\n",
    "\n",
    "members = pd.read_csv(f'{PARTITION_DIR}/members.csv', \n",
    "                      parse_dates=['registration_init_time'], infer_datetime_format = True)\n",
    "trans = pd.read_csv(f'{PARTITION_DIR}/transactions.csv',\n",
    "                   parse_dates=['transaction_date', 'membership_expire_date'], infer_datetime_format = True)\n",
    "logs = pd.read_csv(f'{PARTITION_DIR}/logs.csv', parse_dates = ['date'])\n",
    "\n",
    "trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transactions table is all we will need to make labels. All of our data is stored in S3 so we can access it from any machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "# Credentials\n",
    "with open('/data/credentials.txt', 'r') as f:\n",
    "    info = f.read().strip().split(',')\n",
    "    key = info[0]\n",
    "    secret = info[1]\n",
    "\n",
    "fs = s3fs.S3FileSystem(key=key, secret=secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Churn for One Customer\n",
    "\n",
    "The function below takes in a single customer's transactions along with a number of parameters that define the prediction problem. These are `prediction_freq`, when we want to make predictions, and `churn_days` the number of days without a membership required for a churn. The return is a label_times dataframe for the customer which has cutoff times for the specified `prediction_freq` and the label at each prediction time. Leaving the prediction time and number of days for a churn as parameters allows us to create multiple prediction problems using the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_to_label_times(customer_id, transactions, prediction_freq, churn_days, return_trans = False):\n",
    "    \"\"\"\n",
    "    Make label times for a single customer. Returns a dataframe of labels with times, the binary label, \n",
    "    and the number of days until the next churn.\n",
    "       \n",
    "    Params\n",
    "    --------\n",
    "        customer_id (str): unique id for the customer\n",
    "        transactions (dataframe): transactions dataframe for the customer\n",
    "        prediction_freq (str): frequency for making predicions. Either \"MS\" for the first of the month\n",
    "                               or \"SMS\" for the first and fifteenth of each month \n",
    "        churn_days (int): integer number of days without an active membership required for a churn. A churn is\n",
    "                          defined by exceeding this number of days without an active membership\n",
    "        return_trans (boolean): whether or not to return the transactions for analysis. Defaults to False.\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        label_times (dataframe): a table of customer id, the cutoff times at the specified frequency, the \n",
    "                                 label for each cutoff time, the number of days until the next churn for each\n",
    "                                 cutoff time, and the date on which the churn itself occurred.\n",
    "        transactions (dataframe): optional dataframe of customer transactions if return_trans = True. Useful\n",
    "                                  for making sure that the function performed as expected\n",
    "    \n",
    "       \"\"\"\n",
    "    \n",
    "    assert(prediction_freq in ['MS', 'SMS']), \"Prediction day must be either 'MS' or 'SMS'\"\n",
    "    assert(transactions['msno'].unique() == [customer_id]), \"Transactions must be for only customer\"\n",
    "    \n",
    "    transactions = transactions.copy()\n",
    "    \n",
    "    # Make sure to sort chronalogically\n",
    "    transactions.sort_values(['transaction_date', 'membership_expire_date'], inplace = True)\n",
    "    \n",
    "    # Create next transaction day by shifting back one transaction\n",
    "    transactions['next_transaction_date'] = transactions['transaction_date'].shift(-1)\n",
    "    \n",
    "    # Find number of days between transaction and next\n",
    "    transactions['difference_days'] = (transactions['next_transaction_date'] - \n",
    "                                       transactions['membership_expire_date']).\\\n",
    "                                       dt.total_seconds() / (3600 * 24)\n",
    "    \n",
    "    # Determine which transactions are associated with a churn\n",
    "    transactions['churn'] = transactions['difference_days'] > churn_days\n",
    "    \n",
    "    # Find date of churn\n",
    "    transactions.loc[transactions['churn'] == True, \n",
    "                     'churn_date'] = transactions.loc[transactions['churn'] == True, \n",
    "                                                      'membership_expire_date'] + pd.Timedelta(churn_days + 1, 'd')\n",
    "    \n",
    "    # Range for label times is from first to last transaction\n",
    "    first_transaction = transactions['transaction_date'].min()\n",
    "    last_transaction = transactions['transaction_date'].max()\n",
    "    start_date = pd.datetime(first_transaction.year, first_transaction.month, 1)\n",
    "    end_date = pd.datetime(last_transaction.year, last_transaction.month, 1)\n",
    "    \n",
    "    # Make label times dataframe\n",
    "    label_times = pd.DataFrame({'cutoff_time': pd.date_range(start_date, end_date, freq = prediction_freq),\n",
    "                                'msno': customer_id\n",
    "                               })\n",
    "    # Needed for subsetting to create label time\n",
    "    label_times['next_cutoff_time'] = label_times['cutoff_time'].shift(-1)\n",
    "    \n",
    "    # If no churns\n",
    "    if (transactions['churn'] == False).all():\n",
    "        label_times['label'] = 0\n",
    "        label_times['days_to_churn'] = np.nan\n",
    "        label_times['churn_date'] = np.nan\n",
    "        if return_trans: \n",
    "            return label_times[['msno', 'cutoff_time', 'label', 'days_to_churn', 'churn_date']], transactions\n",
    "        \n",
    "        return label_times[['msno', 'cutoff_time', 'label', 'days_to_churn', 'churn_date']]\n",
    "    \n",
    "    # Keep track of last churn\n",
    "    previous_churn_date = None\n",
    "    \n",
    "    # Iterate through the positive churns\n",
    "    for i, row in transactions.loc[transactions['churn'] == True].iterrows():\n",
    "        churn_date = row['churn_date']\n",
    "        \n",
    "        # Find label time associated with churn and assign label 1 and churn date\n",
    "        label_idx = label_times.loc[(label_times['cutoff_time'] <= churn_date) & \n",
    "                                    (label_times['next_cutoff_time'] > churn_date)].index\n",
    "        label_times.loc[label_idx, 'label'] = 1\n",
    "        label_times.loc[label_idx, 'churn_date'] = churn_date\n",
    "        \n",
    "        # Find number of days until next churn\n",
    "        if not previous_churn_date:\n",
    "            before_idx = label_times.loc[(label_times['cutoff_time'] <= churn_date)].index\n",
    "        else:\n",
    "            before_idx = label_times.loc[(label_times['cutoff_time'] <= churn_date) & \n",
    "                                         (label_times['cutoff_time'] > previous_churn_date)].index\n",
    "        # Calculate days to next churn for all label times\n",
    "        label_times.loc[before_idx, 'days_to_churn'] = (churn_date - label_times.loc[before_idx, \n",
    "                                                                                     'cutoff_time']).\\\n",
    "                                                        dt.total_seconds() / (3600 * 24)\n",
    "        previous_churn_date = churn_date\n",
    "        \n",
    "    if return_trans:\n",
    "        return label_times[['msno', 'cutoff_time', 'label', 'days_to_churn', 'churn_date']], transactions\n",
    "    \n",
    "    return label_times[['msno', 'cutoff_time', 'label', 'days_to_churn', 'churn_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the output of this function for a typical customer. We'll take the use case of making predictions on the first of each month with 30 days required for a churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>label</th>\n",
       "      <th>days_to_churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2016-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno cutoff_time  label  \\\n",
       "0  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2015-09-01    NaN   \n",
       "1  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2015-10-01    NaN   \n",
       "2  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2015-11-01    NaN   \n",
       "3  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2015-12-01    NaN   \n",
       "4  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2016-01-01    NaN   \n",
       "5  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2016-02-01    NaN   \n",
       "6  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2016-03-01    1.0   \n",
       "7  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2016-04-01    NaN   \n",
       "8  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2016-05-01    NaN   \n",
       "9  xDdNp65JYgYhw0J3MWVmc3o+WXBJrUUZTptR/O4Sa3Q=  2016-06-01    NaN   \n",
       "\n",
       "   days_to_churn churn_date  \n",
       "0          197.0        NaT  \n",
       "1          167.0        NaT  \n",
       "2          136.0        NaT  \n",
       "3          106.0        NaT  \n",
       "4           75.0        NaT  \n",
       "5           44.0        NaT  \n",
       "6           15.0 2016-03-16  \n",
       "7            NaN        NaT  \n",
       "8            NaN        NaT  \n",
       "9            NaN        NaT  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOMER_ID = trans.iloc[8, 0]\n",
    "customer_transactions = trans.loc[trans['msno'] == CUSTOMER_ID].copy()\n",
    "\n",
    "label_times, cust_transactions = customer_to_label_times(CUSTOMER_ID, customer_transactions, 'MS', 30, True)\n",
    "label_times.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the function worked, we'll want to take a look at the transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>next_transaction_date</th>\n",
       "      <th>difference_days</th>\n",
       "      <th>churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20245</th>\n",
       "      <td>2015-12-25</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>2016-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>98.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17673</th>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6313</th>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17857</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>2016-09-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_date membership_expire_date  is_cancel  \\\n",
       "20245       2015-12-25             2016-01-25          0   \n",
       "4568        2016-01-25             2016-02-25          0   \n",
       "1032        2016-02-14             2016-02-14          1   \n",
       "5789        2016-05-22             2016-06-21          0   \n",
       "17673       2016-06-21             2016-07-21          0   \n",
       "6313        2016-07-21             2016-08-21          0   \n",
       "17857       2016-08-21             2016-09-21          0   \n",
       "\n",
       "      next_transaction_date  difference_days  churn churn_date  \n",
       "20245            2016-01-25              0.0  False        NaT  \n",
       "4568             2016-02-14            -11.0  False        NaT  \n",
       "1032             2016-05-22             98.0   True 2016-03-16  \n",
       "5789             2016-06-21              0.0  False        NaT  \n",
       "17673            2016-07-21              0.0  False        NaT  \n",
       "6313             2016-08-21              0.0  False        NaT  \n",
       "17857            2016-09-21              0.0  False        NaT  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_transactions.iloc[3:10, -7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the churn occurred on 2016-03-16 as the customer went 98 days between an active membership from 2016-02-14 to 2016-05-22. The churn is only associated with one cutoff time, the month during which the churn occurred. The actual churn occurs 31 days from when the membership expires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the function in use for the other prediction problem, making predictions on the first and fifteenth of each month with churn defined as more than 14 days without an active membership. To change the prediction problem, all we need to do is alter the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>label</th>\n",
       "      <th>days_to_churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2016-02-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=</td>\n",
       "      <td>2016-03-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno cutoff_time  label  \\\n",
       "0  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2015-11-01    NaN   \n",
       "1  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2015-11-15    NaN   \n",
       "2  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2015-12-01    NaN   \n",
       "3  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2015-12-15    NaN   \n",
       "4  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2016-01-01    NaN   \n",
       "5  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2016-01-15    1.0   \n",
       "6  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2016-02-01    NaN   \n",
       "7  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2016-02-15    NaN   \n",
       "8  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2016-03-01    NaN   \n",
       "9  TxOH0+7oP3ew1ZTShSJSPpbzCeCuZVhGGh/4S/mhOdw=  2016-03-15    1.0   \n",
       "\n",
       "   days_to_churn churn_date  \n",
       "0           75.0        NaT  \n",
       "1           61.0        NaT  \n",
       "2           45.0        NaT  \n",
       "3           31.0        NaT  \n",
       "4           14.0        NaT  \n",
       "5            0.0 2016-01-15  \n",
       "6           43.0        NaT  \n",
       "7           29.0        NaT  \n",
       "8           14.0        NaT  \n",
       "9            0.0 2016-03-15  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOMER_ID = trans.iloc[100, 0]\n",
    "customer_transactions = trans.loc[trans['msno'] == CUSTOMER_ID].copy()\n",
    "\n",
    "label_times, cust_transactions = customer_to_label_times(CUSTOMER_ID, customer_transactions, 'SMS', 14, True)\n",
    "label_times.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>next_transaction_date</th>\n",
       "      <th>difference_days</th>\n",
       "      <th>churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16033</th>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7280</th>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16884</th>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20193</th>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18343</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11484</th>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_date membership_expire_date  is_cancel  \\\n",
       "2393        2015-11-29             2015-12-31          0   \n",
       "15856       2016-01-31             2016-02-29          0   \n",
       "16033       2016-03-31             2016-04-30          0   \n",
       "7280        2016-04-30             2016-05-31          0   \n",
       "16884       2016-05-31             2016-06-30          0   \n",
       "6370        2016-06-30             2016-07-31          0   \n",
       "20193       2016-07-31             2016-08-31          0   \n",
       "18343       2016-08-31             2016-09-30          0   \n",
       "6365        2016-09-30             2016-10-31          0   \n",
       "11484       2016-10-31             2016-11-30          0   \n",
       "\n",
       "      next_transaction_date  difference_days  churn churn_date  \n",
       "2393             2016-01-31             31.0   True 2016-01-15  \n",
       "15856            2016-03-31             31.0   True 2016-03-15  \n",
       "16033            2016-04-30              0.0  False        NaT  \n",
       "7280             2016-05-31              0.0  False        NaT  \n",
       "16884            2016-06-30              0.0  False        NaT  \n",
       "6370             2016-07-31              0.0  False        NaT  \n",
       "20193            2016-08-31              0.0  False        NaT  \n",
       "18343            2016-09-30              0.0  False        NaT  \n",
       "6365             2016-10-31              0.0  False        NaT  \n",
       "11484            2016-11-30              0.0  False        NaT  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_transactions.iloc[:10, -7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the label and the tranactions align as intended. Each label of churn is associated with exactly one cutoff time. We can make predictions for either a binary classification problem or for a regression problem to forecast the exact date of a churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Churn for All Customers\n",
    "\n",
    "Next, we take that function which works for one customer and apply it to all customers in a dataset. This requires a loop through the customers by grouping the customer transactions and applying `customer_to_label_times` to each customer's transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label_times(transactions, prediction_freq, churn_days):\n",
    "    \"\"\"\n",
    "    Make labels for an entire series of transactions. \n",
    "    \n",
    "    Params\n",
    "    --------\n",
    "        transactions (dataframe): table of customer transactions\n",
    "        prediction_freq (str): frequency for making predicions. Either \"MS\" for the first of the month\n",
    "                               or \"SMS\" for the first and fifteenth of each month \n",
    "        churn_days (int): integer number of days without an active membership required for a churn. A churn is\n",
    "                          defined by exceeding this number of days without an active membership\n",
    "    Return\n",
    "    --------\n",
    "        label_times (dataframe): a table with customer ids, cutoff times, binary label, regression label, \n",
    "                                 and date of churn. This table can the\n",
    "    \"\"\"\n",
    "    label_times = []\n",
    "    \n",
    "    # Iterate through each customer and find labels\n",
    "    for customer_id, customer_transactions in transactions.groupby('msno'):\n",
    "        label_times.append(customer_to_label_times(customer_id, customer_transactions,\n",
    "                                                   prediction_freq, churn_days))\n",
    "        \n",
    "    # Concatenate into a single dataframe\n",
    "    return pd.concat(label_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>label</th>\n",
       "      <th>days_to_churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            msno cutoff_time  label  \\\n",
       "17  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-06-01    0.0   \n",
       "18  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-07-01    0.0   \n",
       "19  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-08-01    0.0   \n",
       "20  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-09-01    0.0   \n",
       "21  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-10-01    0.0   \n",
       "22  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-11-01    0.0   \n",
       "23  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-12-01    0.0   \n",
       "24  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-01-01    0.0   \n",
       "25  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-02-01    0.0   \n",
       "26  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-03-01    0.0   \n",
       "\n",
       "    days_to_churn churn_date  \n",
       "17            NaN        NaN  \n",
       "18            NaN        NaN  \n",
       "19            NaN        NaN  \n",
       "20            NaN        NaN  \n",
       "21            NaN        NaN  \n",
       "22            NaN        NaN  \n",
       "23            NaN        NaN  \n",
       "24            NaN        NaN  \n",
       "25            NaN        NaN  \n",
       "26            NaN        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_times = make_label_times(trans, 'MS', 30)\n",
    "label_times.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_to_labels(partition_number, label_types = ['MS', 'SMS'], churn_periods = [30, 14]):\n",
    "    \"\"\"Make labels for all customers in one partition\n",
    "    Either for one month or twice a month\n",
    "    \n",
    "    Params\n",
    "    --------\n",
    "        partition (int): number of partition\n",
    "        label_type (str): either 'monthly' for monthly labels or\n",
    "                          'bimonthly' for twice a month labels\n",
    "        churn_period (int): number of days required without a membership for a churn\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "        None: saves the label dataframes with the appropriate name to the partition directory\n",
    "    \"\"\"\n",
    "    partition_dir = BASE_DIR + 'p' + str(partition_number)\n",
    "    \n",
    "    # Read in data and filter anomalies\n",
    "    trans = pd.read_csv(f'{partition_dir}/transactions.csv',\n",
    "                        parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                        infer_datetime_format = True)\n",
    "    trans = trans.loc[trans['membership_expire_date'] >= trans['transaction_date']]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Create both sets of lables\n",
    "    for prediction_freq, churn_days in zip(label_types, churn_periods):\n",
    "        \n",
    "        cutoff_list = []\n",
    "        \n",
    "        cutoff_list.append(make_label_times(trans, prediction_freq = prediction_freq, \n",
    "                                            churn_days = churn_days))\n",
    "        cutoff_times = pd.concat(cutoff_list)\n",
    "        cutoff_times = cutoff_times.drop_duplicates()\n",
    "        \n",
    "        # Encode in order to write to s3\n",
    "        bytes_to_write = cutoff_times.to_csv(None, index = False).encode()\n",
    "\n",
    "        # Write cutoff times to S3\n",
    "        with fs.open(f'{partition_dir}/{prediction_freq}-{churn_days}_labels.csv', 'wb') as f:\n",
    "            f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_to_labels(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark/')\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "\n",
    "# Enable logging\n",
    "conf.set('spark.eventLog.enabled', True);\n",
    "conf.set('spark.eventLog.dir', '/data/churn/tmp/');\n",
    "\n",
    "# Use all cores on all machines\n",
    "conf.set('spark.num.executors', 1)\n",
    "conf.set('spark.executor.memory', '24g')\n",
    "conf.set('spark.executor.cores', 8)\n",
    "\n",
    "sc = pyspark.SparkContext(master = 'spark://ip-172-31-23-133.ec2.internal:7077',\n",
    "                          appName = 'labeling', conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "sc.parallelize(list(range(1000)), numSlices=1000).\\\n",
    "   map(partition_to_labels).collect()\n",
    "sc.stop()\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12599 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>label</th>\n",
       "      <th>days_to_churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+/ArcmV8FBEOABJP5zn7RH2S5lU1EdPN3ucEJjYRXVY=</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+/trjV54MKwcuhk/C6P0OSeEX7hDfLpXme/6EDOny6A=</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+/trjV54MKwcuhk/C6P0OSeEX7hDfLpXme/6EDOny6A=</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+/trjV54MKwcuhk/C6P0OSeEX7hDfLpXme/6EDOny6A=</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+/trjV54MKwcuhk/C6P0OSeEX7hDfLpXme/6EDOny6A=</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno cutoff_time  label  \\\n",
       "0  +/ArcmV8FBEOABJP5zn7RH2S5lU1EdPN3ucEJjYRXVY=  2016-11-01    0.0   \n",
       "1  +/trjV54MKwcuhk/C6P0OSeEX7hDfLpXme/6EDOny6A=  2015-06-01    0.0   \n",
       "2  +/trjV54MKwcuhk/C6P0OSeEX7hDfLpXme/6EDOny6A=  2015-07-01    0.0   \n",
       "3  +/trjV54MKwcuhk/C6P0OSeEX7hDfLpXme/6EDOny6A=  2015-08-01    0.0   \n",
       "4  +/trjV54MKwcuhk/C6P0OSeEX7hDfLpXme/6EDOny6A=  2015-09-01    0.0   \n",
       "\n",
       "   days_to_churn churn_date  \n",
       "0            NaN        NaN  \n",
       "1          144.0          0  \n",
       "2          114.0          0  \n",
       "3           83.0          0  \n",
       "4           52.0          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(f's3://customer-churn-spark/p980/MS-30_labels.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "501px",
    "left": "781px",
    "right": "20px",
    "top": "574px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
