{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Partitioning \n",
    "\n",
    "In this notebook, we will partition the data based on customer id. This will allow us to use a framework such as Spark using PySpark or Dask in order to parallelize computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of All Files\n",
    "\n",
    "Below are all the files provided by the competition. There are several versions of multiple files because the competition released new data several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data/churn/train_v2.csv'),\n",
       " PosixPath('/data/churn/user_logs_v2.csv'),\n",
       " PosixPath('/data/churn/transactions.csv'),\n",
       " PosixPath('/data/churn/WSDMChurnLabeller.scala'),\n",
       " PosixPath('/data/churn/user_logs.csv'),\n",
       " PosixPath('/data/churn/transactions_v2.csv'),\n",
       " PosixPath('/data/churn/members_v3.csv'),\n",
       " PosixPath('/data/churn/train.csv'),\n",
       " PosixPath('/data/churn/sample_submission_v2.csv'),\n",
       " PosixPath('/data/churn/sample_submission_zero.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PATH = Path('/data/churn/')\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "Here we read in the training data (the labels) and join together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1963891, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1 = pd.read_csv(PATH/'train.csv')\n",
    "train_2 = pd.read_csv(PATH/'train_v2.csv')\n",
    "all_train = pd.concat([train_1, train_2], axis = 0)\n",
    "all_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train.to_csv(PATH/'all_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactions Data\n",
    "\n",
    "We take the same approach with the transactions data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_1 = pd.read_csv(PATH/'transactions.csv')\n",
    "trans_2 = pd.read_csv(PATH/'transactions_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YyO+tlZtAXYXoZhNr3Vg3+dfVQvrBVGO8j1mfqe4ZHc=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZtu6Wl0gPojrEQYB8Q3vBSmE2wnZ3hi1FbK1rQQ0A4=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UkDFI97Qb6+s2LWcijVVv4rMAsORbVDT2wNXF0aVbns=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20160427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1C56ijxozNaGD0t2h68PnH2xtx5iO5iR2MVYQB6nBI=</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yvj6zyBUaqdbUQSrKsrZ+xNDVM62knauSZJzakS9OW4=</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  YyO+tlZtAXYXoZhNr3Vg3+dfVQvrBVGO8j1mfqe4ZHc=                 41   \n",
       "1  AZtu6Wl0gPojrEQYB8Q3vBSmE2wnZ3hi1FbK1rQQ0A4=                 41   \n",
       "2  UkDFI97Qb6+s2LWcijVVv4rMAsORbVDT2wNXF0aVbns=                 41   \n",
       "3  M1C56ijxozNaGD0t2h68PnH2xtx5iO5iR2MVYQB6nBI=                 39   \n",
       "4  yvj6zyBUaqdbUQSrKsrZ+xNDVM62knauSZJzakS9OW4=                 39   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 30              129                 129              1   \n",
       "1                 30              149                 149              1   \n",
       "2                 30              129                 129              1   \n",
       "3                 30              149                 149              1   \n",
       "4                 30              149                 149              1   \n",
       "\n",
       "   transaction_date  membership_expire_date  is_cancel  \n",
       "0          20150930                20151101          0  \n",
       "1          20150930                20151031          0  \n",
       "2          20150930                20160427          0  \n",
       "3          20150930                20151128          0  \n",
       "4          20150930                20151121          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>++6eU4LsQ3UQ20ILS7d99XK8WbiVgbyYL4FUgzZR134=</td>\n",
       "      <td>32</td>\n",
       "      <td>90</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>20170131</td>\n",
       "      <td>20170504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>++lvGPJOinuin/8esghpnqdljm6NXS8m8Zwchc7gOeA=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150809</td>\n",
       "      <td>20190412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+/GXNtXWQVfKrEDqYAzcSw2xSPYMKWNj22m+5XkVQZc=</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>20170303</td>\n",
       "      <td>20170422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+/w1UrZwyka4C9oNH3+Q8fUf3fD8R3EwWrx57ODIsqk=</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>20170329</td>\n",
       "      <td>20170331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+00PGzKTYqtnb65mPKPyeHXcZEwqiEzktpQksaaSC3c=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>20170323</td>\n",
       "      <td>20170423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  ++6eU4LsQ3UQ20ILS7d99XK8WbiVgbyYL4FUgzZR134=                 32   \n",
       "1  ++lvGPJOinuin/8esghpnqdljm6NXS8m8Zwchc7gOeA=                 41   \n",
       "2  +/GXNtXWQVfKrEDqYAzcSw2xSPYMKWNj22m+5XkVQZc=                 36   \n",
       "3  +/w1UrZwyka4C9oNH3+Q8fUf3fD8R3EwWrx57ODIsqk=                 36   \n",
       "4  +00PGzKTYqtnb65mPKPyeHXcZEwqiEzktpQksaaSC3c=                 41   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 90              298                 298              0   \n",
       "1                 30              149                 149              1   \n",
       "2                 30              180                 180              1   \n",
       "3                 30              180                 180              1   \n",
       "4                 30               99                  99              1   \n",
       "\n",
       "   transaction_date  membership_expire_date  is_cancel  \n",
       "0          20170131                20170504          0  \n",
       "1          20150809                20190412          0  \n",
       "2          20170303                20170422          0  \n",
       "3          20170329                20170331          1  \n",
       "4          20170323                20170423          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_1.head()\n",
    "trans_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22978755, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trans = pd.concat([trans_1, trans_2], axis = 0)\n",
    "all_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans.to_csv(PATH/'all_trans.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Members Data\n",
    "\n",
    "The members data can be the parent of the other datasets. It includes the basic metadata about each member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>20110911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20110914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>20110915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>20110915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20110915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=     1   0     NaN   \n",
       "1  +tJonkh+O1CA796Fm5X60UMOtB6POHAwPjbTRVl/EuU=     1   0     NaN   \n",
       "2  cV358ssn7a0f7jZOwGNWS07wCKVqxyiImJUX6xcIwKw=     1   0     NaN   \n",
       "3  9bzDeJP6sQodK73K5CBlJ6fgIQzPeLnRl0p5B77XP+g=     1   0     NaN   \n",
       "4  WFLY3s7z4EZsieHCt63XrsdtfTEmJ+2PnnKLH5GY4Tk=     6  32  female   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0              11                20110911  \n",
       "1               7                20110914  \n",
       "2              11                20110915  \n",
       "3              11                20110915  \n",
       "4               9                20110915  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members = pd.read_csv(PATH/'members_v3.csv')\n",
    "members.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach to EntitySet\n",
    "\n",
    "* Members is the parent\n",
    "* Transactions is a child\n",
    "* User logs is another child\n",
    "\n",
    "Partition data based no user ids, `msno`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1082190"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train['msno'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1963891"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waLDQMmcOu2jLDaV1ddDkgCrB/jl6sD66Xzs0Vqax1Y=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QA7uiXy8vIbUSPOkCf9RwQ3FsT8jVq2OxDr8zqa7bRQ=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fGwBva6hikQmTJzrbz/2Ezjm5Cth5jZUNvXigKK2AFA=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mT5V8rEpa+8wuqi6x0DoVd3H5icMKkE9Prt49UlmK+4=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XaPhtGLk/5UvvOYHcONTwsnH97P4eGECeq+BARGItRw=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn\n",
       "0  waLDQMmcOu2jLDaV1ddDkgCrB/jl6sD66Xzs0Vqax1Y=         1\n",
       "1  QA7uiXy8vIbUSPOkCf9RwQ3FsT8jVq2OxDr8zqa7bRQ=         1\n",
       "2  fGwBva6hikQmTJzrbz/2Ezjm5Cth5jZUNvXigKK2AFA=         1\n",
       "3  mT5V8rEpa+8wuqi6x0DoVd3H5icMKkE9Prt49UlmK+4=         1\n",
       "4  XaPhtGLk/5UvvOYHcONTwsnH97P4eGECeq+BARGItRw=         1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some customers have multiple labels as indicated below. It's possible that the same customer can have both a label of did not churn and a churn label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_churn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msno</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VLmKab6JByryjhBzawWgIXnsDn/p8gtuKNUDEIrALIw=</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PX+bAAD+a5wZ0qGOiZbydu8SNbFZrhiCjz+z0q6jlLM=</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArZiQi90rqg0aBc5YeXAm6ux0CkHlyziFa03DKAtjVc=</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3x8Nugz7JdfTmexKza79oBIly8isF7PTReWCXyAr9QU=</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeskHs66YWKq1JhCzVtfj0z8P5B+Y2Xrtu0mByqUufQ=</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              is_churn\n",
       "msno                                                  \n",
       "VLmKab6JByryjhBzawWgIXnsDn/p8gtuKNUDEIrALIw=         2\n",
       "PX+bAAD+a5wZ0qGOiZbydu8SNbFZrhiCjz+z0q6jlLM=         2\n",
       "ArZiQi90rqg0aBc5YeXAm6ux0CkHlyziFa03DKAtjVc=         2\n",
       "3x8Nugz7JdfTmexKza79oBIly8isF7PTReWCXyAr9QU=         2\n",
       "DeskHs66YWKq1JhCzVtfj0z8P5B+Y2Xrtu0mByqUufQ=         2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.groupby(['msno'])['is_churn'].nunique().to_frame().sort_values('is_churn').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YyO+tlZtAXYXoZhNr3Vg3+dfVQvrBVGO8j1mfqe4ZHc=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZtu6Wl0gPojrEQYB8Q3vBSmE2wnZ3hi1FbK1rQQ0A4=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UkDFI97Qb6+s2LWcijVVv4rMAsORbVDT2wNXF0aVbns=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20160427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1C56ijxozNaGD0t2h68PnH2xtx5iO5iR2MVYQB6nBI=</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yvj6zyBUaqdbUQSrKsrZ+xNDVM62knauSZJzakS9OW4=</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  YyO+tlZtAXYXoZhNr3Vg3+dfVQvrBVGO8j1mfqe4ZHc=                 41   \n",
       "1  AZtu6Wl0gPojrEQYB8Q3vBSmE2wnZ3hi1FbK1rQQ0A4=                 41   \n",
       "2  UkDFI97Qb6+s2LWcijVVv4rMAsORbVDT2wNXF0aVbns=                 41   \n",
       "3  M1C56ijxozNaGD0t2h68PnH2xtx5iO5iR2MVYQB6nBI=                 39   \n",
       "4  yvj6zyBUaqdbUQSrKsrZ+xNDVM62knauSZJzakS9OW4=                 39   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 30              129                 129              1   \n",
       "1                 30              149                 149              1   \n",
       "2                 30              129                 129              1   \n",
       "3                 30              149                 149              1   \n",
       "4                 30              149                 149              1   \n",
       "\n",
       "   transaction_date  membership_expire_date  is_cancel  \n",
       "0          20150930                20151101          0  \n",
       "1          20150930                20151031          0  \n",
       "2          20150930                20160427          0  \n",
       "3          20150930                20151128          0  \n",
       "4          20150930                20151121          0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2426143"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trans['msno'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Dask Dataframe for Large Datasets\n",
    "\n",
    "For the user logs, we'll have to use Dask dataframes. This is a method for working with large datasets that does not load the entire file into memory at once. Instead, it loads data as needed (lazy loading) to carry out similar operations as are done to Pandas dataframes. This makes it feasible to work with datasets that are beyond the capabilities of our single machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Logs\n",
    "\n",
    "The user logs are quite large (up to 29 GB) and must be dealt with using Dask dataframes. For example, to compute the shape of the log file, we cannot load in the entire file at once and instead must let Dask handle the loading behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "\n",
    "logs1 = dd.read_csv(PATH/'user_logs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling a method or attribute of a Dask dataframe does not return the value, instead it creates a future that will be executed at a later time. In order to actually execute the task, we have to call the compute method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392106543"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape1 = logs1.shape[0]\n",
    "shape1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18396362"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs2 = dd.read_csv(PATH/'user_logs_v2.csv')\n",
    "shape2 = logs2.shape[0]\n",
    "shape2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5234111"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs1['msno'].nunique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103894"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs2['msno'].nunique().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation does not actually join the datasets together until necessary. Instead, it creates a futures object that will be called when we want to run any calculations with the log data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs = dd.concat([logs1, logs2], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Data\n",
    "\n",
    "The following are the submission files (test data) for the competition. This is also in two parts because of the multiple issues with data provenance encountered in the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1076941"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1 = pd.read_csv(PATH/'sample_submission_zero.csv')\n",
    "sub2 = pd.read_csv(PATH/'sample_submission_v2.csv')\n",
    "all_subs = pd.concat([sub1, sub2], axis = 0)\n",
    "all_subs['msno'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ids\n",
    "\n",
    "I'm not sure how many ids there really are because all the data has differing number of unique ids. For partitioning the data, I'll create a list of all the ids in the training and testing dataframes (both versions). It's possible that much of the data in the other dataframes is not related to any of these customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2159131 unique ids in the training and testing data.\n"
     ]
    }
   ],
   "source": [
    "all_msno = list(all_subs['msno'].unique()) + list(all_train['msno'].unique())\n",
    "print(f'There are {len(all_msno)} unique ids in the training and testing data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunking Data\n",
    "\n",
    "To keep the size of the individual chunks manageable, we'll create 1000 partitions. Each partition will contain all the data associated with a subset of customers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chunks = 1000\n",
    "chunk_size = len(all_msno) // (n_chunks - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a list of 1000 lists of subset customer ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list = [list(all_msno[i:i+chunk_size]) for i in range(0, len(all_msno), chunk_size)]\n",
    "len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2159131"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "all_ids = list(chain(*id_list))\n",
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should make sure that all the ids from the trainig and testing data are represented in the list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids == all_msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Subsetting the Dask Dataframe\n",
    "\n",
    "The Dask dataframe cannot be subsetted all at once. Instead, we can create the call and then compute the result using Dask. Behind the scenes, Dask will load in the dataframe a little at a time and find the correct rows. Then, it will return all the rows we need which we can save in the partition. Without Dask, this operation would not be feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_subset = all_logs.loc[all_logs['msno'].isin(id_list[0]), :].copy().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Data \n",
    "\n",
    "Each partition will be saved as a separate partition on the disk. At the end of paritioning, there will be 1000 directories, each with all the data associated with a subset of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "partition = 0\n",
    "id_section = id_list[0]\n",
    "directory = PATH/f'partitions/p{partition}'\n",
    "\n",
    "os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Application\n",
    "\n",
    "We'll create one trial partition of the first subset of customers. Each subset has about 2100 customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_subset = all_logs.loc[all_logs['msno'].isin(id_section), :].copy().compute()\n",
    "trans_subset = all_trans.loc[all_trans['msno'].isin(id_section), :].copy()\n",
    "members_subset = members.loc[members['msno'].isin(id_section), :].copy()\n",
    "train_subset = all_train.loc[all_train['msno'].isin(id_section), :].copy()\n",
    "test_subset = all_subs.loc[all_subs['msno'].isin(id_section), :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_subset.to_csv(f'{directory}/logs.csv', index = False)\n",
    "trans_subset.to_csv(f'{directory}/transactions.csv', index = False)\n",
    "members_subset.to_csv(f'{directory}/members.csv', index = False)\n",
    "train_subset.to_csv(f'{directory}/train.csv', index = False)\n",
    "test_subset.to_csv(f'{directory}/test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transactions.csv', 'members.csv', 'test.csv', 'train.csv', 'logs.csv']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works as intended so we can wrap the code in a function and then calculate all the partitions. The following function takes in a list of customers (`id_section`) and creates a partition for those customers. The partition is then saved using the number of the parition (`partition`) as the directory identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partition(id_section: list, partition: int) -> None:\n",
    "    \"\"\"Create a partition from a list of ids. Save to disk using the partition number.\"\"\"\n",
    "    \n",
    "    # Log subset must be computed because it is a dask dataframe\n",
    "    logs_subset = all_logs.loc[all_logs['msno'].isin(id_section), :].copy().compute()\n",
    "    # All other subsets can simply be selected\n",
    "    trans_subset = all_trans.loc[all_trans['msno'].isin(id_section), :].copy()\n",
    "    members_subset = members.loc[members['msno'].isin(id_section), :].copy()\n",
    "    train_subset = all_train.loc[all_train['msno'].isin(id_section), :].copy()\n",
    "    test_subset = all_subs.loc[all_subs['msno'].isin(id_section), :].copy()\n",
    "    \n",
    "    # Make the partition directory\n",
    "    directory = PATH/f'partitions/p{partition}'\n",
    "    os.makedirs(directory, exist_ok = True)\n",
    "    \n",
    "    # Save the subset to disk\n",
    "    logs_subset.to_csv(f'{directory}/logs.csv', index = False)\n",
    "    trans_subset.to_csv(f'{directory}/transactions.csv', index = False)\n",
    "    members_subset.to_csv(f'{directory}/members.csv', index = False)\n",
    "    train_subset.to_csv(f'{directory}/train.csv', index = False)\n",
    "    test_subset.to_csv(f'{directory}/test.csv', index = False)\n",
    "    \n",
    "    # Progress\n",
    "    if partition % 10 == 0:\n",
    "        print(f'Partition {partition} saved to {directory}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code runs all of the partitions. This may take quite a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0 saved to /data/churn/partitions/p0.\n",
      "Partition 10 saved to /data/churn/partitions/p10.\n",
      "Partition 20 saved to /data/churn/partitions/p20.\n",
      "Partition 30 saved to /data/churn/partitions/p30.\n",
      "Partition 40 saved to /data/churn/partitions/p40.\n",
      "Partition 50 saved to /data/churn/partitions/p50.\n",
      "Partition 60 saved to /data/churn/partitions/p60.\n",
      "Partition 70 saved to /data/churn/partitions/p70.\n",
      "Partition 80 saved to /data/churn/partitions/p80.\n",
      "Partition 90 saved to /data/churn/partitions/p90.\n",
      "Partition 100 saved to /data/churn/partitions/p100.\n",
      "Partition 110 saved to /data/churn/partitions/p110.\n",
      "Partition 120 saved to /data/churn/partitions/p120.\n",
      "Partition 130 saved to /data/churn/partitions/p130.\n",
      "Partition 140 saved to /data/churn/partitions/p140.\n",
      "Partition 150 saved to /data/churn/partitions/p150.\n",
      "Partition 160 saved to /data/churn/partitions/p160.\n",
      "Partition 170 saved to /data/churn/partitions/p170.\n",
      "Partition 180 saved to /data/churn/partitions/p180.\n",
      "Partition 190 saved to /data/churn/partitions/p190.\n",
      "Partition 200 saved to /data/churn/partitions/p200.\n",
      "Partition 210 saved to /data/churn/partitions/p210.\n",
      "Partition 220 saved to /data/churn/partitions/p220.\n",
      "Partition 230 saved to /data/churn/partitions/p230.\n",
      "Partition 240 saved to /data/churn/partitions/p240.\n",
      "Partition 250 saved to /data/churn/partitions/p250.\n",
      "Partition 260 saved to /data/churn/partitions/p260.\n",
      "Partition 270 saved to /data/churn/partitions/p270.\n",
      "Partition 280 saved to /data/churn/partitions/p280.\n",
      "Partition 290 saved to /data/churn/partitions/p290.\n",
      "Partition 300 saved to /data/churn/partitions/p300.\n",
      "Partition 310 saved to /data/churn/partitions/p310.\n",
      "Partition 320 saved to /data/churn/partitions/p320.\n",
      "Partition 330 saved to /data/churn/partitions/p330.\n",
      "Partition 340 saved to /data/churn/partitions/p340.\n",
      "Partition 350 saved to /data/churn/partitions/p350.\n",
      "Partition 360 saved to /data/churn/partitions/p360.\n",
      "Partition 370 saved to /data/churn/partitions/p370.\n",
      "Partition 380 saved to /data/churn/partitions/p380.\n",
      "Partition 390 saved to /data/churn/partitions/p390.\n",
      "Partition 400 saved to /data/churn/partitions/p400.\n",
      "Partition 410 saved to /data/churn/partitions/p410.\n",
      "Partition 420 saved to /data/churn/partitions/p420.\n",
      "Partition 430 saved to /data/churn/partitions/p430.\n",
      "Partition 440 saved to /data/churn/partitions/p440.\n",
      "Partition 450 saved to /data/churn/partitions/p450.\n",
      "Partition 460 saved to /data/churn/partitions/p460.\n",
      "Partition 470 saved to /data/churn/partitions/p470.\n",
      "Partition 480 saved to /data/churn/partitions/p480.\n",
      "Partition 490 saved to /data/churn/partitions/p490.\n",
      "Partition 500 saved to /data/churn/partitions/p500.\n",
      "Partition 510 saved to /data/churn/partitions/p510.\n",
      "Partition 520 saved to /data/churn/partitions/p520.\n",
      "Partition 530 saved to /data/churn/partitions/p530.\n",
      "Partition 540 saved to /data/churn/partitions/p540.\n",
      "Partition 550 saved to /data/churn/partitions/p550.\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "for i, id_subset in enumerate(id_list):\n",
    "    create_partition(id_subset, i)\n",
    "end = timer()\n",
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "Now that the data has been partitioned, we can run calculations in parallel on the data. After building a processing pipeline by experimenting with a single partition, we can then scale to using all the data by running the operations in parallel. This can be done using Dask or a similar framework like Spark using PySpark.\n",
    "\n",
    "The next notebook will create a processing pipeline for a single partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
