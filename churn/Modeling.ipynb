{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Modeling\n",
    "\n",
    "In this notebook, we will use the calculated feature matrices to train and test a machine learning model. Our objective is a model that can predict, on the first of the month, which customers will churn during the next 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PARTITION_DIR = 's3://customer-churn-spark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>time</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>gender</th>\n",
       "      <th>SUM(transactions.payment_plan_days)</th>\n",
       "      <th>SUM(transactions.plan_list_price)</th>\n",
       "      <th>SUM(transactions.actual_amount_paid)</th>\n",
       "      <th>SUM(transactions.price_difference)</th>\n",
       "      <th>...</th>\n",
       "      <th>WEEKEND(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>WEEKEND(LAST(logs.date))</th>\n",
       "      <th>DAY(LAST(transactions.transaction_date))</th>\n",
       "      <th>DAY(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>DAY(LAST(logs.date))</th>\n",
       "      <th>MONTH(LAST(transactions.transaction_date))</th>\n",
       "      <th>MONTH(LAST(transactions.membership_expire_date))</th>\n",
       "      <th>MONTH(LAST(logs.date))</th>\n",
       "      <th>churn</th>\n",
       "      <th>days_to_next_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+9zx0+mA3IZQLyjmU88qbfqJ0q9okIfYZnDI6FqaN2o=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+sZCvwt5NmFw4uE185pBid4cOxtXTHovIyPFqchulQg=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+wzmLe86mMBeoIYoPedlt24WVTW6tabsRcaz81ZXBx0=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/9+HJnqEryBbuH598zKqa8zb1Eypy927imqI9IWhJTk=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/BAK3DkUpoUESh4t8qlWs16yop+sG3i3oPYDpv5uGI0=</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno        time  city    bd  \\\n",
       "0  +9zx0+mA3IZQLyjmU88qbfqJ0q9okIfYZnDI6FqaN2o=  2015-01-01   1.0   0.0   \n",
       "1  +sZCvwt5NmFw4uE185pBid4cOxtXTHovIyPFqchulQg=  2015-01-01   1.0   0.0   \n",
       "2  +wzmLe86mMBeoIYoPedlt24WVTW6tabsRcaz81ZXBx0=  2015-01-01   1.0   0.0   \n",
       "3  /9+HJnqEryBbuH598zKqa8zb1Eypy927imqI9IWhJTk=  2015-01-01   8.0  29.0   \n",
       "4  /BAK3DkUpoUESh4t8qlWs16yop+sG3i3oPYDpv5uGI0=  2015-01-01  13.0  21.0   \n",
       "\n",
       "   registered_via gender  SUM(transactions.payment_plan_days)  \\\n",
       "0             7.0    NaN                                  0.0   \n",
       "1             7.0    NaN                                 30.0   \n",
       "2             7.0    NaN                                  0.0   \n",
       "3             9.0   male                                  0.0   \n",
       "4             9.0   male                                  0.0   \n",
       "\n",
       "   SUM(transactions.plan_list_price)  SUM(transactions.actual_amount_paid)  \\\n",
       "0                                0.0                                   0.0   \n",
       "1                              149.0                                 149.0   \n",
       "2                                0.0                                   0.0   \n",
       "3                                0.0                                   0.0   \n",
       "4                                0.0                                   0.0   \n",
       "\n",
       "   SUM(transactions.price_difference)         ...          \\\n",
       "0                                 0.0         ...           \n",
       "1                                 0.0         ...           \n",
       "2                                 0.0         ...           \n",
       "3                                 0.0         ...           \n",
       "4                                 0.0         ...           \n",
       "\n",
       "   WEEKEND(LAST(transactions.membership_expire_date))  \\\n",
       "0                                                0.0    \n",
       "1                                                1.0    \n",
       "2                                                0.0    \n",
       "3                                                0.0    \n",
       "4                                                0.0    \n",
       "\n",
       "   WEEKEND(LAST(logs.date))  DAY(LAST(transactions.transaction_date))  \\\n",
       "0                       0.0                                       NaN   \n",
       "1                       0.0                                       1.0   \n",
       "2                       0.0                                       NaN   \n",
       "3                       0.0                                       NaN   \n",
       "4                       0.0                                       NaN   \n",
       "\n",
       "   DAY(LAST(transactions.membership_expire_date)) DAY(LAST(logs.date))  \\\n",
       "0                                             NaN                  NaN   \n",
       "1                                             1.0                  NaN   \n",
       "2                                             NaN                  NaN   \n",
       "3                                             NaN                  1.0   \n",
       "4                                             NaN                  NaN   \n",
       "\n",
       "  MONTH(LAST(transactions.transaction_date))  \\\n",
       "0                                        NaN   \n",
       "1                                        1.0   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   MONTH(LAST(transactions.membership_expire_date))  MONTH(LAST(logs.date))  \\\n",
       "0                                               NaN                     NaN   \n",
       "1                                               2.0                     NaN   \n",
       "2                                               NaN                     NaN   \n",
       "3                                               NaN                     1.0   \n",
       "4                                               NaN                     NaN   \n",
       "\n",
       "   churn  days_to_next_churn  \n",
       "0    0.0                 NaN  \n",
       "1    0.0               379.0  \n",
       "2    0.0                 NaN  \n",
       "3    0.0               472.0  \n",
       "4    0.0                 NaN  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0_fm = pd.read_csv(f'{PARTITION_DIR}/p0/MS-30_feature_matrix.csv')\n",
    "p0_fm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init('/usr/local/spark-2.3.1-bin-hadoop2.7/')\n",
    "# import pyspark\n",
    "\n",
    "# sc = pyspark.SparkContext(master = 'spark://ip-172-31-23-133.ec2.internal:7077', appName = 'retrieval')\n",
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(partition_num, label_type = 'MS-30'):\n",
    "    return pd.read_csv(f'{PARTITION_DIR}/p{partition_num}/{label_type}_feature_matrix.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "N_PARTITIONS = 1000\n",
    "partitions = list(range(N_PARTITIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell retrieves a number of feature matrices for training and for testing. This could be done in parallel, but does not take very long to do sequentially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0% complete.\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(263092, 252)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(50)\n",
    "\n",
    "# Set number of train and testing feature matrices\n",
    "fms_to_get = 10\n",
    "test_fms_to_get = 5\n",
    "\n",
    "# Choose random sample of partitions\n",
    "ps = random.sample(list(range(900)), fms_to_get + test_fms_to_get)\n",
    "\n",
    "# Separate into training and testing\n",
    "test_p = ps[:test_fms_to_get]\n",
    "train_p = ps[test_fms_to_get:]\n",
    "\n",
    "\n",
    "train_fms = []\n",
    "\n",
    "for i, p in enumerate(train_p):\n",
    "    print(f'{round(100 * (i / fms_to_get), 2)}% complete.', end = '\\r')\n",
    "    train_fms.append(retrieve_data(p))\n",
    "    \n",
    "feature_matrix = pd.concat(train_fms)\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0% complete.\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(129800, 252)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fms = []\n",
    "\n",
    "for i, p in enumerate(test_p):\n",
    "    print(f'{round(100 * (i / test_fms_to_get), 2)}% complete.', end = '\\r')\n",
    "    test_fms.append(retrieve_data(p))\n",
    "    \n",
    "test_feature_matrix = pd.concat(test_fms)\n",
    "test_feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preparation\n",
    "\n",
    "The next blocks of code get the features ready for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to one hot encode the features. After doing this, we align the training and testing dataframes so they have the same columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263092, 387)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = pd.get_dummies(feature_matrix.set_index('msno'))\n",
    "test_feature_matrix = pd.get_dummies(test_feature_matrix.set_index('msno'))\n",
    "feature_matrix, test_feature_matrix = feature_matrix.align(test_feature_matrix, join = 'inner', axis = 1)\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract the labels. There are two different problems: one is a binary classification of whether or not the customer will churn during the month. The other is a regression: how many days are there until the next churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, test_y = np.array(feature_matrix.pop('churn')), np.array(test_feature_matrix.pop('churn'))\n",
    "y_reg, test_y_reg = np.array(feature_matrix.pop('days_to_next_churn')), np.array(test_feature_matrix.pop('days_to_next_churn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in Missing Values\n",
    "\n",
    "We can fill in missing values using the median of the column. As an important note, the missing test values are filled in with the median of the corresponding training feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = feature_matrix.replace({np.inf: np.nan, -np.inf: np.nan}).\\\n",
    "                                fillna(feature_matrix.median()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_matrix = test_feature_matrix.replace({np.inf: np.nan, -np.inf: np.nan}).\\\n",
    "                                          fillna(feature_matrix.median()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(feature_matrix.isnull()), np.any(np.isinf(feature_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## Baseline Model\n",
    "\n",
    "We can use a logistic regression in order to see baseline performance on this problem. If the logistic regression works well enough, then there is no need to move to a more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "\n",
      "ROC AUC: 0.5294\n",
      "precision_score: 0.0072\n",
      "recall_score: 0.0057\n",
      "f1_score: 0.0064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(model, train, y, test, test_y):\n",
    "    model.fit(train, y)\n",
    "    \n",
    "    probs = model.predict_proba(test)[:, 1]\n",
    "    preds = model.predict(test)\n",
    "    \n",
    "    roc = roc_auc_score(test_y, probs)\n",
    "    name = repr(model).split('(')[0]\n",
    "    print(f\"{name}\\n\")\n",
    "    print(f'ROC AUC: {round(roc, 4)}')\n",
    "    \n",
    "    for metric in [precision_score, recall_score, f1_score]:\n",
    "        print(f'{metric.__name__}: {round(metric(test_y, preds), 4)}')\n",
    "        \n",
    "    return model\n",
    "\n",
    "evaluate(model, feature_matrix, y, test_feature_matrix, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Complex Model\n",
    "\n",
    "For a better machine learning model, we can move to the Random Forest Classifier. From the results of the logistic regression, this looks to be a non-linear problem which means we should use a model capable of learning a non-linear decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "\n",
      "ROC AUC: 0.9553\n",
      "precision_score: 0.9418\n",
      "recall_score: 0.3528\n",
      "f1_score: 0.5133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100, max_depth = 20, n_jobs = -1)\n",
    "model = evaluate(model, feature_matrix, y, test_feature_matrix, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TIME_SINCE_LAST(transactions.transaction_date)</th>\n",
       "      <td>0.023557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAST(transactions.DAY(membership_expire_date))</th>\n",
       "      <td>0.022873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY(LAST(transactions.membership_expire_date))</th>\n",
       "      <td>0.022667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, membership_expire_date)</th>\n",
       "      <td>0.019445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME_SINCE_LAST(logs.date)</th>\n",
       "      <td>0.017653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    importance\n",
       "TIME_SINCE_LAST(transactions.transaction_date)        0.023557\n",
       "LAST(transactions.DAY(membership_expire_date))        0.022873\n",
       "DAY(LAST(transactions.membership_expire_date))        0.022667\n",
       "TOTAL_PREVIOUS_MONTH(transactions.actual_amount...    0.019445\n",
       "TIME_SINCE_LAST(logs.date)                            0.017653"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.DataFrame({'importance': model.feature_importances_}, index = feature_matrix.columns).\\\n",
    "sort_values('importance', ascending = False)\n",
    "fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7362488338696902"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100, max_depth = 20, n_jobs = -1)\n",
    "model.fit(feature_matrix[['TIME_SINCE_LAST(transactions.transaction_date)',\n",
    "                          'LAST(transactions.DAY(membership_expire_date))']], np.array(y))\n",
    "\n",
    "p = model.predict_proba(test_feature_matrix[['TIME_SINCE_LAST(transactions.transaction_date)',\n",
    "                          'LAST(transactions.DAY(membership_expire_date))']])[:, 1]\n",
    "roc_auc_score(np.array(test_y), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9770493066255778"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - np.mean(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      0.068229\n",
       "mean     202.495165\n",
       "std      186.021711\n",
       "min        0.000000\n",
       "25%       31.000000\n",
       "50%      140.000000\n",
       "75%      393.000000\n",
       "max      757.000000\n",
       "Name: TIME_SINCE_LAST(transactions.transaction_date), dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.iloc[np.where(y == 1)[0]]['TIME_SINCE_LAST(transactions.transaction_date)'].describe() / (3600 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.571970e+05\n",
       "mean     2.111073e+07\n",
       "std      1.919956e+07\n",
       "min      0.000000e+00\n",
       "25%      3.024000e+06\n",
       "50%      1.702080e+07\n",
       "75%      3.456000e+07\n",
       "max      6.825600e+07\n",
       "Name: TIME_SINCE_LAST(transactions.transaction_date), dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.iloc[np.where(y == 0)[0]]['TIME_SINCE_LAST(transactions.transaction_date)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
